{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00fd4389",
   "metadata": {},
   "source": [
    "# Librabries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d9355bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23f5879",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3651eb2d",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0a7ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike = pd.read_csv(\"Seoul_Bike.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928b9638",
   "metadata": {},
   "source": [
    "DOI\n",
    "10.24432/C5F62R\n",
    "License\n",
    "This dataset is licensed under a Creative Commons Attribution 4.0 International (CC BY 4.0) license.\n",
    "This allows for the sharing and adaptation of the datasets for any purpose, provided that the appropriate credit is given.\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/560/seoul+bike+sharing+demand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3319d90",
   "metadata": {},
   "source": [
    "@misc{misc_seoul_bike_sharing_demand_560,\n",
    "  title        = {{Seoul Bike Sharing Demand}},\n",
    "  year         = {2020},\n",
    "  howpublished = {UCI Machine Learning Repository},\n",
    "  note         = {{DOI}: https://doi.org/10.24432/C5F62R}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3114db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Dew point temperature(°C)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Functioning Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>37</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Rented Bike Count  Hour  Temperature(°C)  Humidity(%)  \\\n",
       "0  01/12/2017                254     0             -5.2           37   \n",
       "1  01/12/2017                204     1             -5.5           38   \n",
       "2  01/12/2017                173     2             -6.0           39   \n",
       "\n",
       "   Wind speed (m/s)  Visibility (10m)  Dew point temperature(°C)  \\\n",
       "0               2.2              2000                      -17.6   \n",
       "1               0.8              2000                      -17.6   \n",
       "2               1.0              2000                      -17.7   \n",
       "\n",
       "   Solar Radiation (MJ/m2)  Rainfall(mm)  Snowfall (cm) Seasons     Holiday  \\\n",
       "0                      0.0           0.0            0.0  Winter  No Holiday   \n",
       "1                      0.0           0.0            0.0  Winter  No Holiday   \n",
       "2                      0.0           0.0            0.0  Winter  No Holiday   \n",
       "\n",
       "  Functioning Day  \n",
       "0             Yes  \n",
       "1             Yes  \n",
       "2             Yes  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7da1278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Dew point temperature(°C)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Functioning Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>30/11/2018</td>\n",
       "      <td>694</td>\n",
       "      <td>21</td>\n",
       "      <td>2.6</td>\n",
       "      <td>39</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1968</td>\n",
       "      <td>-9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>30/11/2018</td>\n",
       "      <td>712</td>\n",
       "      <td>22</td>\n",
       "      <td>2.1</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1859</td>\n",
       "      <td>-9.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>30/11/2018</td>\n",
       "      <td>584</td>\n",
       "      <td>23</td>\n",
       "      <td>1.9</td>\n",
       "      <td>43</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1909</td>\n",
       "      <td>-9.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Rented Bike Count  Hour  Temperature(°C)  Humidity(%)  \\\n",
       "8757  30/11/2018                694    21              2.6           39   \n",
       "8758  30/11/2018                712    22              2.1           41   \n",
       "8759  30/11/2018                584    23              1.9           43   \n",
       "\n",
       "      Wind speed (m/s)  Visibility (10m)  Dew point temperature(°C)  \\\n",
       "8757               0.3              1968                       -9.9   \n",
       "8758               1.0              1859                       -9.8   \n",
       "8759               1.3              1909                       -9.3   \n",
       "\n",
       "      Solar Radiation (MJ/m2)  Rainfall(mm)  Snowfall (cm) Seasons  \\\n",
       "8757                      0.0           0.0            0.0  Autumn   \n",
       "8758                      0.0           0.0            0.0  Autumn   \n",
       "8759                      0.0           0.0            0.0  Autumn   \n",
       "\n",
       "         Holiday Functioning Day  \n",
       "8757  No Holiday             Yes  \n",
       "8758  No Holiday             Yes  \n",
       "8759  No Holiday             Yes  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce60c0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8760, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c051a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Dew point temperature(°C)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>704.602055</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>12.882922</td>\n",
       "      <td>58.226256</td>\n",
       "      <td>1.724909</td>\n",
       "      <td>1436.825799</td>\n",
       "      <td>4.073813</td>\n",
       "      <td>0.569111</td>\n",
       "      <td>0.148687</td>\n",
       "      <td>0.075068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>644.997468</td>\n",
       "      <td>6.922582</td>\n",
       "      <td>11.944825</td>\n",
       "      <td>20.362413</td>\n",
       "      <td>1.036300</td>\n",
       "      <td>608.298712</td>\n",
       "      <td>13.060369</td>\n",
       "      <td>0.868746</td>\n",
       "      <td>1.128193</td>\n",
       "      <td>0.436746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-17.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>-30.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>191.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>940.000000</td>\n",
       "      <td>-4.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>504.500000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>13.700000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1698.000000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1065.250000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3556.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>39.400000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>8.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rented Bike Count         Hour  Temperature(°C)  Humidity(%)  \\\n",
       "count        8760.000000  8760.000000      8760.000000  8760.000000   \n",
       "mean          704.602055    11.500000        12.882922    58.226256   \n",
       "std           644.997468     6.922582        11.944825    20.362413   \n",
       "min             0.000000     0.000000       -17.800000     0.000000   \n",
       "25%           191.000000     5.750000         3.500000    42.000000   \n",
       "50%           504.500000    11.500000        13.700000    57.000000   \n",
       "75%          1065.250000    17.250000        22.500000    74.000000   \n",
       "max          3556.000000    23.000000        39.400000    98.000000   \n",
       "\n",
       "       Wind speed (m/s)  Visibility (10m)  Dew point temperature(°C)  \\\n",
       "count       8760.000000       8760.000000                8760.000000   \n",
       "mean           1.724909       1436.825799                   4.073813   \n",
       "std            1.036300        608.298712                  13.060369   \n",
       "min            0.000000         27.000000                 -30.600000   \n",
       "25%            0.900000        940.000000                  -4.700000   \n",
       "50%            1.500000       1698.000000                   5.100000   \n",
       "75%            2.300000       2000.000000                  14.800000   \n",
       "max            7.400000       2000.000000                  27.200000   \n",
       "\n",
       "       Solar Radiation (MJ/m2)  Rainfall(mm)  Snowfall (cm)  \n",
       "count              8760.000000   8760.000000    8760.000000  \n",
       "mean                  0.569111      0.148687       0.075068  \n",
       "std                   0.868746      1.128193       0.436746  \n",
       "min                   0.000000      0.000000       0.000000  \n",
       "25%                   0.000000      0.000000       0.000000  \n",
       "50%                   0.010000      0.000000       0.000000  \n",
       "75%                   0.930000      0.000000       0.000000  \n",
       "max                   3.520000     35.000000       8.800000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1525f72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8760 entries, 0 to 8759\n",
      "Data columns (total 14 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Date                       8760 non-null   object \n",
      " 1   Rented Bike Count          8760 non-null   int64  \n",
      " 2   Hour                       8760 non-null   int64  \n",
      " 3   Temperature(°C)            8760 non-null   float64\n",
      " 4   Humidity(%)                8760 non-null   int64  \n",
      " 5   Wind speed (m/s)           8760 non-null   float64\n",
      " 6   Visibility (10m)           8760 non-null   int64  \n",
      " 7   Dew point temperature(°C)  8760 non-null   float64\n",
      " 8   Solar Radiation (MJ/m2)    8760 non-null   float64\n",
      " 9   Rainfall(mm)               8760 non-null   float64\n",
      " 10  Snowfall (cm)              8760 non-null   float64\n",
      " 11  Seasons                    8760 non-null   object \n",
      " 12  Holiday                    8760 non-null   object \n",
      " 13  Functioning Day            8760 non-null   object \n",
      "dtypes: float64(6), int64(4), object(4)\n",
      "memory usage: 958.3+ KB\n"
     ]
    }
   ],
   "source": [
    "bike.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d554ad98",
   "metadata": {},
   "source": [
    "## Changing from categorical to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49481691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Winter', 'Spring', 'Summer', 'Autumn'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike[\"Seasons\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71933fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No Holiday', 'Holiday'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike[\"Holiday\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cddce80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike[\"Functioning Day\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b553529",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike['Seasons'].replace('Winter', 0, inplace = True)\n",
    "bike['Seasons'].replace('Spring', 1, inplace = True)\n",
    "bike['Seasons'].replace('Summer', 2, inplace = True)\n",
    "bike['Seasons'].replace('Autumn', 3, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b709716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8758    3\n",
       "8759    3\n",
       "Name: Seasons, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike['Seasons'].tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a633542",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike[\"Holiday\"].replace('No Holiday', 0, inplace = True)\n",
    "bike[\"Holiday\"].replace('Holiday', 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "168799a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8758    0\n",
       "8759    0\n",
       "Name: Holiday, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike[\"Holiday\"].tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d461b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike[\"Functioning Day\"].replace('No', 0, inplace = True)\n",
    "bike[\"Functioning Day\"].replace('Yes', 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de4649aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8758    1\n",
       "8759    1\n",
       "Name: Functioning Day, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike[\"Functioning Day\"].tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5ded7f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b8617ba",
   "metadata": {},
   "source": [
    "# Graphics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a66de9",
   "metadata": {},
   "source": [
    "sns.histplot(data = bike, y = \"Rented Bike Count\", x = \"Hour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9f97d3",
   "metadata": {},
   "source": [
    "sns.histplot(data = bike, x = \"Holiday\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4344e869",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f52f9faf",
   "metadata": {},
   "source": [
    "sns.histplot(data = bike, x = \"Functioning Day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbb515f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27e3f8db",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "sns.histplot(data = bike, x = \"Rented Bike Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b638edd",
   "metadata": {},
   "source": [
    "sns.histplot(data = bike, x = \"Temperature(°C)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f862ac",
   "metadata": {},
   "source": [
    "sns.histplot(data = bike, x = \"Humidity(%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3b5b69",
   "metadata": {},
   "source": [
    "sns.histplot(data = bike, x = \"Wind speed (m/s)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae0515",
   "metadata": {},
   "source": [
    "sns.histplot(data = bike, x = \"Visibility (10m)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bcb0bb",
   "metadata": {},
   "source": [
    "sns.histplot(data = bike, x = \"Dew point temperature(°C)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc3744c",
   "metadata": {},
   "source": [
    "sns.histplot(data = bike, x = \"Solar Radiation (MJ/m2)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc2ba5",
   "metadata": {},
   "source": [
    "sns.histplot(data = bike, x = \"Rainfall(mm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48980c8",
   "metadata": {},
   "source": [
    "sns.histplot(data = bike, x = \"Snowfall (cm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98697b8",
   "metadata": {},
   "source": [
    "sns.histplot(data = bike, x = \"Seasons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca143f37",
   "metadata": {},
   "source": [
    "The bikes have been used equally throughout the seasons "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd615d3f",
   "metadata": {},
   "source": [
    "The seasons have the same amount of observations but the number of rented bikes are different between seasons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a558a7",
   "metadata": {},
   "source": [
    "bike.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc44aa3b",
   "metadata": {},
   "source": [
    "bike.plot(x = \"Temperature(°C)\", y = \"Rented Bike Count\", style = \"*\")\n",
    "plt.title(\"Rented Bike Count vs Temperature(°C)\")\n",
    "plt.xlabel(\"Temperature(°C)\")\n",
    "plt.ylabel(\"Rented Bike Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff3f65f",
   "metadata": {},
   "source": [
    "bike.plot(x = \"Hour\", y = \"Rented Bike Count\", style = \"*\")\n",
    "plt.title(\"Rented Bike Count vs Hour\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Rented Bike Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05d02d0",
   "metadata": {},
   "source": [
    "sns.histplot(data = bike, x = \"Seasons\", y = \"Rented Bike Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d391499",
   "metadata": {},
   "source": [
    "('Winter', 0, inplace = True)\n",
    "('Spring', 1, inplace = True)\n",
    "('Summer', 2, inplace = True)\n",
    "('Autumn', 3, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551fcf49",
   "metadata": {},
   "source": [
    "sns.histplot(data = bike, x = \"Seasons\", y = \"Temperature(°C)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc42cc7",
   "metadata": {},
   "source": [
    "sns.boxplot(data = bike[\"Rented Bike Count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97e4996",
   "metadata": {},
   "source": [
    "sns.boxplot(data = bike[\"Temperature(°C)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ec0b6c",
   "metadata": {},
   "source": [
    " sns.boxplot(data = bike[\"Visibility (10m)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e489789",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82dc2cc5",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3405e80a",
   "metadata": {},
   "source": [
    "bike.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85bf135",
   "metadata": {},
   "source": [
    "bike_d = bike.drop([\"Date\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3493c839",
   "metadata": {},
   "source": [
    "bike_d.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd8c52d",
   "metadata": {},
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = bike_d.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(bike_d.values, i) for i in range(bike_d.shape[1])]\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0787800",
   "metadata": {},
   "source": [
    "corr_matrix = np.corrcoef(bike_d, rowvar = False)\n",
    "\n",
    "sns.heatmap(corr_matrix, annot = True, cmap = 'coolwarm', fmt = '.2f', \n",
    "            xticklabels = range(bike_d.shape[1]), yticklabels = range(bike_d.shape[1]))\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b0ce43",
   "metadata": {},
   "source": [
    "The highest correlations are between: \n",
    "- Rented Bike Count & Temperature(°C) = 0.54 (0 & 2)\n",
    "- Temperature(°C) & Dew point temperature(°C) = 0.91 (2 & 6)\n",
    "- Temperature(°C) & Seasons = 0.59 (2 & 10)\n",
    "- Humidity(%) & Visibility (10m) = 0.54 (3 & 5)\n",
    "- Humidity(%) & Dew point temperature(°C) = 0.54 (3 & 6)\n",
    "- Dew point temperature(°C) & Seasons = 0.58 (6 & 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f9512",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "eigenvalues, _ = np.linalg.eig(corr_matrix)\n",
    "print(\"Eigenvalues:\", eigenvalues)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abe2c34",
   "metadata": {},
   "source": [
    "condition_number = np.sqrt(np.max(eigenvalues) / np.min(eigenvalues))\n",
    "print(\"Condition Number:\", condition_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8260248c",
   "metadata": {},
   "source": [
    "def find_highly_correlated_vars(corr_matrix, threshold = 0.5):\n",
    "    if isinstance(corr_matrix, pd.DataFrame):\n",
    "        corr_matrix = corr_matrix.values\n",
    "    rows, cols = np.where(np.abs(corr_matrix) > threshold)\n",
    "    unique_pairs = set((min(r, c), max(r, c)) for r, c in zip(rows, cols) if r != c)\n",
    "    return list(unique_pairs)\n",
    "\n",
    "corr_matrix = bike_d.corr()\n",
    "highly_corr_vars = find_highly_correlated_vars(corr_matrix, threshold=0.5)\n",
    "\n",
    "print(\"Pairs of highly correlated variables:\", highly_corr_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc574245",
   "metadata": {},
   "source": [
    "bike_d.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3da89e",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "sns.pairplot(bike[[\"Rented Bike Count\", \"Temperature(°C)\"]])\n",
    "\n",
    "#sns.pairplot(bike[[\"Rented Bike Count\", \"Seasons\"]])\n",
    "\n",
    "sns.pairplot(bike[[\"Temperature(°C)\", \"Dew point temperature(°C)\"]])\n",
    "\n",
    "sns.pairplot(bike[[\"Temperature(°C)\", \"Seasons\"]])\n",
    "\n",
    "sns.pairplot(bike[[\"Humidity(%)\", \"Visibility (10m)\"]])\n",
    "\n",
    "sns.pairplot(bike[[\"Humidity(%)\", \"Dew point temperature(°C)\"]])\n",
    "\n",
    "sns.pairplot(bike[[\"Dew point temperature(°C)\", \"Seasons\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686a6bcf",
   "metadata": {},
   "source": [
    "Rented Bike Count & Temperature(°C) = 0.54 (0 & 2)\n",
    "\n",
    "Temperature(°C) & Dew point temperature(°C) = 0.91 (2 & 6)\n",
    "\n",
    "Temperature(°C) & Seasons = 0.59 (2 & 10)\n",
    "\n",
    "Humidity(%) & Visibility (10m) = 0.54 (3 & 5)\n",
    "\n",
    "Humidity(%) & Dew point temperature(°C) = 0.54 (3 & 6)\n",
    "Dew point temperature(°C) & Seasons = 0.58 (6 & 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f341a7b9",
   "metadata": {},
   "source": [
    "Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8fb6a3",
   "metadata": {},
   "source": [
    "X = bike_d.iloc[:, 1:]  # All rows, columns from index 1 onwards (excluding the first column)\n",
    "y = bike_d.iloc[:, 0]   # All rows, only the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a7078a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_d2 = bike.drop([\"Date\", \"Visibility (10m)\", \"Dew point temperature(°C)\", \"Seasons\", \"Holiday\", \"Functioning Day\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de5b431d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>37</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rented Bike Count  Hour  Temperature(°C)  Humidity(%)  Wind speed (m/s)  \\\n",
       "0                254     0             -5.2           37               2.2   \n",
       "1                204     1             -5.5           38               0.8   \n",
       "\n",
       "   Solar Radiation (MJ/m2)  Rainfall(mm)  Snowfall (cm)  \n",
       "0                      0.0           0.0            0.0  \n",
       "1                      0.0           0.0            0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_d2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf1272e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg8AAAGxCAYAAADlDVU6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAADT3UlEQVR4nOzddXhT1//A8XfStKm7l3qx4hR3LT4YMGDokA3GNjZkwtiGTJhiGzp8OAx3dxgOw6FIC9Rd07S5vz8yUtKmhUIy2Pd3Xs+TB3pyzs05yb25n3vkRiZJkoQgCIIgCMIzkr/sCgiCIAiC8N8iggdBEARBEEpFBA+CIAiCIJSKCB4EQRAEQSgVETwIgiAIglAqIngQBEEQBKFURPAgCIIgCEKpiOBBEARBEIRSEcGDIAiCIAilIoKH/2cWL16MTCYz+BgzZoxJXvPq1atMmDCBe/fumWT7xhAbG8tnn31GlSpVsLW1xdLSkrJly/Lhhx9y69atl129ImQyGRMmTCh1uaysLCZMmMDBgweLPPd433gZn1OzZs2QyWQEBQVh6Ka3hw8f1u2nixcvLvX2Hz16xIQJE7hw4UKpyr311lsEBASU+vUE4X+d4mVXQHg5Fi1aRIUKFfTSvL29TfJaV69eZeLEiTRr1uyV/CI+deoUHTt2RJIk3n//ferXr4+FhQU3btxg2bJl1KlTh+Tk5JddTaPIyspi4sSJgPaE/aQOHTpw4sQJvLy8XkLNwM7Ojrt377J//35atmyp99zChQuxt7cnLS3tubb96NEjJk6cSEBAANWrV3/mcl9++SUffvjhc72mIPwvE8HD/1OVK1emVq1aL7saL0StViOTyVAonn83TktLo3PnzlhaWnL8+HHKlCmje65Zs2YMHTqUdevWGaO6ZGVlYW1tbfC57OxsrKysjPI6z8vNzQ03N7eX9vp+fn7Y2dmxcOFCveAhPT2dtWvX0qdPH37//fd/pS6PP6vg4OB/5fUE4b9GDFsIBq1evZr69etjY2ODra0tbdq04fz583p5zpw5Q69evQgICMDKyoqAgADefPNN7t+/r8uzePFi3njjDQCaN29epOs5ICCAt956q8jrN2vWTO/K+ODBg8hkMv744w9Gjx6Nj48PSqWS27dvA7B3715atmyJvb091tbWNGzYkH379j21nb///jsxMTH8+OOPeoHDk7p376739+bNm6lfvz7W1tbY2dnRunVrTpw4oZdnwoQJyGQyzp07R/fu3XFyctKdiAICAujYsSPr16+nRo0aWFpa6noDYmJiGDp0KGXKlMHCwoLAwEAmTpxIXl5eie2Ij49n+PDhhIaGYmtri7u7Oy1atODIkSO6PPfu3dMFBxMnTtR9Fo/f/+KGLRYuXEi1atWwtLTE2dmZ119/nWvXrunleeutt7C1teX27du0b98eW1tbfH19GT16NCqVqsS6P2nQoEGsX7+elJQUXdqqVasA6NWrV5H8t2/fZuDAgZQtWxZra2t8fHzo1KkTf//9ty7PwYMHqV27NgADBw7UtfvxsM/juv/999+Eh4djZ2enC14KD1usWrUKmUzGb7/9pleP8ePHY2Zmxp49e565rYLwXyaCh/+n8vPzycvL03s89t133/Hmm28SGhrKmjVr+OOPP0hPT6dx48ZcvXpVl+/evXuUL1+eadOmsWvXLn744Qeio6OpXbs2CQkJgLYr/LvvvgNg5syZnDhxghMnTtChQ4fnqvfYsWOJjIxkzpw5bNmyBXd3d5YtW0Z4eDj29vYsWbKENWvW4OzsTJs2bZ4aQOzevRszMzM6der0TK+/YsUKOnfujL29PStXrmTBggUkJyfTrFkzjh49WiR/165dCQkJYe3atcyZM0eXfu7cOT7++GNGjBjBzp076datGzExMdSpU4ddu3bx1VdfsWPHDgYPHszkyZN5++23S6xXUlISoD2Jbdu2jUWLFhEUFESzZs108xu8vLzYuXMnAIMHD9Z9Fl9++WWx2508eTKDBw+mUqVKrF+/nunTp3Pp0iXq169fZC6IWq3mtddeo2XLlmzatIlBgwYxdepUfvjhh2d6b0EbIJiZmbFy5Upd2oIFC+jevTv29vZF8j969AgXFxe+//57du7cycyZM1EoFNStW5cbN24AULNmTRYtWgTAF198oWv3kCFDdNvJzc3ltddeo0WLFmzatEkXzBmq37Bhwxg9ejRnzpwBYP/+/XzzzTd8/vnntG7d+pnbKgj/aZLw/8qiRYskwOBDrVZLkZGRkkKhkD744AO9cunp6ZKnp6fUo0ePYredl5cnZWRkSDY2NtL06dN16WvXrpUA6cCBA0XK+Pv7SwMGDCiS3rRpU6lp06a6vw8cOCABUpMmTfTyZWZmSs7OzlKnTp300vPz86Vq1apJderUKeHdkKQKFSpInp6eJeZ5cpve3t5SlSpVpPz8fF16enq65O7uLjVo0ECXNn78eAmQvvrqqyLb8ff3l8zMzKQbN27opQ8dOlSytbWV7t+/r5f+888/S4B05coVXRogjR8/vti65uXlSWq1WmrZsqX0+uuv69Lj4+OLLft437h7964kSZKUnJwsWVlZSe3bt9fLFxkZKSmVSql37966tAEDBkiAtGbNGr287du3l8qXL19sPR9r2rSpVKlSJd22atWqJUmSJF25ckUCpIMHD0qnT5+WAGnRokUltjs3N1cqW7asNHLkSF16SWUf133hwoUGn/P399dLy8nJkWrUqCEFBgZKV69elTw8PKSmTZtKeXl5T22nIPyvED0P/08tXbqU06dP6z0UCgW7du0iLy+P/v376/VKWFpa0rRpU71Z+hkZGXz66aeEhISgUChQKBTY2tqSmZlZpFvbWLp166b39/Hjx0lKSmLAgAF69dVoNLRt25bTp0+TmZlplNe+ceMGjx49ol+/fsjlBYeOra0t3bp14+TJk2RlZZVY38eqVq1KuXLl9NK2bt1K8+bN8fb21mtLu3btADh06FCJ9ZszZw41a9bE0tIShUKBubk5+/bte+7P4sSJE2RnZxcZVvL19aVFixZFenVkMlmRHpyqVavqDWM9i0GDBnHmzBn+/vtvFixYQHBwME2aNDGYNy8vj++++47Q0FAsLCxQKBRYWFhw69atUre7uM+qMKVSyZo1a0hMTKRmzZpIksTKlSsxMzMr1esJwn+ZmDD5/1TFihUNTpiMjY0F0I0RF/bkSbN3797s27ePL7/8ktq1a2Nvb49MJqN9+/ZkZ2ebpN6FVwI8rm/heQlPSkpKwsbGxuBzfn5+3Lp1i8zMzGLzPJaYmGiwDqBdqaLRaEhOTtabFFncygVD6bGxsWzZsgVzc3ODZR4PBRkyZcoURo8ezbBhw/j6669xdXXFzMyML7/88rmDh6e1t/D4vrW1NZaWlnppSqWSnJycUr1ukyZNKFu2LHPnzmXNmjV89NFHyGQyg3lHjRrFzJkz+fTTT2natClOTk7I5XKGDBlSqn3Q2tra4LBIcUJCQmjcuDHbtm3j3XfffWkrVAThZRHBg6DH1dUVgHXr1uHv719svtTUVLZu3cr48eP57LPPdOkqlUo3/v4sLC0tDU6oS0hI0NXlSYVPIo/z/Prrr9SrV8/ga3h4eBT7+m3atGH37t1s2bLF4IS8J7m4uAAQHR1d5LlHjx4hl8txcnIqsb4lpbu6ulK1alW+/fZbg2VKWkq7bNkymjVrxuzZs/XS09PTiy3zNE9rr6HPx1gGDhzIF198gUwmY8CAAcXmW7ZsGf3799fNq3ksISEBR0fHZ3694j6n4syfP59t27ZRp04dfvvtN3r27EndunVLtQ1B+C8TwYOgp02bNigUCiIiIkrsxpXJZEiShFKp1EufP38++fn5emmP8xi6EgwICODSpUt6aTdv3uTGjRvPdHJq2LAhjo6OXL16lffff/+p+QsbPHgwP/30E5988gmNGzfGx8enSJ7169fTtWtXypcvj4+PDytWrGDMmDG6E05mZiZ//vmnbgXG8+rYsSPbt28nODi4SBDyNDKZrMhncenSJU6cOIGvr68uraTPorD69etjZWXFsmXLdCtmAB48eMD+/ftL7O15UQMGDOCvv/6iYsWKBj+Txwy1e9u2bTx8+JCQkBBdWmna/TR///03I0aMoH///vz+++80aNCAnj17cv78+VJ/boLwXyWCB0FPQEAAkyZNYty4cdy5c4e2bdvi5OREbGwsp06dwsbGhokTJ2Jvb0+TJk346aefcHV1JSAggEOHDrFgwYIiV3yVK1cGYN68edjZ2WFpaUlgYCAuLi7069ePvn37Mnz4cLp168b9+/f58ccfn/l+A7a2tvz6668MGDCApKQkunfvjru7O/Hx8Vy8eJH4+PgiV+NPcnBwYNOmTXTs2JEaNWro3STq1q1bLFu2jIsXL9K1a1fkcjk//vgjffr0oWPHjgwdOhSVSsVPP/1ESkoK33///XO/7wCTJk1iz549NGjQgBEjRlC+fHlycnK4d+8e27dvZ86cOcUuJ+3YsSNff/0148ePp2nTpty4cYNJkyYRGBiot5LGzs4Of39/Nm3aRMuWLXF2dtZ9foU5Ojry5Zdf8vnnn9O/f3/efPNNEhMTmThxIpaWlowfP/6F2lsSb29vNm7c+NR8HTt2ZPHixVSoUIGqVaty9uxZfvrppyLvU3BwMFZWVixfvpyKFStia2uLt7d3qW+MlpmZSY8ePQgMDGTWrFlYWFiwZs0aatasycCBA5+pzoLwP+Flz9gU/l2PZ9SfPn26xHwbN26UmjdvLtnb20tKpVLy9/eXunfvLu3du1eX58GDB1K3bt0kJycnyc7OTmrbtq10+fJlgysopk2bJgUGBkpmZmZ6s941Go30448/SkFBQZKlpaVUq1Ytaf/+/cWutli7dq3B+h46dEjq0KGD5OzsLJmbm0s+Pj5Shw4dis1fWExMjPTpp59KlSpVkqytrSWlUimFhIRIQ4cOlf7+++8i703dunUlS0tLycbGRmrZsqV07NgxvTyPV1vEx8cXeS1/f3+pQ4cOBusRHx8vjRgxQgoMDJTMzc0lZ2dnKSwsTBo3bpyUkZGhy0ehFRMqlUoaM2aM5OPjI1laWko1a9aUNm7caHC1wN69e6UaNWpISqVSAnSfVeHVFo/Nnz9fqlq1qmRhYSE5ODhInTt31lv5IUnaVQk2NjZF2vP4fXiaJ1dbFMfQionk5GRp8ODBkru7u2RtbS01atRIOnLkSJH9R5IkaeXKlVKFChUkc3NzvfevuLo/fu7J969v376StbV1kfY/XlE0derUp7ZVEP4XyCTJwI3kBUEQBEEQiiGWagqCIAiCUCoieBAEQRAEoVRE8CAIgiAIQqmI4EEQBEEQXhGHDx+mU6dOeHt7I5PJnmkFz6FDhwgLC8PS0pKgoCC939ExFRE8CIIgCMIrIjMzk2rVqhX55dbi3L17l/bt29O4cWPOnz/P559/zogRI/jzzz9NWk+x2kIQBEEQXkEymYwNGzbQpUuXYvN8+umnbN68We829MOGDePixYucOHHCZHUTPQ+CIAiCYEIqlYq0tDS9h6Hb8j+PEydOEB4erpfWpk0bzpw5g1qtNsprGPLK3GFym3n5l12FF9b45IyXXQWjsHh4+2VXwSi+eDjwZVfhhXUy/GOS/zk+lrEvuwovbO1Zv5ddBaPIy//f6Gz+8k3Tnr6MeU46Pe5NJk6cqJc2fvx4JkyY8MLbjomJKfL7PR4eHuTl5ZGQkGCyH217ZYIHQRAEQXhVyMxL92NpJRk7diyjRo3SSyv8mywvovAPuz2ejVDaH3wrDRE8CIIgCIIJKZVKowYLT/L09CQmJkYvLS4uDoVCoftlXFMQwYMgCIIgFCJXmO6q3Zjq16/Pli1b9NJ2795NrVq1MDc3N9nrigmTgiAIglCIzFxutEdpZGRkcOHCBS5cuABol2JeuHCByMhIQDsE0r9/f13+YcOGcf/+fUaNGsW1a9dYuHAhCxYsYMyYMUZ7LwwRPQ+CIAiCUMjL6nk4c+YMzZs31/39eK7EgAEDWLx4MdHR0bpAAiAwMJDt27czcuRIZs6cibe3NzNmzKBbt24mracIHgRBEAThFdGsWTNKuv3S4sWLi6Q1bdqUc+fOmbBWRYngQRAEQRAKMeZqi/9FIngQBEEQhEL+KxMmXxYxYVIQBEEQhFIRPQ+CIAiCUIgYtiiZCB4EQRAEoRAxbFEyMWwhCIIgCEKpiJ4HQRAEQShEZiZ6HkoiggdBEARBKEQugocSiWELQRAEQRBKRfQ8CIIgCEIhMrnoeSjJfzJ4cG5Ui6DRg3GoWRlLb3fOdBtO7OZ9JZdpXJvQnz/DNrQsqkdxRPwyn8h5q/TyeL4eTrkJH2Id7EdWRCQ3vppK7Ka9JmvH2j1HWLZ1HwkpaQT5eDKqfzdqVAh+armLN+4w9OsZBPl6sWLyp7r0iAfRzF27net3o4hOSGJkv9fp3a55CVsyjtXHL7H44DkS0jMJ9nDmk9eaUDPIx2De0xEPGDJnfZH0jR/3JdDduUj6jgs3+Wz5TppXCmLaWx2NXvfCwmuZUzfUDGuljMhYDeuP5BKbXPytYutWNCOsvAJPZ20n3oN4DTv+UhMVp9HL16CSgmbVFdhZy4hNlth0LJe70RpDm3whB3esYdemJaQmJ+DtG0zPQWMoG1rTYN6UpHjWLZnC/YhrxEVH0qL9m/Qc/LFeniN71nPi4FYeRd4GwC+4Iq/3+YDAspWNXvcnbd26hfV/riMpKQk/f3/eeWcYlSsbfs1jx46yfds27ty5g1qtxt/fj959+hIWVksvX0ZGBkuXLOb48WNkZGTg4enJkCFvU7t2HZO2pVElGdWDZFiaw6Mk2H1OQ0Ja8fld7aFxZTmeTuBoI2PveQ2nb+nvg/UryChfRoazHeTlw8NEOHBJQ1K6adrQpLKcmsEyLC20r7XzTD7xJbTBzR6aVpXj5STD0VbGrnP5nLpR/HHUMFRGi2pm/HVDw+5zxj8unofMTHTMl+Q/+e6Y2ViTdukGVz6c9Ez5rQLKUHvLPJKOnuVo7S7c/mEOlaaOw/P1cF0ex3rVqbFiKg+Xb+JIWGceLt9EzZXTcKxT1SRt2H3iHFOWrmdgl3CWffcJ1SsE8+EPs4lJSCqxXEZWNuNn/0HtSuWKPJejysXH3YX3e3XCxdHeJPUubOeFm/y4+TBvt6zF6o/epGagD8MXbCY6ueRvsU2f9GPfl4N1Dz9XxyJ5HiWnMWXrEWoGepuo9vqaV1fQpJqCDUfUTP8zh7QsiXc6KVGW8Ku2wd5mXLiVz5xNOfy6PoeUdIl3Oiqxtym4aqkWbMZrDc3Ze07N1LU53InOZ0gHJY62xr2yOX10F6sX/UT7boP58peVlK1YgxnfvE9ifLTB/Hl5amztnWjfbTBlAoruTwA3Lp+hTqO2jJ70O59OXoKzqxfTJr5LcmKcUev+pMOHDvH7vLn07NmLGb/OpHKlyoz/6gvi4gy/5pXLl6lRoyYTJ01i+oxfqVq1GpMmTiAi4rYuj1qt5otxY4mNi+Xzz79g3rz5jBjxIS4uriZrB0C9CjLqlJOx+5yGxXs1ZOZI9Goqx6KEyzZzM0jJkDh4SSIj2/AJ189NxtnbEkv3aVh1SINcBr2ayDE3M34bGlSUUa+CjJ1nNSzYnU9mjkSf5mYltkGhgOQM2H9RQ3oxbXjMyxlqBMtLDNJfBrmZzGiP/0X/yeAhftdhbo6fRszGPc+U3/+dXuRERnN19HdkXL9D1MJ1RC1eT9CoQbo8gR8MIGHvcSJ+nEfmjTtE/DiPhP0nCfhggEnasGL7ATo3q0eX5g0I9PFkdP9ueLg4sW7v0RLLfTd/NW0a1KJK2YAiz1UK9ufDPl0IbxCGheLf6VT64/B5Xq9dia51KxPk4cwnnZvg6WjLmhOXSiznbGuNq72N7mEm198V8zUaxq7Yxbvh9Sjj7GDKJug0rmrOvrNqLt/NJyZJYtX+XCwUMmqULf69XLEvl+NX8niUKBGfIrH2UC4yGZT1KWhP02oKTl3P49S1fOJSJDYfU5OSIVG/knE/oz1bltGoZRcat+6KV5kgeg7+GCcXTw7tWmswv6u7N70Gf0L95p2wsrY1mGfIyO9o1q4HvoHl8SoTSP93v0SSJK5f+suodX/Shg3rCQ9vQ5u27fDz8+OdocNwdXNj+7atBvO/M3QY3d94g3LlyuPj48OAtwbi7e3NX38V1HHP7t2kp2fw5ZfjCa1UCXcPDypVqkxQUJDJ2gFQu6yM49ckbj6EhDTYekrC3AxC/Yo/oUQnw4FLEteiJPKKuQhffUTD3/ckEtIgLhW2ntbgYCPD08n4bahTXs7RKxquP5CIT4VNJzWYK6CyfwltSIJ9FzRciZTIzy9+2+YKeL2+GdtOacjONX7dBdP5TwYPpeVYrzrxe4/ppcXvPoJDWGVk/5xknepVJ6HQiTthzxGc6tcwen3UeXlcvxtF3aoV9NLrVqnApZt3iy23+eBJHsQl8Ha3tkav0/NQ5+Vz7WEc9cv56aXXL+fHxfuGr3Yf6zl1JS0nzeftues5dTuqyPNz95zCycaKrnUqGbXOxXG2k2FvI+PGg4JvunwNRDzKJ8Dz2Q8TCwWYySFLpb2KMpODj5ucm1H6Z4GbUaXb7tPkqdVERlwjtFp9vfTQ6vWIuH7RaK+Tm5tDfn4eNnamCejUajW3b9+iRk39oZaaNWpy7dq1Z9qGRqMhOzsbOzs7Xdpff52kQsUKzJo1kz69ezH83aGsXr2K/JLObC/I0QZsrWTcjSm4os7XQGQ8lDFyh4flP71jxj4BO9qAnZWMO4XacD9Ooozbi19Rt6sl59Yjibuxr1avA2jnPBjr8b+o1Jc+Dx48YPbs2Rw/fpyYmBhkMhkeHh40aNCAYcOG4evra4p6vhClhyuq2AS9tNy4ROTm5li4OqGKiUfp6YoqNlEvjyo2EaWnm9Hrk5KeSb5Gg7ODnV66i4MdiamGu/sjo+OYuWoL88Z/iMLMBH2TzyE5M5t8jYSLnbVeuoutNQnpWQbLuNnZ8FX3FoT6uJObl8/Wc9d5Z94GFgzrRtg/8yTO333EhtNXWDOyt8nb8JidtfYAzyhU7YxscCrF8EL7euakZkrceqANFmwsZZjJZaRn6X85pmdLutc0hoz0ZDSafOwd9eeN2Du4kJaSWEyp0lv/xwwcnd2pWLWu0bb5pLS0NDQaDY6O+pfQjk5OJCeXPKT32Ib1f5KTk0Pjxk10aTEx0cRejKVZ8+ZMmPg1jx49ZPasmeTn59O7dx+jtuExG0vtv5k5+umZORIONjLAeCfMltXkRMVLJc6leB62Vtp/M4q0ARxsXmzblfxkeDnJmL/LdAHci/hfHW4wllIFD0ePHqVdu3b4+voSHh5OeHg4kiQRFxfHxo0b+fXXX9mxYwcNGzYscTsqlQqVSqWXppY0mMtM2BFS+PfRZbKi6YbylPC76i9Khv7OKSFhaHfN12j4YuZS3uneDn8vd5PV53kVrrNE0bY9FuDuRIB7wYmhWoAXMSnpLDl0jrAgHzJzcvl85W7Gd2+Jk42Vyepco6wZ3Zta6P5esE31T92Lft7Pugc0q66gRoiC2ZtyyHvK96GsNBsuDVnRfapw2vPauWExp47uZMyk3zG3UBplm8UpXGVJkpA9QzsOHjzA8uXL+PKr8Tg6OurSNRoJR0dHPvjgQ8zMzChbtixJiYn8+ec6owUPlfxktA0rqOOao9oAsvDHLDNu3EB4TRlujrBs/4tPNKzsL6ND7YLv4ZWH/tmRDdT3RZpgbw3hYXJWHMgn/9WYHymUUqmCh5EjRzJkyBCmTp1a7PMfffQRp0+fLnE7kydPZuLEiXppb8qc6WNmmslLqtiEIj0IFm7OaNRqchNTtHliElB66r++0t25SI+FMTjaacf4E1P1LxOSUjOK9EYAZGXncO1OJDfvPeCnxesA0EgSkiRRr+9H/Dp2uMEJlKbmZGOFmVxWpJchKSMLF7tnP/FX9fdi27nrAEQlpvIoOY0Ri7bontf8E8DV/PRXNn3cD18DkytL6+q9fKbEFlxOKf7pzLGz1u8lsLWi2ElrT2paTUHLmubM3aIiOqkgf2aORL6maC+DrZXsqRPJSsPWzgm53Iy0ZP1ehvTUJOwdiq5iKa3dG5ey488FjJwwp9jJlcZgb2+PXC4nOTlZLz01JaVIb0Rhhw8dYsb0aXw29nNq1NAf9nB2dsZMYYbZE712vr5+JCcno1arMTcvYVbsM7r1SOLRE5/948n6tpb6vQ/WShmZKuN89q1ryCjrLWPZAQ3p2S++vZsPJR4mFkS+isdtsNLvfbCxLNqjUhpeTjJsLWUMaVPwecjlMvzdoXZZM75bk2/K67ZnIu4wWbJSBQ+XL19m2bJlxT4/dOhQ5syZ89TtjB07llGjRuml7XcOK01VSiXl5AXcO+gvWXRr3YjUs5eR8vIASD55AdeWDbk7fYkuj2urRiSfOG/0+pgrFFQI9OWvv2/QvHY1Xfqpy9dpElalSH4bK0tW/vCZXtq6PUc5c+Um3380CB83F6PX8VmYK8yo6OPOyVuRtKxSsMT05M1ImlV69olo1x/G4Wqn7QMNdHdi3Wj9K8GZO0+Qqcrlk85N8XQsGlw9D5UaVGr9b6e0TIlyZcx4lKDdJ8zk2tUU206qS9xWs+rawOH3bSoexOtfRuVr4GG8hnJl5Fy+W/ClXK6MGZfvGa+7VmFujl9wRa5ePEmNei106dcunqRanWYvtO1dG5ewbd18PvpyJgEhpp2DYm5uTkhIWc6fP0+DBgU9mOfPn6devXrFljt48ADTp03lk08+o06dokMqoaGhHDx4AI1Gg/yfybkPHz7E2dnZKIEDQG4e5Gbop2VkSwR4yIhN0e5rcjn4ucGBkucTP5PwGjLK+chYflBDauaLbw8MtyE9WyLQU0ZMckEb/N1l7Lvw/F0Gd2Ml5mzP00t7ra4ZCWkSx69pXnrgACCT/7+YEvjcShU8eHl5cfz4ccqXL2/w+RMnTuDl5fXU7SiVSpRK/W7P0gxZmNlYYxNSMEnPOrAM9tUqkJuUSk5UNOW/GYWljwcXB2rvgXB/3ir8h/eh4k+fEbVgDY71auA7sBvn+47WbePeb0upt38ZQWPeJnbLPjw6tcS1ZX1ONDPNuHvv9s0ZP+sPQoN8qVI2kA37jxOTkEy3lo0A+G3VZuKTUpk4vB9yuZwQX/3lis72tlhYmOulq/PyuPMgRvf/+KRUbtx7gLWlEl8TzN0A6NekBuNW7Sa0jDvV/L3486/LRKdk8EZ9bRA0ffsx4lIz+fZN7bLYZUfO4+1kT7CHC+r8fLadu87evyP4pX97AJTmCsp66gdDdpbafaVwurEduaSmZU1zElIlElI1tKhpTm6exPlbBV9yvVpYkJopseMvbUDRrLqCtnXMWb43l+Q0DY87XFRq7RcxwKGLebzZ0oKoeA33YzTUC1XgaCfj5JW8wlV4Ia079WXhjC/wDwkluHxVDu9eT1JCDE3DuwOwftkMUhLjGPThN7oyUXdvaOubk0V6WjJRd29gplDg7asNBnduWMzmlbMYPPI7XNy9SU3W9sQpLa2xtLLGFF5/vSu//PITZcuWpUKFiuzcuYP4+Djat+8AwOJFC0lMTGT0GO09KQ4ePMCUX37mnaHDKF+hAklJ2rkRSqUSGxttUNq+Q0e2bNnM3LlzeK3Tazx89JA1a1bR6bXOJmnDY6dvSTSoKCM5QyIpXbvsUZ0PVyMLzo4d68hIz4ZDfxecnF3/WWltJtde9bs7gjpPu/wRoE1NGaF+MtYd05CbVzC/QqXmqUNmpXXqhoZGoXKS0jUkpUs0CpWjzoPL9wva0LmenPRs7dLMx21we6INdlYyPBwlcv9pQ24exKfqv05unnbCZ+F04dVUquBhzJgxDBs2jLNnz9K6dWs8PDyQyWTExMSwZ88e5s+fz7Rp00xU1QIOYZWpv+8P3d+hP38OQNTS9VwaPBallxtWvgVBTPa9B5zu9A6hv4zF/90+qB7FcWXkt8Rs2K3Lk3ziPOf7jKL8xI8oP3EEWRFRnO89kpRTRrhEMCC8fk1SMzKZv34XCSmpBJfxYtonw/By03YxJ6SkEZOY/JSt6ItPTqXv5z/q/l62bT/Ltu2nZsUQ5n45wqj1f6xt9XKkZuUwb+8p4tMyCfF0Yebg1/B20n5zJKRlEZNSMAlUnadhytajxKVmoDRXEOzpwm+DXqNxxQCT1K80DlzIw1who2tjC6yUEBmn4fetKlRPdDw42cr0rooaVFKgMJMxoI1+MLz7tJrdZ7QFL0bkY2OppnWYOfY2MmKSJBZsU5GcYdzLq9qN2pCZnsq2NfO0N4nyC+GDcb/i4q4NMFOTE0hKiNEr8/XoXrr/34+4xqkjO3Bx82Ly3O0AHNq5hrw8NXN/0r95VMceQ3mt1zCj1v+xJk2bkpaexsoVy0lKSsY/wJ+JE7/G3cMDgKTkJOLjC+75sHPHdvLz85k9ayazZ83Upbds1YpRo8YA4ObmxtfffMvv8+bx3nvv4uLiymudu9C9+xsmacNjJ69LKMygTU05lhbwKBFWHdLoAksAe2sZ0hM7lZ0lDA4v6M6vV0FGvQraFQ4rDmpPzjVDtBdbfZvrT57eekq7hNOYjl+TUJhJtKslx+qfm0QtP5hfchus4J12BaeXBhVlNKgo516sxB/7X80JkoX9r66SMBaZJJWug2j16tVMnTqVs2fP6pY5mZmZERYWxqhRo+jRo8dzVWSbueHejP+SxidnvOwqGIXFw9tPz/Qf8MXDgS+7Ci+sU5On5/kv8LGMfdlVeGFrz/o9PdN/QF7+KzAmYARfvmnae9lcCG9stG1V333EaNt6VZT63e/Zsyc9e/ZErVaTkKDtwnR1dTXauKEgCIIgCK+25w7dzM3Nn2l+gyAIgiD814hhi5L9J38YSxAEQRBMSay2KJkIHgRBEAShENHzUDIRWgmCIAiCUCqi50EQBEEQChG/bVEyETwIgiAIQiFi2KJkYthCEARBEIRSET0PgiAIglCIWG1RMhE8CIIgCEIhYtiiZCK0EgRBEAShVETPgyAIgiAUInoeSiaCB0EQBEEoRAQPJRPDFoIgCIIglIroeRAEQRCEQsRqi5KJ4EEQBEEQChF3mCyZCB4EQRAEoRAx56Fkol9GEARBEIRSeWV6HhqfnPGyq/DCjtQb8bKrYBS2F86/7CoYRfbN3JddhRfmr4x72VUwike5Xi+7Ci8swOd/41pLpRZX1M/iZc55mDVrFj/99BPR0dFUqlSJadOm0bhx42LzL1++nB9//JFbt27h4OBA27Zt+fnnn3FxcTFZHf83jgZBEARBMCKZXGa0R2msXr2ajz76iHHjxnH+/HkaN25Mu3btiIyMNJj/6NGj9O/fn8GDB3PlyhXWrl3L6dOnGTJkiDHehmKJ4EEQBEEQXhFTpkxh8ODBDBkyhIoVKzJt2jR8fX2ZPXu2wfwnT54kICCAESNGEBgYSKNGjRg6dChnzpwxaT1F8CAIgiAIhRiz50GlUpGWlqb3UKlURV4zNzeXs2fPEh4erpceHh7O8ePHDdazQYMGPHjwgO3btyNJErGxsaxbt44OHTqY5H15TAQPgiAIglCITC432mPy5Mk4ODjoPSZPnlzkNRMSEsjPz8fDw0Mv3cPDg5iYGIP1bNCgAcuXL6dnz55YWFjg6emJo6Mjv/76q0nel8dE8CAIgiAIJjR27FhSU1P1HmPHji02v0ymP09CkqQiaY9dvXqVESNG8NVXX3H27Fl27tzJ3bt3GTZsmFHbUNgrs9pCEARBEF4VxrzPg1KpRKlUPjWfq6srZmZmRXoZ4uLiivRGPDZ58mQaNmzIxx9/DEDVqlWxsbGhcePGfPPNN3h5mWalk+h5EARBEIRCjDls8awsLCwICwtjz549eul79uyhQYMGBstkZWUhL/QaZmZmgLbHwlRE8CAIgiAIr4hRo0Yxf/58Fi5cyLVr1xg5ciSRkZG6YYixY8fSv39/Xf5OnTqxfv16Zs+ezZ07dzh27BgjRoygTp06eHt7m6yeYthCEARBEAorZo6BqfXs2ZPExEQmTZpEdHQ0lStXZvv27fj7+wMQHR2td8+Ht956i/T0dH777TdGjx6No6MjLVq04IcffjBpPUXwIAiCIAiFvMzfthg+fDjDhw83+NzixYuLpH3wwQd88MEHJq6VPhE8CIIgCEIh4ie5SybeHUEQBEEQSkX0PAiCIAhCIeInuUsmggdBEARBKEQMW5RMvDuCIAiCIJSK6HkQBEEQhELEsEXJRPAgCIIgCIWI4KFk/9ngYe2eIyzbuo+ElDSCfDwZ1b8bNSoEP7XcxRt3GPr1DIJ8vVgx+VNdesSDaOau3c71u1FEJyQxst/r9G7X3GT1d25Ui6DRg3GoWRlLb3fOdBtO7OZ9JZdpXJvQnz/DNrQsqkdxRPwyn8h5q/TyeL4eTrkJH2Id7EdWRCQ3vppK7Ka9JmsHwMEda9i1aQmpyQl4+wbTc9AYyobWNJg3JSmedUumcD/iGnHRkbRo/yY9B3+sl+fInvWcOLiVR5G3AfALrsjrfT4gsGxlk7YDoH0DSxpWtcBaKeNeTD5r9mYRnagpNn+DKhbUrWSBt6t2BDAyNp/NR3K4H5NvMH94HSWdm1ix/6yKPw9kG73+W7ZuY+369SQlJePv58ewd96mSuVKBvMePXacrdt3cOfOHdRqNf7+fvTt3ZtaYQWfXV5eHqvWrGXvvv0kJCZSpowPg996i9q1woxe9yft376WHRv/ICU5AR/fIHoPHk25SjUM5k1JSmDVoqncj7hGbHQUrTr0oveQ0fpt3beFBb9OLFJ23ppjmFs8/TcHnsep/Ss4vnMB6SnxuPuE0PbNz/EvV6vY/PdunGLXqu+Je3gbO0d3GrYbQu3mvXTPxz28xYGNM3h07wqpiY9o02ss9cMHmKTuT5IkiaNbf+PCkdXkZKXhHViN8De/ws27bInlrp/bxeHN00mJj8TRzY+mnUdSvkZr3fPHd8zlxvndJMXcQWFhiU9QDZp3HYOLZ5CpmyQYwX9yzsPuE+eYsnQ9A7uEs+y7T6heIZgPf5hNTEJSieUysrIZP/sPalcqV+S5HFUuPu4uvN+rEy6O9qaquo6ZjTVpl25w5cNJz5TfKqAMtbfMI+noWY7W7sLtH+ZQaeo4PF8v+N13x3rVqbFiKg+Xb+JIWGceLt9EzZXTcKxT1VTN4PTRXaxe9BPtuw3my19WUrZiDWZ88z6J8dEG8+flqbG1d6J9t8GUCSj6OQDcuHyGOo3aMnrS73w6eQnOrl5Mm/guyYlxJmsHQOs6SlqEKVmzL5sfl6eTlqnh/TdsUZoXX6acr4Iz13OZvjqTn1dkkJym4f3utjjYFr1q8fM0o2E1Cx7EGQ4sXtTBw0eY8/t83uzZg1kzplO5ciW+GD+BuDjD79vfV65Qs0Z1vp44nt+mT6Nq1aqMn/Q1tyMidHkWL13G9p07GT5sKL/PnkWHdu2Y9O13enmM7a+ju1mx8Bc6vjGIiVOWUy60BlO+HkFivOGfJM5T52Ln4ETHNwbhG1D8Cc3K2oZpi3bqPUwVOFw+tZ2dKyfTuOMwhk3YgF/ZWiyb+g4piY8M5k+Of8DyqUPxK1uLYRM20LjjUHas+JarZ3bp8qhzc3By86VV99HYOriZpN6GnNz1O6f2LiK811e8NXYdNvaurJo2EFVORrFlHkScZ+PvI6lctzODv9xE5bqd2TjvIx7evajLE3nzFGHN+tD/szX0+nARGk0+q6YPJleV9W806+nkcuM9/gf9J1u1YvsBOjerR5fmDQj08WR0/254uDixbu/REst9N381bRrUokrZgCLPVQr258M+XQhvEIaFwvQdMvG7DnNz/DRiNu55embA/51e5ERGc3X0d2Rcv0PUwnVELV5P0KhBujyBHwwgYe9xIn6cR+aNO0T8OI+E/ScJ+MB0Vyd7tiyjUcsuNG7dFa8yQfQc/DFOLp4c2rXWYH5Xd296Df6E+s07YWVtazDPkJHf0axdD3wDy+NVJpD+736JJElcv/SXydoB0Lymkl1/5XDxlproBA1/7MjCQiGjdkWLYsss3p7FkQu5PIjPJzZJw/Ld2chkUN5Pfx9SmsNb7a1ZsSubLJVpfqxm/YaNtAlvTbs2bfDz8+Xdd97GzdWVrdt3GMz/7jtv06N7N8qXK4ePjzeDBvTH29uLk3+d0uXZd+AAvXr0oE7tWnh5edKpQ3vCatbgz/UbTdIGgN2bltOkVWeatu6Ct28gvYeMxtnVg/071xnM7+rhTZ8hY2jYvGOx+5SWDAcnV72HqZzYtZiajbsR1uQN3LyDadf7cxycPTlzYKXB/GcOrsLBxYt2vT/HzTuYsCZvUKNxV47vWqjL4xNYhfAen1ClbgfMFCVEtEYkSRKn9y2lQbthlK8ZjptPOTq+9QPq3ByuntpabLkz+5YQWLEBDdoNxcUzmAbthuJfoR6n9y3R5en14QKqNuiKm3dZPHwr0HHAZNKSHhFz/8q/0bSnkslkRnv8L/rPBQ/qvDyu342ibtUKeul1q1Tg0s27xZbbfPAkD+ISeLtbW1NX0SQc61Unfu8xvbT43UdwCKuM7J9gx6ledRIKBVAJe47gVN9wd++LylOriYy4Rmi1+nrpodXrEXH9YjGlSi83N4f8/Dxs7ByMts3CXBzkONjKuXYvT5eWlw+3H+QR6PPswaSFAszkkJWjHyD0aGXNlTtqbkTmFVPyxajVam7dvk1YDf3POqxmDa5eu/ZM29BoNGRnZ2NnZ6e3XQtz/ROV0kLJlatXX7zSBuSp1dyLuE6l6vX00itVr0fE9UsvtG1VTjZj3u7IqMHtmfbNR9y/c/2FtlecvLxcHt2/QnClhnrpwZUaEnX7vMEyUREXiuQPqdSIR/eukJ+nNkk9n0VKwgMy0+IJDG2kS1OYW+BXrjYPIgy3BeDhnQt6ZQCCKjXmYQllcrLTAbCyMd1xLhiP0YOHqKgoBg0aVGIelUpFWlqa3kOVm/tM209JzyRfo8HZwU4v3cXBjsTUdINlIqPjmLlqC1+/1x/FPz9V+l+j9HBFFZugl5Ybl4jc3BwLVydtHk9XVLGJenlUsYkoPU3TxZmRnoxGk4+9o7Neur2DC2kpicWUKr31f8zA0dmdilXrGm2bhdnbaK8O0jP15zekZWqwt372K4fOTaxIzdBw/X5BkBBW3hxfdzM2HckxTmUNSEtLQ6PR4OjoqJfu6OhIcnLKM23jzw0byclR0bRxwZd+WM0a/LlxIw8fPkKj0XD2/HlO/HWSpKSShwifV3p6isF9ysHBmdTkhGJKPZ1XmQAGjxjPiM+nMGzUt5ibW/DdZ4OJeRT59MKllJWejKTJx8bBRS/dxt6FjFTDbchIjcfGvlB+Bxc0+XlkZSQbvY7PKjMtXluXwnWzcyUzrfjPIyMtoWgZexfd9gqTJIl9aydTJiQMNx/Dw5n/tpfxk9z/JUZvVVJSEkuWLCkxz+TJk3FwcNB7TFm0ulSvI0P/C11CwtBXfL5Gwxczl/JO93b4e7mX6jVeOYV/m/1xd9iT6YbymPA33fXq8bgKSEb7RbqdGxZz6uhO3v3kZ6OOT9euaM6UEQ66h9k/R0Lhd6o0zWhVW0mtCubM25RJ3j/TGhztZHRvYcWS7QVpplS4i1SSJAweGIUcOHiIP5av4PNPP9ELQN4d+g4+3t4MGfYuHTq/zqzZcwlv1Qq5mWm/EA0d3y+yTwWXr0KDZu3xCyxHuUo1ePfj7/Hw9mffttJ975RG4TYgUWIbinRvS7onjFqvklz+azM/j6ihe2jy8wzWTSpypBhiYF8sZmfcvXIS8Q9v0nnIlOeptknI5DKjPf4XlXpwf/PmzSU+f+fOnaduY+zYsYwaNUovTXXl0DO9vqOdDWZyOYmpaXrpSakZRXojALKyc7h2J5Kb9x7w02LtmKlGkpAkiXp9P+LXscMNTqB81ahiE4r0IFi4OaNRq8lNTNHmiUlA6ak/jqt0dy7SY2EstnZOyOVmpCXr9zKkpyZh7+BcTKlnt3vjUnb8uYCRE+YUO7nyeV26reZedEFPleKfDil7GzlpmQVneTtrOWlZT/+ibFlLSZu6lvy6NoNHCQW9F34eCuxt5Hzar2DfNJPLCCljRtMaFnw4NdUosZ29vT1yuZzkZP2r1NTUVJwK9UYUdvDwEabOmMG4zz6jZo3qes85Ojgw4csvyM3NJS0tHRcXZxYsWoKHh8eLV9oAOztH5HIzUgv1XKWlJuPg6FJMqdKTy+UElg0lNjrKaNt8zNrOCZncrEgvQ2Z6Irb2httg6+BWNH9aInIzBdY2jkavY3HKVmuBd2A13d/5edoe4YzUBGwdCi6+stITsbEvfs6IrX3Rnoms9CSDZXav/Jpbl/bTd8wy7J08X7QJxvM/2mNgLKUOHrp06YJMJvsnijTsaRNElEolSqX+VWSaRfGT0p5krlBQIdCXv/6+QfPaBTv5qcvXaRJWpUh+GytLVv7wmV7auj1HOXPlJt9/NAgfN+N9IZlSyskLuHfQXzrq1roRqWcvI+Vprw6ST17AtWVD7k4v6PlxbdWI5BPFjzO+CIW5OX7BFbl68SQ16rXQpV+7eJJqdZq90LZ3bVzCtnXz+ejLmQSEGF5q+CJUaohP0R+iSM3QUMFfoVsNYSaHkDIKNh0ueUllq9pK2taz5Ld1GUTG6ncv3Liv5pvF+oFuv7bWxCZq2H06x2idQubm5pQNCeHc+fM0bFAwB+Xc+QvUr1f8cM+Bg4eYMn0GYz8ZQ906tYvNZ2FhgaurC3l5eRw9fpwmjRsVm/dFKMzNCQiuwJULfxFWr2B/v3rhL6rXbWq015Ekici7Nynj//Tl3aWlUFjg7V+JiKvHqRhWsDQx4spxKtRoYbCMb3B1blw4oJcWceUY3gGV/rXJkQBKS1uUlgWTTiVJwsbejXvXjuHpFwpoA4rIm6dp3nVMsdvxCarO3WvHqNPqLV3a3atH8QkumJMjSRK7V33NzQt76DPqDxxdfY3fIMFkSh08eHl5MXPmTLp06WLw+QsXLhAWZto14L3bN2f8rD8IDfKlStlANuw/TkxCMt1aar/Qflu1mfikVCYO74dcLifE11uvvLO9LRYW5nrp6rw87jyI0f0/PimVG/ceYG2pxNcEcwbMbKyxCfHT/W0dWAb7ahXITUolJyqa8t+MwtLHg4sDtfeiuD9vFf7D+1Dxp8+IWrAGx3o18B3YjfN9C9az3/ttKfX2LyNozNvEbtmHR6eWuLasz4lmvY1e/8dad+rLwhlf4B8SSnD5qhzevZ6khBiahncHYP2yGaQkxjHow290ZaLu3gBAlZNFeloyUXdvYKZQ4O2r/SLfuWExm1fOYvDI73Bx99aNdSstrbG0sjZZWw6cU9GmriXxyRriUvJpU9eS3DyJ09cK5uP0b2dNSoaGzf/MX2hVW0nHhpYs3pZFUmrB/AiVWkKl1gYp0Qn6QYpKDRk5UpH0F9X19S789MsUypUtS8UKFdi+cydx8fF0aN8OgIWLl5CQmMgno7W9fgcOHuKnKVN59523qVC+AklJ2l4LpdICGxsbAK5fv0FCYiLBQUEkJCaybMUKJI2GHt26GrXuTwrv3Iffp31FQEhFQspX5dDu9SQmxNC8TTcA1v7xGymJcbz9UcEy58g7j/epbNLTkom8cwMzc3N8fLX3DNi4ah7B5avg4eVLTlYme7atIuruDfq984lJ2lC/zVus//1TvAMq4xtcnbOH1pCaFE2tZtr7Nuxd9wtpyXF0ffsHAGo168WpfcvZuWoyYU16EBVxgXNH/qT70J9128zLyyX+kXaJbH6emvSUWKIjr2GhtMbFw98k7ZDJZNRu2Z/jO+bi5B6As7s/x3fMxdzCktA6HXX5tiz6BDtHD5q9rv0+qtWyP8t+7suJnfMoV70lNy/s4961E/T9ZIWuzK6VE7l6aivdh8/CwtKGjFTtfAillR3mFpYmaU9p/K8ONxhLqYOHsLAwzp07V2zw8LReCWMIr1+T1IxM5q/fRUJKKsFlvJj2yTC83LRd5QkpacQklm6SUXxyKn0//1H397Jt+1m2bT81K4Yw98sRRq0/gENYZerv+0P3d+jPnwMQtXQ9lwaPRenlhpWvl+757HsPON3pHUJ/GYv/u31QPYrjyshvidmwW5cn+cR5zvcZRfmJH1F+4giyIqI433skKadebJZ6SWo3akNmeirb1szT3iTKL4QPxv2Ki7s2MEtNTiApQX99/tejC258cz/iGqeO7MDFzYvJc7cDcGjnGvLy1Mz9Sf/mUR17DOW1XsNM1pY9p1SYK2T0bGWFtaWMe9H5/LYuA9UTk92d7OV6vQVNqisxV8h4u7ON3ra2Hc9h+3HTTZA0pFmTxqSnpbF85SqSkpLw9/fnm4nj8XDXdjcnJSURH18wYW37zp3k5+fz2+w5/DZ7ji69dcsWjBk1EoBcdS5L/lhGdEwMVlaW1K5Vi09Gj8LWtqQlkS+mbqNwMtNS2bx6PqnJCfj4BTPyy+m4umuPh9SkhCL3fBg/qo/u//cirnHy8E5c3Lz4+fctAGRnprNk1rekJidiZWOLX2B5Pvv2d4LKmebGY5XrtCcrI4VDm2eSkRqPu09Z+nw0F0dXHwDSU+NJTSq454OTWxn6jJzLzpXfc3r/Cuwc3WnXexyhtdro8qSnxDF3wuu6v4/vXMjxnQvxL1+bgZ8WfJcYW702b5OnVrFrxURyslLxDqxGrw8X6vVQpCVFI5MVdPOXCa5JlyFTOLRpGoc3z8DJzZcub0/F54khkfOHtMtWl//ST+/1OgyYTNUGpgtOn9WT7RGKkkmlPNMfOXKEzMxM2rY1vOQxMzOTM2fO0LRp6boY087uenqmV9yResYPMl4G2wumGeb4t63Z8WwreF5lH3cx7Y2x/i2P1F5Pz/SKu59kuoDp36RS/29cUb/VzLTbT/72XaNty2ncbKNt61VR6p6Hxo0bl/i8jY1NqQMHQRAEQXiliGGLEv1nf9tCEARBEEzlf/X+DMYi3h1BEARBEEpF9DwIgiAIQiFitUXJRPAgCIIgCIWJ1RYlEu+OIAiCIAilInoeBEEQBKEQMWxRMhE8CIIgCEJhYrVFiUTwIAiCIAiFPO03mv6/E6GVIAiCIAilInoeBEEQBKEwMWxRIhE8CIIgCEIhYsJkyURoJQiCIAhCqYieB0EQBEEoTNwkqkQieBAEQRCEwsSwRYlEaCUIgiAIQqmIngdBEARBKEQmhi1K9MoEDxYPb7/sKrww2wvnX3YVjCKjeo2XXQWj6Pf3qZddhRe29365l10Fo+js+dfLrsILi7Oo9bKrYBR/nct+2VUwjma2pt2+GLYokQitBEEQBEEolVem50EQBEEQXhUycZOoEongQRAEQRAKE79tUSIRPAiCIAhCYaLnoUTi3REEQRCEV8isWbMIDAzE0tKSsLAwjhw5UmJ+lUrFuHHj8Pf3R6lUEhwczMKFC01aR9HzIAiCIAiFvaRhi9WrV/PRRx8xa9YsGjZsyNy5c2nXrh1Xr17Fz8/PYJkePXoQGxvLggULCAkJIS4ujry8PJPWUwQPgiAIglDIy5owOWXKFAYPHsyQIUMAmDZtGrt27WL27NlMnjy5SP6dO3dy6NAh7ty5g7OzMwABAQEmr6cYthAEQRAEE1KpVKSlpek9VCpVkXy5ubmcPXuW8PBwvfTw8HCOHz9ucNubN2+mVq1a/Pjjj/j4+FCuXDnGjBlDdrZp7+chggdBEARBKEwmN9pj8uTJODg46D0M9SIkJCSQn5+Ph4eHXrqHhwcxMTEGq3nnzh2OHj3K5cuX2bBhA9OmTWPdunW89957JnlbHhPDFoIgCIJQmBHvMDl27FhGjRqll6ZUKovNLys030KSpCJpj2k0GmQyGcuXL8fBwQHQDn10796dmTNnYmVl9YK1N0wED4IgCIJgQkqlssRg4TFXV1fMzMyK9DLExcUV6Y14zMvLCx8fH13gAFCxYkUkSeLBgweULVv2xSpfDDFsIQiCIAiFyGRyoz2elYWFBWFhYezZs0cvfc+ePTRo0MBgmYYNG/Lo0SMyMjJ0aTdv3kQul1OmTJnna/wzEMGDIAiCIBQmlxnvUQqjRo1i/vz5LFy4kGvXrjFy5EgiIyMZNmwYoB0C6d+/vy5/7969cXFxYeDAgVy9epXDhw/z8ccfM2jQIJMNWYAYthAEQRCEV0bPnj1JTExk0qRJREdHU7lyZbZv346/vz8A0dHRREZG6vLb2tqyZ88ePvjgA2rVqoWLiws9evTgm2++MWk9RfAgCIIgCIWVYrjB2IYPH87w4cMNPrd48eIiaRUqVCgy1GFqIngQBEEQhMLED2OVSAQPgiAIglCY+GGsEv1ng4fVxy+x+OA5EtIzCfZw5pPXmlAzyMdg3tMRDxgyZ32R9I0f9yXQ3blI+o4LN/ls+U6aVwpi2lsdjV73xw7uWMOuTUtITU7A2zeYnoPGUDa0psG8KUnxrFsyhfsR14iLjqRF+zfpOfhjvTxH9qznxMGtPIq8DYBfcEVe7/MBgWUrm6wNzo1qETR6MA41K2Pp7c6ZbsOJ3byv5DKNaxP682fYhpZF9SiOiF/mEzlvlV4ez9fDKTfhQ6yD/ciKiOTGV1OJ3bTXZO0A2Ld9Hds3/EFqciLefkH0GTyS8pVqGMybkpTAykXTuHf7OrHRUbTu2JM+Q0YVyZeZkc6fy2Zz5uQBsjLScfXw5s2BH1KtVkOTtUOSJI5v+42Lx1ajykrDK6AarXp+hat3yUu2bpzfxbEt00lJiMTR1Y9Gr42kXPXWBvOe3DmXI5unENa8Py3eGGf0NqzfsZeVm7aTmJxKgK8PHw7qQ7XQ8gbzXrx2gzlL13D/4SNycnPxdHOlc3hzenZqq8uzff8Rvvvt9yJl962aj9LCwuj1BzixZyWHti8kPSUeD58QOvX9jMAKtYrNf+faabYu/4HYh7exd3SnacdB1GvZS/f8mcMbWDuv6Hv9zcLzmFs8fRngi2hbx4L6lRRYWcqIjNGw7pCKmCRNsfnrVVJQu4I5Xs7aE3BUfD7bTuQSGVtQplWYOVWDFbg7yVHnSdyL0bDlmIq4FMmkbRGM4z8ZPOy8cJMfNx9m3OvNqB7gzbqTlxm+YDMbxvTFy8mu2HKbPumHrbLgi8LJtuhM1EfJaUzZeoSagd6mqLrO6aO7WL3oJ3q/PZaQitU5vOtPZnzzPhOm/4mLm1eR/Hl5amztnWjfbTB7ty43uM0bl89Qp1FbgitUQ2Fuwa6NS5g28V0mTP8TJxd3k7TDzMaatEs3eLBkPWFrf3tqfquAMtTeMo+oBWu5MOBjnBrUpPKv48mNTyJmw24AHOtVp8aKqdwcP52YTXvx7NyKmiuncaJZb1JOXTJJO/46soflC6bQf+gnlKtYjQO7NvDLpI+Y/NtqXNw8i+RXq3Oxs3ei0xsD2bV5pcFt5qnV/DT+fewdnHn/0+9xdnEnKSEWSytrk7ThsVN7fufM/kW06/c9Th4BnNwxmzW/DmTI+J1YWNoaLPPwznm2LBhJo44fUrZ6K25d2MuW+R/x5ugVeAdW08sbfe8Sl46txs3H8Mn8Re07epIZi5Yz+u0BVKlYlk27DjDmm5/5Y/pkPN1ci+S3Uirp2r4Vwf6+WFkquXTtJj/NWYSlUknn8Oa6fDbWVqz49Qe9sqYKHC6e3MGWZZPp8tZX+JerwV/717Dwp6GM+mELTq5Fv1uS4h6w8Odh1GnWnZ7v/sD9m+fZuHgSNnbOVKlTcKtipZUtH/+0Ta+sqQOHljXNaVbDnBV7c4hLlgivbc67nS35blkWKrXhMiE+Zpy7qeZetAZ1vkTLmha829mK75dnkZqpDQ6Cfcw4eklNZJwGuRw61LNg2D95ck37m07P5iXOefgv+E++O38cPs/rtSvRtW5lgjyc+aRzEzwdbVlzouQTi7OtNa72NrqHWaFuqXyNhrErdvFueD3KODsUsxXj2LNlGY1adqFx6654lQmi5+CPcXLx5NCutQbzu7p702vwJ9Rv3gkra8MngCEjv6NZux74BpbHq0wg/d/9EkmSuH7pL5O1I37XYW6On0bMxmebrOP/Ti9yIqO5Ovo7Mq7fIWrhOqIWrydo1CBdnsAPBpCw9zgRP84j88YdIn6cR8L+kwR8MMBUzWDnphU0afUazcK74O0bSJ8ho3B29WDfjj8N5nfz8Kbv26Np1KID1jaGP4/DezeTkZHGiM9/olzFari6e1EutDp+geVM1g5Jkji7fyn12g6jXI1w3LzL0a7/D+Tl5nD19NZiy53dv4SACg2o13YoLp7B1Gs7FL8K9Th7YIlevtycTLYt/pjwPt9gaW2aY2TVlp10bNmUTq2bEVDGhw8H98XdxZmNu/YbzF8uKIDWjesT5FcGL3c32jRtSJ3qVbh07YZePhkyXJwc9R6mcmTHYmo360ad5t3x8AnmtX5jcXDx4uS+VQbzn9y/GkcXL17rNxYPn2DqNO9OraZdObx9kX4bZDLsHN30HqbWpLo5e07ncikin5gkDcv3qLAwlxFWrvhrz2W7VRz7O4+HCRrikiVW7Vchk0E5XzNdnrmbczh1PY+YJA2PEjSs2JuDs72cMu6vyGnpJS3V/K94RT6lZ6fOy+fawzjql9P/adL65fy4eD+6xLI9p66k5aT5vD13PaduRxV5fu6eUzjZWNG1TiWj1rmwPLWayIhrhFarr5ceWr0eEdcvGu11cnNzyM/Pw8bOtIFQaTjWq0783mN6afG7j+AQVhmZQvtl5FSvOgl7j+rlSdhzBKf6hocQXlSeWs29iOtUrl5XL71y9brcvv78PR3nTx8hpHwVls79kQ/6t+XzD3qxZe0iNPn5L1rlYqUmPiAzLZ6Aio10aQpzC3zL1ubRnfPFlnt094JeGYDAio2LlNm7ehJBlZsSUMHwDWtelFqdx82Ie9Supj/UVrt6FS5fv/VM27h55x6Xb9ymemgFvfTsnBy6vTOS14d8yCff/sLNO/eMVW09eXm5PLx7lbKV9YemylVuwP1bFwyWibx1gXKV9d/TclUa8eDuFfLzCi7vc3OymPxhS779oDmLfn6Xh/euGr3+T3Kxl+FgI+d6ZME+m6+B2w/zCfAyK6GkPguFdgpBZk7xQxJWSu1JNivn+esr/HtKPWyRnZ3N2bNncXZ2JjQ0VO+5nJwc1qxZo3cDC0NUKlWRXxST1GqU5uZPff3kzGzyNRIudvpdvy621iSkZxks42Znw1fdWxDq405uXj5bz13nnXkbWDCsG2H/zJM4f/cRG05fYc3I3k+tw4vKSE9Go8nH3lF/voW9gwtpKYlGe531f8zA0dmdilXrPj3zv0Tp4YoqNkEvLTcuEbm5ORauTqhi4lF6uqKK1X8fVLGJKD1Nc5WVnpaCRpOPg6OLXrqDozOpyc//ecTHPORa3BnqN23DqK+mEvsoiqXzfiQ/P58uvYa8aLUNykyNB8DGTr8t1naupCU9Kr5cWgLW9oXK2LuQmRav+/vamW3ERl2l36frjFhjfanp6eRrNDg76ge8zg72JKakllj29SEfkpKWTr4mn0E9XqdT62a65/x8vPj8g7cJ8vMlKzubtVt38+7n37B4yjf4ehcdlnoRWena/cnWQf/9tHVwIT0lwWCZ9NQEg/k1+Xlkpqdg7+SGm3cQb7zzLZ6+5VBlZ3B01zJmT+rLR9+tx9UzwKhteMzOWntCT8/WP+mnZ0k42z37FXXHBhakZkjcjCo+cO7SSEnEo/wS51L8q8SwRYlKFTzcvHmT8PBwIiMjkclkNG7cmJUrV+LlpR2jT01NZeDAgU8NHiZPnszEiRP10sb1ascXb3Z45roU3m0ltN2ShgS4OxHg7qT7u1qAFzEp6Sw5dI6wIB8yc3L5fOVuxndviZON6e7IVUThHz9BMtryoJ0bFnPq6E7GTPrd5GOipSYVuvp43OYn0w3lKZxmZIXf+pJ+jOZZaCQNdg5ODBz+OXIzMwJDKpKSHM/2DcuMFjxcPbWZ3SvH6/7u9u5c7X+K1FsqetAUUuT4kbRHFUBaUjT7137LGx8sRGFu+v2pyGdB0R8LKmzmt1+QnZPDlZu3mfPHGny8PGjdWNu7V7l8CJXLh+jyVqlQlkFjvuLP7Xv4aEg/Y1cfDNa35P3JUH5tuvYv/5Bq+IcUzD/xL1eTGV9049ju5XTub5xJq2HlFPRoXvD5ztuS/WRVnqhrkaRitahpTs1y5vy2Ppu8YmKHbk0t8HaVM32daX9GulTEUs0SlSp4+PTTT6lSpQpnzpwhJSWFUaNG0bBhQw4ePIifn9/TN/APQ78wJu1Z+ExlnWysMJPLivQyJGVk4WL37Cf+qv5ebDt3HYCoxFQeJacxYtEW3fOaf05UNT/9lU0f98PX1fGZt/00tnZOyOVmpBW6qk1PTcLeoejqj9LavXEpO/5cwMgJcygTYLrx9eehik0o0oNg4eaMRq0mNzFFmycmAaWn/sQ4pbtzkR4LY7Gzd0QuNyOl0OeRlppcpHeoNBydXDEzUyA3K+je9SoTSGpyInlqNYpn6Gl7mpCqLfAKKDih5OflAtqeBFuHgkmyWemJ2NgVnWz4mI29K5lp+u9vVnoSNvbaMrGRV8hKT2Tp9111z0uafKJun+bcoeWMmvE3cvmzd2MXx8HODjO5nMRk/V6G5NQ0nB3sSyzr7aHdr4L9fUlKSWPh6g264KEwuVxOxZBAoqJjX7jOhVnbafenwr0MGalJRXoXHrNzcDWYX26mwNrW0WAZuVxOmaAqJMTcN0q9AS7fzeN+bMEZXmGmPYHaWctIyyoIF2ytZKRnPT18aF7DnNa1LJi1MZvoRMM9Cl2bWFA5UMGv67N1kymFV1+pgofjx4+zd+9eXF1dcXV1ZfPmzbz33ns0btyYAwcOYGNj80zbMfQLYznP+EVqrjCjoo87J29F0rJKsC795M1ImlUKeua2XH8Yh6udtr6B7k6sG91H7/mZO0+Qqcrlk85N8XQsfgXH81CYm+MXXJGrF09So14LXfq1iyepVqfZC21718YlbFs3n4++nElAiGnnbjyPlJMXcO/QXC/NrXUjUs9eRsrTTrFOPnkB15YNuTu9YLKea6tGJJ8ofsz+RSjMzQkIrsCVi6eoVb+gblcunKJG3SbPvd2yFatx8vAuNBoN8n8m58Y+isTRydUogQOAhaWt3goKSZKwsXfj3rVjePhqhxXz83KJunWaJl3GFLsd78Dq3Lt+jFot39Kl3bt2FO8g7TwT/wr1eOuLLXpldi4di7NnEHXC3zZK4ABgbq6gXHAApy9epmm9gmWNZy5eplEdw8uYDZIk1Orip+xLksStu5EE+Rv/h4MUCgt8AkO5dfk4lWu30qXfunyc0LAWBsv4la3OtXMH9NJuXT5GmcBKmCkM7yuSJBF9/zqevsb71USVGlSpT57AJVIzNZT3M+NhgvbkbybXrqbYckxleCP/aF7DnPDaFszZlE1UnOHAoVtTC6oEKfhtfTZJaa9Y4CDu81CiUgUP2dnZKBT6RWbOnIlcLqdp06asWLHCqJUrTr8mNRi3ajehZdyp5u/Fn39dJjolgzfqVwFg+vZjxKVm8u2b2iVOy46cx9vJnmAPF9T5+Ww7d529f0fwS//2ACjNFZT11L8isLPUBjeF042ldae+LJzxBf4hoQSXr8rh3etJSoihaXh3ANYvm0FKYhyDPiy4P3nUXe3scVVOFulpyUTdvYGZQoG3rzaI2rlhMZtXzmLwyO9wcfcmNVl7JaO0tDbZ8kAzG2tsQgp6nawDy2BfrQK5SankREVT/ptRWPp4cHHgpwDcn7cK/+F9qPjTZ0QtWINjvRr4DuzG+b6jddu499tS6u1fRtCYt4ndsg+PTi1xbVmfE81MNx+lbefezJ02nsCQioSUr8KBXRtITIihRVvtlfaapTNJToxj6MiC4bb7d24CkJOdRXpqMvfv3EShUODjpw1iW7Ttxt6ta1g+/xdad+hBTHQUW9YupnXHHiZrh0wmI6xFf/7aNRcn9wCc3P35a+dcFBaWhNYuuGfJtsWfYOfoQZMu2vc9rHl/Vk7ty1+75xFStSW3L+3j/vUTvDlae0xbWNri5q3fi2WutMbKxrFI+ovq1aktX8+YS4WQQCqXD2Hz7oPEJiTSJVx74p2zbA3xicl8+eFQAP7csRcPVxf8fbTDp5eu3WTl5h10a19wj4qFqzdQqVwwZbw8tXMetu3m1r1IRr1T8hDr82rc7i1Wz/6UMkGV8AupzqkDa0lJjKZey54A7Fg9hbTkOHoO+x6Aei16cnzPCrYs+4E6zbsTefsCpw/+yZvv/azb5p71M/ELqYarpz+q7AyO7VrGo8jrdHnrC5O04bHDF9S0rmVBfIqG+BSJ1rXMyVVLnL1ZEJz1aa0kNUNi6wltz1eLmua0r2fB0l05JKVLurkTKrVE7j/zP7s3VRJWXsH8rdmo1AXzK3JUEmrTzSl+dmLYokSlCh4qVKjAmTNnqFixol76r7/+iiRJvPbaa0atXHHaVi9HalYO8/aeIj4tkxBPF2YOfg1vJ223ZkJaFjEp6br86jwNU7YeJS41A6W5gmBPF34b9BqNKwb8K/U1pHajNmSmp7JtzTztTaL8Qvhg3K+4uGvXgKcmJ5CUoP+b7l+PLrhhzP2Ia5w6sgMXNy8mz90OwKGda8jLUzP3J/2bR3XsMZTXeg0zSTscwipTf98fur9Df/4cgKil67k0eCxKLzesfAvuW5F97wGnO71D6C9j8X+3D6pHcVwZ+a3uHg8AySfOc77PKMpP/IjyE0eQFRHF+d4jTXaPB4C6jVuTkZ7KptULSElKwMc/mFFfTcXV/Z/5PMkJJCXod3F/NbKv7v/3Iq5z4vAuXN29+OX3TQC4uHnw8cQZrFgwjS8+7IOjixvhnXrSoatpTliP1Wn9Nnm5KvaumkhOVipeAdV444OFej0U6cnRyJ64svIJrkmnQVM4umUaR7fMwNHVl06Dpxa5x8O/oWWjeqSmZ7B4zSYSk1MI9CvDT+NG4+muHUJJTE4hNqFgiEnSaJi7bA3RcfGYmZnh4+HOsL499O7xkJGZxY+zF5GUkoqNtRXlgvyZ+c3nhJYNLvL6xlCtXjuy0lPYt2E2aSnxeJYpy8CP5+Lkqp2gnZ6SQEpCweowZ/cyDBozhy3LvufE3hXYO7nzWv/P9e7xkJOVzvoF40lPTcDS2g5v/4oM+2IpvsFVTdKGx/adU2OukNG9mRJrpYz7sRpmb8rRu8eDk60cSSroXWhUxRyFmYxB7fWHknf+lcvOU9oAo1FVbY/KB930L2xW7NEu4RRebTJJevZZaJMnT+bIkSNs377d4PPDhw9nzpw5aDSlny2bs3lmqcu8av4KHviyq2AUGdVNsyTy3+by96mXXYUXdvnhq7PM9kV09jTdvUb+Lceyir875H/JwZOv0KTEFzDtA8P3VzGWnO3zjLYty/bvGG1br4pSDeqMHTu22MABYNasWc8VOAiCIAjCK0UuN97jf9B/8vbUgiAIgmBSYs5Dif43QyJBEARBEExG9DwIgiAIQmHiDpMlEsGDIAiCIBQmhi1KJEIrQRAEQRBKRfQ8CIIgCEJh/6OrJIxFBA+CIAiCUIgkhi1KJEIrQRAEQRBKRfQ8CIIgCEJhYrVFiUTwIAiCIAiFieChROLdEQRBEAShVETPgyAIgiAUIiZMlkwED4IgCIJQmBi2KJEIHgRBEAShMNHzUCIRWgmCIAiCUCqi50EQBEEQChN3mCzRKxM8fPFw4MuuwgvLvpn7sqtgFP3+PvWyq2AUiVXqvOwqvLBd7+982VUwisW3c152FV7Y/GnRL7sKRmHXzPVlV+E/QUyYLJkIrQRBEARBKJVXpudBEARBEF4ZYrVFiUTwIAiCIAiFSCJ4KJF4dwRBEARBKBXR8yAIgiAIhYkJkyUSwYMgCIIgFCKGLUomggdBEARBKEz0PJRIhFaCIAiCIJSK6HkQBEEQhMLEsEWJxLsjCIIgCIVIMpnRHqU1a9YsAgMDsbS0JCwsjCNHjjxTuWPHjqFQKKhevXqpX7O0RPAgCIIgCK+I1atX89FHHzFu3DjOnz9P48aNadeuHZGRkSWWS01NpX///rRs2fJfqacIHgRBEAShMJncaA+VSkVaWpreQ6VSGXzZKVOmMHjwYIYMGULFihWZNm0avr6+zJ49u8TqDh06lN69e1O/fn1TvBtFiOBBEARBEAqRkBntMXnyZBwcHPQekydPLvKaubm5nD17lvDwcL308PBwjh8/XmxdFy1aREREBOPHjzf6+1AcMWFSEARBEExo7NixjBo1Si9NqVQWyZeQkEB+fj4eHh566R4eHsTExBjc9q1bt/jss884cuQICsW/d0oXwYMgCIIgFGLMm0QplUqDwUJxZIUmWUqSVCQNID8/n969ezNx4kTKlSv3wvUsDRE8CIIgCEJhL2GppqurK2ZmZkV6GeLi4or0RgCkp6dz5swZzp8/z/vvvw+ARqNBkiQUCgW7d++mRYsWJqmrmPMgCIIgCK8ACwsLwsLC2LNnj176nj17aNCgQZH89vb2/P3331y4cEH3GDZsGOXLl+fChQvUrVvXZHX9T/c8hNcyp26oGdZKGZGxGtYfySU2WSo2f92KZoSVV+DprI2ZHsRr2PGXmqg4jV6+BpUUNKuuwM5aRmyyxKZjudyN1hjapFG0b2BJw6oWWCtl3IvJZ83eLKITi3+9BlUsqFvJAm9XbTsiY/PZfCSH+zH5BvOH11HSuYkV+8+q+PNAttHrv2/7OrZv+IPU5ES8/YLoM3gk5SvVMJg3JSmBlYumce/2dWKjo2jdsSd9howqki8zI50/l83mzMkDZGWk4+rhzZsDP6RarYZGr79zo1oEjR6MQ83KWHq7c6bbcGI37yu5TOPahP78GbahZVE9iiPil/lEzlull8fz9XDKTfgQ62A/siIiufHVVGI37TV6/Q15o40jrerbYWsl51akivl/JvIgRl1s/jpVrOna2hFPVwVmchkxCWq2HEzj8JkMg/m7tHSgT0dnth1KZfHGJJO0YdCb/rzWxgs7WwVXb6YzZc4t7kZmPVPZlo3dmPhJKIdPJvD5t1f0nnN1tuDdt4KoF+aMUikn6mE238+4wY0Iw219Xtu3bmLDn2tITkrEzz+Awe8Mp1Llqgbznjh2hB3bNnP3TgRqtRo/f3969RlAzbDaBvMfPrSfX374lrr1GvD5V18btd6FHdq5mr2bF5OanICXbzBvvPUJIaE1DeZNTY7nzyW/EHnnKvHRkTRr35s3Bn6il+dR1G22rppF5J1rJMU/ovtbH9OiY1+TtuF5PM/9GYxh1KhR9OvXj1q1alG/fn3mzZtHZGQkw4YNA7TzJx4+fMjSpUuRy+VUrlxZr7y7uzuWlpZF0o3tP9vz0Ly6gibVFGw4omb6nzmkZUm800mJ0rz4MsHeZly4lc+cTTn8uj6HlHSJdzoqsbcp2EmqBZvxWkNz9p5TM3VtDnei8xnSQYmjrWl2pNZ1lLQIU7JmXzY/Lk8nLVPD+2/YltiOcr4KzlzPZfrqTH5ekUFymob3u9viYKCOfp5mNKxmwYM4w4HFi/rryB6WL5hCpzcGMmnqH5QPrc4vkz4iMd7w5B61Ohc7eyc6vTEQ34CyBvPkqdX8NP59EuKief/T7/l+1loGvfc5Ti5uJmmDmY01aZducOXDSc+U3yqgDLW3zCPp6FmO1u7C7R/mUGnqODxfL5gh7VivOjVWTOXh8k0cCevMw+WbqLlyGo51DJ88jKlzCwc6NnNgwZ+JfDb1ESlp+Xw5zBNLZfH7cEaWhvV7Uhg3LZoxPz3kwKkMhvdypVp5qyJ5g30taF3fjnsPDS81M4Y+3Xzp2aUMU+beZsiocyQm5zJ1UlWsrMyeWtbDTcl7g4K5cDmlyHN2Ngpm/1iDvHyJMRP+pu/w0/y2IIL0zDyj1v/IoQMsmDeLN3r2ZuqvcwmtVIVJX40lPi7WYP4rly9RvUYYX036jikzZlOlanW+nfgFdyJuFckbFxvL4vnabZramWM7Wbf4R9p2fZuxP60mpGJNZn43nKT4aIP589S52No70bbr2/j4Gx6Dz1Xl4OpRhi59RmDv6GrK6r8QSSY32qM0evbsybRp05g0aRLVq1fn8OHDbN++HX9/fwCio6Ofes+Hf8N/NnhoXNWcfWfVXL6bT0ySxKr9uVgoZNQoW3xnyop9uRy/ksejRIn4FIm1h3KRyaCsT8Hb0LSaglPX8zh1LZ+4FInNx9SkZEjUr2SaTprmNZXs+iuHi7fURCdo+GNHFhYKGbUrWhRbZvH2LI5cyOVBfD6xSRqW785GJoPyfvp1VJrDW+2tWbErmyxV8T0yL2LnphU0afUazcK74O0bSJ8ho3B29WDfjj8N5nfz8Kbv26Np1KID1ja2BvMc3ruZjIw0Rnz+E+UqVsPV3YtyodXxCzTNhKD4XYe5OX4aMRv3PD0z4P9OL3Iio7k6+jsyrt8hauE6ohavJ2jUIF2ewA8GkLD3OBE/ziPzxh0ifpxHwv6TBHwwwCRteFKHpvas35PCqb+ziIpR89uKeJQWMhrVNPx+A1yNyOHU31k8jFMTm5jH9sNp3I/OpUKQ/iQvSwsZI/q6M2dNApnZpuuNe+M1H5auieTwiQTuRmbx7dTrKJVmhDd1L7GcXA7jx1RkwYp7PIrNKfJ8n+6+xCWomDz9BtdupRMTp+LspRQexRTN+yI2bVhHq/B2hLftgK+fP0OGvoermzs7tm0xmH/I0Pfo+kYvypargLdPGfq9NQQvbx9O/XVCL19+fj5TfvqON/sOwNPLy6h1NmT/lj9o0OJ1GrbqileZIN4Y+AmOLp4c3r3GYH4Xdx96DPqUes06YWVtZzBPQEhluvYfRa1G7VCYF/8999LJZMZ7lNLw4cO5d+8eKpWKs2fP0qRJE91zixcv5uDBg8WWnTBhAhcuXHiOBpfOfzJ4cLaTYW8j48aDgqvpfA1EPMonwPPZm2ShADM5uhOrmRx83OTcjNL/UrwZVbrtPisXBzkOtnKu3Su46snLh9sP8gj0efZgRdeOHP0AoUcra67cUXMj0rhXVY/lqdXci7hO5er642qVq9fl9vVLz73d86ePEFK+Ckvn/sgH/dvy+Qe92LJ2EZp80/SelJZjverE7z2mlxa/+wgOYZWR/bNUyqledRL2HtXLk7DnCE71DQ/nGIu7iwInewUXbxQMT+Xlw9XbOZQPfPbZ3pXLWuLtZs61CP2T6uDuLpy7lsXfN417sn2St4clrs5KTp1P1qWp8yQuXE6hcgX7Esu+1cuflFQ12/YY7vlqWMeF67fT+frTULb8UZ+F02rSKdzTqPVXq9VE3L5J9Zq19NKr1wjj+rUrxZTSp9FoyM7Oxs5Ov72rV/6BvYMDrdu0N1p9i5OnVhN55xoVq+nfdKhitfrcuXHR5K8vvNpKfTl97do1Tp48Sf369alQoQLXr19n+vTpqFQq+vbt+0wzO1UqVZG7a+Wp81GYP9uXm521NpLLKDT8mZENTqUYXmhfz5zUTIlbD7TBgo2lDDO5jPQs/ZNwerake01jejxckp6pH6ykZWpwtn/2YKVzEytSMzRcv18QJISVN8fX3Ywflz3bGPHzSE9LQaPJx8HRRS/dwdGZ1OTE595ufMxDrsWdoX7TNoz6aiqxj6JYOu9H8vPz6dJryItW+4UpPVxRxSbopeXGJSI3N8fC1QlVTDxKT1dUsfrvgSo2EaWnaYZeHnO003brp6brB1qpGfm4OpV8uFtbypg7wQ+FQoZGIzF/XSKXnggSGtSwIchHyWdTHxm/4k9wdtJejSal5OqlJ6fk4uFuWWy5KhXt6djai4Efnik2j7enFV3aWbF64wOWro0ktJwdH70TglotsfOA4SGF0kpLS0Wj0eDo6KSX7ujkRHLys80P2bh+LaqcbBo2bqpLu3blMnt37WDab/OMUs+nyUhPRqPJx85B//i2d3AhLSWhmFL/O4y5VPN/UamCh507d9K5c2dsbW3Jyspiw4YN9O/fn2rVqiFJEm3atGHXrl1PDSAmT57MxIkT9dLqt/+cBh3HGcxfo6wZ3ZsWdG8t2KYNPCSKdsU/a+d8s+oKaoQomL0ph7ynXNDKSrPhEtSuaM6bra11f89ar52gVXjTpenlalVbSa0K5kxbnaFrh6OdjO4trPhtXcZT22YMhetb3JrkZ6WRNNg5ODFw+OfIzcwIDKlISnI82zcseyWCBwCkQp/a4/Y+mW4oT+G0F9Sopg1DexSMG0/+XXsCLPoqsqfuw9kqiY9/foilhZzK5SwZ0MWZ2MQ8rkbk4OJoxsDXXfhmTgzqPOO2oXVTdz5+r2BI6pNJf2v/Y+jAKOalrazM+HJ0BX787SapacX3tMllcP12OvP+uAvArTsZBPhZ06W9t9GChyer+yRJKrp+35DDB/ezavlSPv9qki4AycrKYsrPk3lvxCjsHRyMWs+nKXLPASRkvJzJhP8m6f9BG19EqYKHSZMm8fHHH/PNN9+watUqevfuzbvvvsu3334LwLhx4/j++++fGjwYutvWV4uLP8tdvZfPlCfGLxX/zJmys9bvJbC1gozsp3+xNa2moGVNc+ZuURGdVJA/M0ciX1O0l8HWSkb6M2z3aS7dVnMvOl339+N22NvIScssaL+dtZy0rKe/XstaStrUteTXtRk8SijovfDzUGBvI+fTfgVjjmZyGSFlzGhaw4IPp6Ya5RxmZ++IXG5GSqFehrTUZOwdnZ97u45OrpiZKZCbFUyO8yoTSGpyInlqNQrzEmaT/gtUsQlFehAs3JzRqNXkJqZo88QkoPTUnwymdHcu0mPxos5cyeL2zw91fysU2n3X0c6MlLSCfcrBVk5KRsmRpCRBTIL2xHvvUS5lPCx4vZUDVyNyCCqjxNHOjB9Geevym5nJqBhkSdtG9vT++B6a59ynjp5K5OrNgt4CC3PtFZ+zkwWJyQW9D04O5kV6Ix7z8bTE28OK778smGEu/+cwPrixCb2HneJRTA6Jybnci9LvjbsflUWzBsbrEbK3d0Aul5OcnKyXnpqSXKQ3orAjhw7w6/Sf+XTsV1SvEaZLj4l+RFxsDN9M/EKXJv1zEL/esTWzfl+Cl5d3ke29CFs7J+RysyK9DOmpSdgV6m0U/v8pVfBw5coVli5dCkCPHj3o168f3bp10z3/5ptvsmDBgqdux9DdthTmxXevq9SgUut/M6VlSpQrY8ajf77szOTa1RTbTha/HA20PQ4ta5rz+zYVD+L1hwvyNfAwXkO5MnIu3y34oi1XxozL9178El6lhvgU/ddMzdBQwV+hWw1hJoeQMgo2HS55SWWr2kra1rPkt3UZRMbq1+3GfTXfLE7TS+vX1prYRA27T+cY7eJXYW5OQHAFrlw8Ra36zXXpVy6cokbdJiWULFnZitU4eXgXGo0GuVx7Iol9FImjk+tLDxwAUk5ewL1Dc700t9aNSD17GSlPuz8mn7yAa8uG3J2+RJfHtVUjkk+cN2pdclQSMSr9K+3ktDyqlrfi3kPtiVZhBqEhlizbkmxoE8WSAeb/BCN/38pm1A8P9J4f/qYbj+LUbNyX8tyBA0B2dj4Ps/X34YQkFbWrO3HrjrZ3TqGQUb2yI3OW3DG4jcgHWfR777Re2tv9ArG2MmP6vNvEJWh7K/++loqfj7VePl8fa2LijDeHw9zcnOCQclw8f5b6DRrp0i+cP0vdesUvNT58cD+/TvuJ0Z+Mo1adenrPlfH1Y8as+Xppy5cuJDs7WzsZ09X4w2EKc3P8gipy7dJJqtct+KXG65dOUrV2M6O/3qtGDFuU7LmXEMjlciwtLXF0dNSl2dnZkZqaaox6PdWRS2pa1jQnIVUiIVVDi5rm5OZJnL9V8EXaq4UFqZkSO/7SBhTNqitoW8ec5XtzSU7TYPfPKjSVGnL/KXboYh5vtrQgKl7D/RgN9UIVONrJOHnFNJMOD5xT0aauJfHJGuJS8mlT15LcPInT1wqusPq3syYlQ8PmI9ovuFa1lXRsaMnibVkkpWqw/6enRKWW/gm0IDpBP0hRqSEjRyqS/qLadu7N3GnjCQypSEj5KhzYtYHEhBhatO0KwJqlM0lOjGPoyIJhqvt3bgKQk51Femoy9+/cRKFQ4OMXBECLtt3Yu3UNy+f/QusOPYiJjmLL2sW07tjDqHV/zMzGGpsQP93f1oFlsK9WgdykVHKioin/zSgsfTy4OPBTbf3nrcJ/eB8q/vQZUQvW4FivBr4Du3G+72jdNu79tpR6+5cRNOZtYrfsw6NTS1xb1udEs94macOTth1Ko2srB2Li1UTHq+nayhFVrsTRcwX3MXi/tytJqfms2KYNKLq0dOBOlIqYxDwUZjJqVrSiSW1bfl+rverMUUlEFbpPhCpXQ3pmfpF0Y1i7+SH93vDjwaMsoh5l07+HHypVPrsPxenyfDGyPPGJucxdepdctVTkHhAZ/yy/fDJ99aaHzPmxOv3e8GP/0ThCy9nzWhsvfvztplHr3/n17kz75XtCypajfIVQdu3cRkJ8HG3bdwJg6aL5JCYmMHLMZ4A2cJj2y/cMGfoe5SuEkpyknRthobTAxsYWCwsL/AMC9V7Dxla7eqZwujG16NSPJb+Owz8olMDy1Ti250+SE6JpHP4GABuXTyclMY63RnyrKxN19zoAqpwsMlKTibp7HYXCHC/fYEA7ETP6QQQA+XlqUpLiiLp7HaWlNe5efrwyXtJ9Hv4rShU8BAQEcPv2bUJCQgA4ceIEfn4FH3ZUVBRe/8LyIYADF/IwV8jo2tgCKyVExmn4fasK1RPfY062Mr2r7AaVFCjMZAxoo9/rsfu0mt1ntAUvRuRjY6mmdZg59jYyYpIkFmxTkZxhmqWOe06pMFfI6NnKCmtLGfei8/ltXYZ+O+zleu1oUl2JuULG251t9La17XgO24+bbha8IXUbtyYjPZVNqxeQkpSAj38wo76aiqu7dj9ITU4gKUF/LPmrkQU3hLkXcZ0Th3fh6u7FL79vAsDFzYOPJ85gxYJpfPFhHxxd3Ajv1JMOXfubpA0OYZWpv+8P3d+hP38OQNTS9VwaPBallxtWvgX7dfa9B5zu9A6hv4zF/90+qB7FcWXkt8Rs2K3Lk3ziPOf7jKL8xI8oP3EEWRFRnO89kpRTz78K5Vlt2p+KhbmMId1dsLGSc/u+im/mxJDzxHJdVyeF3j5laSFnSHdXXBzMyFVLPIxT8+uyeI5fyDR5fQ1Z/mcUSgs5o94ti52tOVdvpjHyq0tkP9FD4eFmWeoej+u30vn8uysM7R/IW738iY7NZsbvt9nzRFBiDI2bNic9PY3VK/4gKSkJ/4AAvpo4Gfd/bjGcnJxIQnzBa+7asZX8/HzmzprB3FkzdOktWoXz4ahPjVq30qjVsC2Z6alsXzePtOR4vPxCGP75TFzctEMkackJJCfor2yZ/HFP3f8j71zl9NHtOLt5883sHQCkJsfp5dm7eQl7Ny+hbGgtRk56es+18GqQSdKzd2LPmTMHX19fOnToYPD5cePGERsby/z58w0+X5Ixs023KuDfkp1peDz2v6Zfx/+NiDuxSp2XXYUXtvj9nS+7CkYRffvl39TmRc2fFvyyq2AUD7Ne3RszlUbLKsWvvDGGuKvFr9opLffQWk/P9B9Tqp6Hx7fHLM7jiZOCIAiC8F/2sm5P/V8hZoQIgiAIglAq/+kfxhIEQRAEUxCrLUomggdBEARBKETcJKpkIngQBEEQhEJEz0PJxLsjCIIgCEKpiJ4HQRAEQShErLYomQgeBEEQBKEQMeehZGLYQhAEQRCEUhE9D4IgCIJQiJgwWTIRPAiCIAhCIWLYomQitBIEQRAEoVREz4MgCIIgFCKGLUomggdBEARBKEQMW5RMhFaCIAiCIJSK6HkQBEEQhELEsEXJRPAgCIIgCIWIYYuSvTLBQ6cmL7sGL85fGfeyq2AUe++Xe9lVMIpd7+982VV4YW/91vZlV8Eoal1a8bKr8MJ2RJV52VUwCoWZ9LKr8J8gbk9dMtEvIwiCIAhCqbwyPQ+CIAiC8KqQJNHzUBIRPAiCIAhCIZLomC+ReHcEQRAEQSgV0fMgCIIgCIWI1RYlE8GDIAiCIBQigoeSiWELQRAEQRBKRfQ8CIIgCEIhouehZCJ4EARBEIRCRPBQMjFsIQiCIAhCqYieB0EQBEEoRNwkqmQieBAEQRCEQsSwRclE8CAIgiAIhYjgoWRizoMgCIIgvEJmzZpFYGAglpaWhIWFceTIkWLzrl+/ntatW+Pm5oa9vT3169dn165dJq+jCB4EQRAEoRAJmdEepbF69Wo++ugjxo0bx/nz52ncuDHt2rUjMjLSYP7Dhw/TunVrtm/fztmzZ2nevDmdOnXi/PnzxngbiiWGLQRBEAShkJc1YXLKlCkMHjyYIUOGADBt2jR27drF7NmzmTx5cpH806ZN0/v7u+++Y9OmTWzZsoUaNWqYrJ6i50EQBEEQTEilUpGWlqb3UKlURfLl5uZy9uxZwsPD9dLDw8M5fvz4M72WRqMhPT0dZ2dno9S9OP/ZnoeDO9awa9MSUpMT8PYNpuegMZQNrWkwb0pSPOuWTOF+xDXioiNp0f5Neg7+WC/PkT3rOXFwK48ibwPgF1yR1/t8QGDZyiZrw5at21i7fj1JScn4+/kx7J23qVK5ksG8R48dZ+v2Hdy5cwe1Wo2/vx99e/emVlhBm/Py8li1Zi179+0nITGRMmV8GPzWW9SuFWayNgBIksTxbb9x8dhqVFlpeAVUo1XPr3D1LltiuRvnd3Fsy3RSEiJxdPWj0WsjKVe9tcG8J3fO5cjmKYQ170+LN8aZohkAvNHGkVb17bC1knMrUsX8PxN5EKMuNn+dKtZ0be2Ip6sCM7mMmAQ1Ww6mcfhMhsH8XVo60KejM9sOpbJ4Y5JR6+7cqBZBowfjULMylt7unOk2nNjN+0ou07g2oT9/hm1oWVSP4oj4ZT6R81bp5fF8PZxyEz7EOtiPrIhIbnw1ldhNe41a98I2bN/Dyo1bSUpOIcDXhw8G96dapQoG8166ep05S1cR+fAROSoVnm6uvNamJT1ea6/Lc+jEKZat28TD6Fjy8vMp4+VJz87tadO8sUnbIUkSR7f+xoUjq8nJSsM7sBrhb36F21OOjevndnF483RS4iNxdPOjaeeRlK9RcGwc3zGXG+d3kxRzB4WFJT5BNWjedQwunkEmacPhzb9x7vAacrLS8AmsSts+X+HuU3Ibrp3dxcGNM0iOj8TJzY/mr39EhZr6x/eZAys4sWsB6SnxuHmH0KbX5/iVq2X0NjwPjREnTE6ePJmJEyfqpY0fP54JEybopSUkJJCfn4+Hh4deuoeHBzExMc/0Wr/88guZmZn06NHjher8NP/JnofTR3exetFPtO82mC9/WUnZijWY8c37JMZHG8yfl6fG1t6J9t0GUyagnME8Ny6foU6jtoye9DufTl6Cs6sX0ya+S3JinEnacPDwEeb8Pp83e/Zg1ozpVK5ciS/GTyAuzvDr/X3lCjVrVOfrieP5bfo0qlatyvhJX3M7IkKXZ/HSZWzfuZPhw4by++xZdGjXjknffqeXxxRO7fmdM/sX0arHV/T9dB029q6s+XUguTmGT6AAD++cZ8uCkYTW6cyAzzcRWqczW+Z/xKO7F4vkjb53iUvHVuPmU96UzaBzCwc6NnNgwZ+JfDb1ESlp+Xw5zBNLZfFfIhlZGtbvSWHctGjG/PSQA6cyGN7LlWrlrYrkDfa1oHV9O+49LHrFYQxmNtakXbrBlQ8nPVN+q4Ay1N4yj6SjZzlauwu3f5hDpanj8Hy94KrHsV51aqyYysPlmzgS1pmHyzdRc+U0HOtUNUkbAPYdPcGvC5fS/40uzJ/yHVVDK/DJ1z8QG59gML+lpSVd24fz67df8cevP9P/jdeZv3wtm3cVBE72trb0e6MLs36YyKJp39OuZRO+/3Uup84X3d+M6eSu3zm1dxHhvb7irbHaY2PVtIGoSjg2HkScZ+PvI6lctzODv9xE5bqd2TjvIx4+cWxE3jxFWLM+9P9sDb0+XIRGk8+q6YPJVWUZvQ3Hd87n5J7FtO39JYO/WIuNgxvLpwx6ahv+nDuKKvVf453xm6hS/zX+nDuSh3cK2nDl1HZ2rZpMo/bDePurDfiVq8WK6e+QmvjI6G14Hsac8zB27FhSU1P1HmPHji32tWUy/e8cSZKKpBmycuVKJkyYwOrVq3F3d3/h96Ak/8ngYc+WZTRq2YXGrbviVSaInoM/xsnFk0O71hrM7+ruTa/Bn1C/eSesrG0N5hky8juateuBb2B5vMoE0v/dL5EkieuX/jJJG9Zv2Eib8Na0a9MGPz9f3n3nbdxcXdm6fYfB/O++8zY9unejfLly+Ph4M2hAf7y9vTj51yldnn0HDtCrRw/q1K6Fl5cnnTq0J6xmDf5cv9EkbQDtTn12/1LqtR1GuRrhuHmXo13/H8jLzeHq6a3Flju7fwkBFRpQr+1QXDyDqdd2KH4V6nH2wBK9fLk5mWxb/DHhfb7B0trBZO0A6NDUnvV7Ujj1dxZRMWp+WxGP0kJGo5qG9xmAqxE5nPo7i4dxamIT89h+OI370blUCFLq5bO0kDGirztz1iSQma0xSf3jdx3m5vhpxGzc80z5/d/pRU5kNFdHf0fG9TtELVxH1OL1BI0apMsT+MEAEvYeJ+LHeWTeuEPEj/NI2H+SgA8GmKQNAGs2badDq2Z0bN2cAF8fRgzpj5urCxt3Gu7tKBcUQKsmDQj0K4OXhxvhzRpRu0ZVLl29octTo0ooTerVJsDXBx8vD97o1I6gAD+9PMYmSRKn9y2lQbthlK8ZjptPOTq+9QPq3Byunir+2DizbwmBFRvQoJ322GjQbij+Fepxel/BsdHrwwVUbdAVN++yePhWoOOAyaQlPSLm/hWjt+HU3qU06jCMimHhuPuUo/Og71Hn5nD5r+Lb8NeepQSFNqBR+6G4egXRqP1QAivU46+9BW04uWcxNRp1o0aTN3DzDqZNr8+xd/LkzMGVRm3Dq0CpVGJvb6/3UCqVRfK5urpiZmZWpJchLi6uSG9EYatXr2bw4MGsWbOGVq1aGbX+hhgleJAkyRibeSZ5ajWREdcIrVZfLz20ej0irhvvKiI3N4f8/Dxs7Ix/wlKr1dy6fZuwQpNZwmrW4Oq1a8+0DY1GQ3Z2NnZ2dnrbtTA318untFBy5erVF690MVITH5CZFk9AxUa6NIW5Bb5la/PoTvGzfR/dvaBXBiCwYuMiZfaunkRQ5aYEVGhg3IoX4u6iwMlewcUb2bq0vHy4ejuH8oFFD/LiVC5ribebOdcicvTSB3d34dy1LP6+mVNMyX+fY73qxO89ppcWv/sIDmGVkSm0I5pO9aqTsPeoXp6EPUdwqm+aiVhqdR43I+5Su7p+z0bt6lW4fP3mM23j5p17XLl+k+qVKxp8XpIkzl68TNTDaKpVMpzHGFIStMdGYKj+seFXrjYPIoo/Nh7euaBXBiCoUmMellAmJzsdACsb435fpSQ8ICM1nqBKDXVpCnML/MvX5sHt4uvz4M4FgkIb6qUFVWrEg9sXAMjPyyX6/hW97QIEV2pY4nvzb5IkmdEez8rCwoKwsDD27NG/ANizZw8NGhT/Hbhy5UreeustVqxYQYcOHZ67zaVhlDkPSqWSixcvUrGi6Q7ExzLSk9Fo8rF31J8MYu/gQlpKotFeZ/0fM3B0dqdi1bpG2+ZjaWlpaDQaHB0d9dIdHR1JTk55pm38uWEjOTkqmjYu+JIJq1mDPzdupErlynh5eXL+4kVO/HUSTb5prnQBMlPjAbCxc9FLt7ZzJS2p+O7HzLQErO0LlbF3ITMtXvf3tTPbiI26Sr9P1xmxxoY52pkBkJqer5eempGPq1PJh4m1pYy5E/xQKGRoNBLz1yVy6YkgoUENG4J8lHw29dXojn1M6eGKKlZ/KCA3LhG5uTkWrk6oYuJRerqiitU/rlSxiSg93UxSp9T0dPI1Gpwc9U+Czg4OJCWnlli22+D3SUlNI1+Tz8Ce3ejYurne8xmZWXQb/B656jzM5HJGDh1I7epVjN6Gxx7vyzaF9nMbO1dSSzg2MtISipYpdGw8SZIk9q2dTJmQMNx8DA/LPq+Mf45vWwP1KWl4ISM1ARuHQmUcXMj4pw1ZGclImnyD7cxINTw89W97WTeJGjVqFP369aNWrVrUr1+fefPmERkZybBhwwAYO3YsDx8+ZOnSpYA2cOjfvz/Tp0+nXr16ul4LKysrHBxM11tbquBh1KhRBtPz8/P5/vvvcXHR7ghTpkwpcTsqlarITNPc3HwsLJ79Co/CY0JIRdKe184Nizl1dCdjJv2OeWnqVEqGxrWeZX89cPAQfyxfwYQvv9ALQN4d+g7TZvzKkGHvAuDt5UV4q1bs3mu8yW1XT21m98rxur+7vTtX+58i7/3T2yIrnEGSeFwoLSma/Wu/5Y0PFqIwN/5n0KimDUN7uOr+nvx7rLYKBmppIFFPtkri458fYmkhp3I5SwZ0cSY2MY+rETm4OJox8HUXvpkTgzrv3+uhe2aFew0ff45PphvKY+LeRgN701MP71+/+4rs7Byu3rzN3D9W4ePlSasmBVdr1laWLJg6mezsHM5eusLMhcvw9nCnRpVQo9T58l+b2bm84Njo8b722ChynD9th9KW0i/zxLFR2O6Vk4h/eJO+H68oVX0N+fvkFrb9UdCGN0fMMVgf7eFd8gdS9Pguup2i34FF0/6/6dmzJ4mJiUyaNIno6GgqV67M9u3b8ff3ByA6Olrvng9z584lLy+P9957j/fee0+XPmDAABYvXmyyepYqeJg2bRrVqlUrcsUsSRLXrl3DxsbmmT54QzNPB7z7OQPfe/osels7J+RyM9KS9a+G0lOTsHd48aUpuzcuZcefCxg5YU6xkytflL29PXK5nOTkZL301NRUnAq9t4UdPHyEqTNmMO6zz6hZo7rec44ODkz48gtyc3NJS0vHxcWZBYuWPHWsrDRCqrbAK6Ca7u/8vFxA25Ng61AwQScrPREbO9ci5R+zsXclM03/CiMrPQkbe22Z2MgrZKUnsvT7rrrnJU0+UbdPc+7QckbN+Bu53Oy523HmSha3f36o+1uh0O63jnZmpKQV9D442MpJycgvUv5JkgQxCXkA3HuUSxkPC15v5cDViByCyihxtDPjh1HeuvxmZjIqBlnStpE9vT++h+YlxRSq2IQiPQgWbs5o1GpyE1O0eWISUHrqf45Kd+ciPRbG4mBnh5lcTlKKfi9Dcmpqkd6Iwrw9tPtfcIAfSSmpLFr1p17wIJfLKePlCUDZoADuP3jIsj83GS14KFutBd6BRY+NjFQDx4Z98ceG7VOOjSftXvk1ty7tp++YZdg7eb5oEyhXvTk+gQVDRnmP25CWgJ1jQRsy0xOL9Bo8ydbBtUgPQmZaIrb/tMHa1gmZ3KxInqynbPff9DJ/GGv48OEMHz7c4HOFA4KDBw+avkIGlCp4+Pbbb/n999/55ZdfaNGihS7d3NycxYsXExr6bAfh2LFji/Ri/BVR8hf0Ywpzc/yCK3L14klq1Cuow7WLJ6lWp9kzbaM4uzYuYdu6+Xz05UwCQgwvmTQGc3NzyoaEcO78eRo2KJi7ce78BerXK36Y5MDBQ0yZPoOxn4yhbp3axeazsLDA1dWFvLw8jh4/TpPGjYrNW1oWlrZYWBZMIJQkCRt7N+5dO4aHr/bzz8/LJerWaZp0GVPsdrwDq3Pv+jFqtXxLl3bv2lG8g7Rj6f4V6vHWF1v0yuxcOhZnzyDqhL/9QoEDQI5KIkaVp5eWnJZH1fJW3Huo/cJUmEFoiCXLtiQb2kSxZID5P8HI37eyGfXDA73nh7/pxqM4NRv3pby0wAEg5eQF3Dvod+27tW5E6tnLSHna9yb55AVcWzbk7vSCiW6urRqRfMI049Lm5grKBQdy5sLfNKlXsI+fuXCZRnVLseRYklCri19i+08W1Oq8EvOUhtLSFmUxx4anX8GxEXnzNM27Fn9s+ARV5+61Y9Rp9ZYu7e7Vo/gEF8wzkSSJ3au+5uaFPfQZ9QeOrr4ma4Otgxt3rxzH64k23L9xmpbdRxe7nTJB1bl79Tj1wgvacOfqMcqEVAfATGGBl38l7lw9rrd8887V45Sr3oJXgfhti5KVKngYO3YsrVq1om/fvnTq1InJkydjXmiC3rNQKpVFZppaWDz7EqPWnfqycMYX+IeEEly+Kod3rycpIYam4d0BWL9sBimJcQz68Btdmai72lnVqpws0tOSibp7AzOFAm/fYEA7VLF55SwGj/wOF3dvUpO1EbHS0hpLK+tSt/Fpur7ehZ9+mUK5smWpWKEC23fuJC4+ng7t2wGwcPESEhIT+WS0Nsg6cPAQP02ZyrvvvE2F8hVIStKe0JRKC2xsbAC4fv0GCYmJBAcFkZCYyLIVK5A0Gnp062q4EkYgk8kIa9Gfv3bNxck9ACd3f/7aOReFhSWhtTvq8m1b/Al2jh406aL9wglr3p+VU/vy1+55hFRtye1L+7h//QRvjtZ2vVpY2uLmrd/zY660xsrGsUi6sWw7lEbXVg7ExKuJjlfTtZUjqlyJo+cKlqS939uVpNR8VmzTvv9dWjpwJ0pFTGIeCjMZNSta0aS2Lb+v1e4/OSqJqEL3iVDlakjPzC+S/qLMbKyxCfHT/W0dWAb7ahXITUolJyqa8t+MwtLHg4sDPwXg/rxV+A/vQ8WfPiNqwRoc69XAd2A3zvctOCnc+20p9fYvI2jM28Ru2YdHp5a4tqzPiWa9jVr3J/Xo3J5vp82ifEgQlcqXZcvu/cQlJNC5TUsA5v6xioTEJMZ9pL0yW799Nx6uLviV0fbu/H3tBqs2baNrhza6bS5bt4nyIUH4eLqjzsvj5NkL7Dp4hNHDBhWtgJHIZDJqt+zP8R3aY8PZ3Z/jO+ZibmFJaJ2CY2PLIu2x0ex17fteq2V/lv3clxM751GuektuXtjHvWsn6PtJwbDErpUTuXpqK92Hz8LC0kY3N0FpZYe5haVR21CnVX+Obp+Ls4c/zh7+HN2mbUPlugVt2LjgU+wc3WnZTduGOq36seTHfhzb8Tvlq7fkxoV93L12grc+Xa4rU6/1W2xc8CneAZXxCarO+cNrSE2KJqxZL6PV/0WIn+QuWaknTNauXZuzZ8/y3nvvUatWLZYtW/avj1HVbtSGzPRUtq2Zp71JlF8IH4z7FRd37ZdHanICSQn6S12+Hl2wQ96PuMapIztwcfNi8tztABzauYa8PDVzf9K/eVTHHkN5rdcwo7ehWZPGpKelsXzlKpKSkvD39+ebiePx+GdtblJSEvHxBROktu/cSX5+Pr/NnsNvs+fo0lu3bMGYUSMByFXnsuSPZUTHxGBlZUntWrX4ZPQobG2LX2poDHVav01eroq9qyaSk5WKV0A13vhgoV4PRXpyNDJ5weIen+CadBo0haNbpnF0ywwcXX3pNHiqXrfvv23T/lQszGUM6e6CjZWc2/dVfDMnhhxVQfeAq5NCb7jf0kLOkO6uuDiYkauWeBin5tdl8Ry/kPmv198hrDL19/2h+zv0588BiFq6nkuDx6L0csPK10v3fPa9B5zu9A6hv4zF/90+qB7FcWXkt8Rs2K3Lk3ziPOf7jKL8xI8oP3EEWRFRnO89kpRTl0zWjpaN6pOWlsGS1etJTE4h0K8MP3z5CZ7u2iGWxKQUYuMLhi0ljcS8ZauJjo3HzEyOt6cHQ/v14rV/gg2AbJWKKXMXEp+YhNLCAj8fb74YOZyWjeoXeX1jqtfmbfLUKnat0B4b3oHV6PXhQr2r+7SkaGSygmOjTHBNugyZwqFN0zi8eQZObr50eXsqPk8cG+cPaZczLv+ln97rdRgwmaoNjHux0KDtEPJyc9ixfBLZman4BFWlz6gF+m1IfKR3HvANqUnXd37h4MbpHNyobUPXd6bgE1TQhkp12pOdmcLhLTPJSI3Hzbssb344F0cXn/9r777jmrreP4B/wt5776GyBRVUcFfFYq2ztlZr3ePb4aC2VVtXF7Z11zqwzjrQurWV4QAXiAOqooIyZG8Ie+b+/ogGMyWQNMLveb9e96XcnHPzPLk3ybnnnHsj0/iJfLCYdlxnGRYWhkWLFqGoqAgPHjxo9bCFKDFJsr+5yX/NXj379YU6gIvP5XNm/1+LOJ+u6BDabfrWtxUdgkz43m//ZD5Fu1Ag3zu1/ldUlN/Aibtt8NEA+Z60xj2RfHWPNPq6yvceNYrQrks1J02ahP79++Pu3bu8maCEEEJIR0fDFpK1+z4PNjY2sLGxkUUshBBCCOkAOuwPYxFCCCHyQldbSEaNB0IIIUQADVtI1iF/GIsQQgghikM9D4QQQogAGraQjBoPhBBCiABF3v21I6BhC0IIIYRIhXoeCCGEEAE0bCEZNR4IIYQQAXS1hWTUeCCEEEIEtP2HG/5/oDkPhBBCCJEK9TwQQgghAjg050EiajwQQgghAmjOg2Q0bEEIIYQQqVDPAyGEECKAJkxKRo0HQgghRADd50EyGrYghBBCiFTemJ4Ha40CRYfQbrkNlooOQSbGWNxSdAgyse9ZnaJDaDff+4cVHYJM3Ok+WdEhtFvl6SeKDkEmWHRC3Sr02xaSvTGNB0IIIeRNQVdbSEbDFoQQQgiRCvU8EEIIIQLoagvJqPFACCGECKA7TEpGjQdCCCFEAPU8SEZzHgghhBAiFep5IIQQQgTQ1RaSUeOBEEIIEUD3eZCMhi0IIYQQIhXqeSCEEEIE0IRJyajxQAghhAigH8aSjIYtCCGEECIV6nkghBBCBNCEScmo8UAIIYQIoDkPktGwBSGEEEKkQj0PhBBCiADqeZCswzYezp8/h5MnjqO0tBR29vaYO3c+PD09RZa9ceM6/vn7b6SlpaGxsRH29naYPOUj9Orly1euqqoKB/bvw82bN1BVVQVzCwvMnj0Hfn695ZLD5X/+woXTf6K8rBjWtk6YPOsLdPPoIbJseWkxwvZuxPPUxyjIy8KwdyZh8uwv+Mpcv3QOu39bI1Q39NgNqKqpyyUHADh54SKOnPkHJWVsONhaY+HMKfB2dxFZ9t/Hydhx4Bie5+SirqEBFqYmGBM4BB+8+zavzD+Xr+GnrbuE6l4K+wPqampyywMAZn5oj9EjLKGro4JHKZXYsOMp0jNrWlV36ABTrPnKHVfjirH8xyS+x0yM1PC/6U7o28sI6upKyMqpxdotyUhOrZJp/Kf+icKR0+dRWlYOB1trfD7rY3h7uIose//RE+w4EIbMnFzU1dfDwtQEo0cMxfujR/LKxMTG4+DxM8jJK0BTczNsLC3wwZiRGDFkgEzjfpVRf184fTEL+j09oWFlhjsTPkHB2UuS6wzwg/u6pdBx74r63EKkrv8DmaFhfGUsxgWi2+qF0HK2Q01qJpJXbkTBmYtyywMAGIZBfMRWJMUdQ31NBcztu2PQhJUwtugqsd6zfyNwK3wL2MWZ0DexQ9+gRXDuPpz3+P7v30JlWa5QPa9+kzFowkr55BB7DHW1FbCwe5GD5etziLvQkoP/SP4c9n0nPofB78k2h7bg0B0mJeqQjYerMTHYFboTn3zyKdzcPRB+4R+sWvkttu8IhZmZmVD5pIcP0aNHT0ybPh3a2jq4GBWJ79asxoaNm+Ds3AUA0NjYiG+/WQZ9AwMsX/4tTExMUFRcBE1NLbnkcOt6JA7vWY+p85aiq6s3oiNOYsP3C/Djb3/B2NRCqHxTYwN09Q0xauJMRJ49LHa7mlraCPn9BN86eTYcLl2Pw5a9h/DFnGnwcuuKMxFXsOSHdfhzcwgsTE2E41NXx/iRw+BsbwtNDXXcf5yCX3fshYa6OsYEDuGV09bSxOHffuarK++Gw5QJtvhgrA1+3JSMrJwaTPvAHhu/644P/3cbtbXNEuuam6rj05nOSHxYLvSYrrYKtv/SA/celGPJ6gcoYzfA2kITldVNMo3/0vVY/LbnAILnzYSnazecjbiEr77/GQd++xXmIvaFhoYGxo8MhLODHTTU1fHgcTLWbd8NDXV1jB4xFACgp6ODqRPHws7aCqoqKrh55x7W/rYThgZ66N3DW6bxv6SsrYWK+8nI3n8Svf7a+trymg428DsXiqzdfyFx2pcwDOgJz99WoaGoFPmnIgEABn190OPwRqSs2oz8MxdhMWYYeh7ZhNjBk1Eef18ueQDAvct/IDFmH4Z9GAIDUwfcidqBMztm4qOlF6CmoSOyTl5GAiL+DEaftxfA2Ws4Uh9EIeLAYoz//BAs7Lmv+fuLj4PDaTkmS/Of4syOmXD2HiGXHBKi92HY5BAYmjrg9ssclknOIfxAMPoGLYCT13CkPYhC+P7FmLCgJYcPgvlzKMnj5tDFR/Y5tIUiex62bduGX3/9FXl5efDw8MCmTZswYID4BntMTAyCg4ORlJQEKysrfPXVV5g/f75cY+yQcx5OnTqJwMARGPF2EOzs7DB33nyYmJrin7/Piyw/d958vDdxIrp1c4G1tTWmTZ8BKysr3Lp1i1cmKjISlZVVWLFiFdw9PGBmbg4PD084OTnJJYfIM4cwcNgYDBo+Fla2jpg8+wsYmZjjcvhxkeVNzK0wZfYS9BsyCppaot+wXCzoG5rwLfIUdi4co4YOwrvDB8PBxhoLZ30EM2MjnI64LLJ8NycHDB/gDyc7G1iamWLEoH7o7eOF+4+TBbJgwdjQgG+Rt4mjrXHgWCauxhYjPbMGP258AnV1ZQQOEm6QvkpJCVi1xA27D2cgt6BO6PEp79misLgeIZuT8fhpJfIL63H3fjly84XLtsexM//gnWGDMWr4EDjYWmPB7I9hamKM0+Giz667OTlg2MAAONrZwNLcFIGD+8OvR3fcf9SyL3p4uWNgXz842FrD2tIcE98NgpODHV8ZWSuKuIqUVZuQfzqqVeXt505CXWYeHn3xE6qepCFrz3Fk7TsJp+CZvDKOn09D8cWbSP0lFNXJaUj9JRTFl+Pg8Pk0eaUBhmHw79UD8B02H87dA2Fs2Q3DJq9FU0MdUu6J/qwCgH+vHoBttwD4DpsHQ3Mn+A6bB5uuffHv1f28Mpo6RtDWM+UtGUnR0De2g7WzbHtJGYZBYswB+A2fjy4vchg+eS0aX5NDYkxLDkYvc+jWF4kxEnJ4FA19E9nn0NEcPXoUixYtwjfffIOEhAQMGDAAQUFByMzMFFk+PT0dI0eOxIABA5CQkIDly5djwYIFOHHihMjystLhGg+NjY149uwpevTsybe+Z4+eePz4cau2weFwUFtbC11dXd66W7fi4Ormim3bfseUyZPwyf/m4ejRMDQ3Sz7jbIumxkZkpD6Bh09fvvUePn2R+qR9Z0H1dbVYMmcUgmeNxKYfFuF52pN2bU+SxsYmpKRmwM+bf7jIz8cLD588bdU2UtIy8DD5GXzc+bvWa+vqMGHuYoybvRBf/bgeKWkZsgpbJCtzDZgYqSM+oYy3rrGJQeLDcni66kmsO32SPcrZjfg7Kl/k4/16G+PJs0p8/7U7zv3pjz2beuLdQOHepfbg7ot0+Pl051vP3RcprdpGSloGkp6kwMfTTeTjDMPg7r8PkZWTB28P0WUUwaCvD4ou3uBbVxR5Dfq9PMFS4XauGvb1QfHF63xliqOuwdBf9DChLFSUZqOmsgh2Lv1465RV1GDt7Ie8jASx9fIzEvnqAICda3/kZySKLN/c1IDke2fh1mc8WCzZdrVXlIjJoYsf8tKlzMHlNTncPQu33rLPoa0YRnZLfX09Kioq+Jb6+nqRz7thwwbMmjULs2fPhpubGzZt2gRbW1ts375dZPkdO3bAzs4OmzZtgpubG2bPno2ZM2di3bp18nx5Ot6wRUVFBTgcDgwMDPnWGxgaoqystFXbOHXyBOrq6jBgwEDeuvz8PBT8W4DBQ4Zg9ZrvkZubg+3bfkdzczMmT54i0xwqK8vB4TRDz8CIb72+vhEelhW3ebuWNg6YtWAVbOy7oK6mGlHnj+CnpbOwZtMRWFjZtTdsIezKSjRzODAy0Odbb6Svh5JytsS642YvRHlFJZo5zZj5/ji8O3ww7zE7a0ss/3wOnOxsUVNbi7/OR+J/y3/Avg0/wNZKtl+6vJgNuUMipeUNfOvLyhtgbqYhtp6Xmx5GDbfEjIV3xJaxstDE2CBNHD2djQN/ZcK9my4Wze2CxkYG4VcKZBL/y31hKLQv9FFaJnlfTJj1GcrZFWjmNGPGBxMwavgQvserqmswYdanaGhsgrKSEhbPmwE/Hy+ZxC0L6uYmqC/gf980FJZASVUVaiaGqM8vgrqFCeoLSvjK1BeUQN3CVG5x1VQUAQA0dY351mvqGosc6+fVqyyGpo5AHR1jVL/YnqC0h5dQX1sJV79x7YxYVCyic9DSeX0OWoJ1dCXk8ICbg1tv2efQVrK8z0NISAjWrOGfj7Zq1SqsXr2ab11DQwPu3r2LpUuX8q0PDAzEzZs3RW47NjYWgYGBfOtGjBiB3bt3o7GxEaqqqu1PQIR2NR7Kysqwf/9+PH36FJaWlpg2bRpsbW1fW6++vl6o1VVfXw919daPzQs2ThmGaVWLNTr6Cg4dOogVK1fBwMCAt57DYWBgYIDPP18IZWVldO3aFaUlJThx4rjMGw8vsQRuf8qAEU5MCs4uXnB2aflQ7+LmjdXBH+HS30cxZc6Xbd7u6wjtC+C1++L3H79FbV0dklKeYcefx2BtaY7hA/wBAJ4uXeDp0oVX1su1K2YuWYkT/0Rh0eypMol5+CAzfPlpN97fX333oCX4V7FYwute0NRUxoovXPHL1hSwK8TPX1BiAU+eVSL0z3QAwNO0KjjYaWHsSCuZNR544Qr8zd0Xkuv89tNK1NbW4VHKM+z8MwzWlhYYNjCA97iWpgZ2bwxBbW0d7t5Pwu97DsLK3Aw9vNxlGnu7CA5Qv0z61fWiyshwYDv57jlE/7WK9/eo2TtePI3wG0TwvS9I1PtH3Hvq0a3jsHcdAB19cykjFpZ89xyuHGvJ4d05L3IQ+qzCaw8sReXwJlq2bBmCg4P51on6visuLkZzczPMzflfB3Nzc+Tni+7ZzM/PF1m+qakJxcXFsLS0bGf0oknVeLCyssKDBw9gbGyM9PR0BARwP2C8vLxw9uxZrFu3DnFxcXB1FT27+yVRrbDPP1+ABQsXvTYGPT09KCkpoaysjG89u7xcqDdC0NWYGGzZvAlLly1Hjx78wx5GRkZQVlGGsrIyb52trR3Kyspk3nrT1TWAkpIy2OX8Z0IV7DLoGxiLqSU9JSUlOHZ1R0Felsy2+Sp9XV0oKymhRODMtoxdASN9yV39VubcMz5ne1uUlldgz9FTvMaDICUlJbh1cURWnuy+aK/Hl+BRSktvgZoqdwTPyFANJWUtvQ+G+qpCvREvWVtowMpcE2tXtAzbKL34bIw+PRCT58cjN78OJWUNyMjiv2LjeVYNBgfI7qz35b4oLRfcF2yh3ghBVubcOR3ODnYoLWdjb9gJvsaDkpISbCy5PT5dnRzwPDsHB0+ceWMaD/UFxUI9CGqmRuA0NqKhpJxbJr8Y6hb883/UzYyEeizaw9FjCMztWoaNmpu5x01NRTG09VrmzdRWlQidyb9KS9cENZX8cdVWlUBLV3j+UkVpDrJTYhE047f2hg/gRQ5LXsmh6UUOlcXQ1ufPQUtHcg7VFfw51FSKzyErJRYjZZSDrDAyvNpCXV1dypNjgcbaa06ORZUXtV6WpJrzkJ+fz5sDsHz5cri6uiI1NRWRkZF49uwZBgwYgBUrVrx2O8uWLQObzeZb5s3/X6tiUFVVRZcuXZGQwD/elpCQADc38eOw0dFXsHHjenz55dfo3buP0OPu7u7Iy80Fh8PhrcvJyYGRkZHMu31UVFXh4OyKpMRbfOsfJd6Cs2t3MbWkxzAMMtNToG8ouwbJq1RVVdDN2QG3/33It/7Ovw/h6Sr5Mi4+DIPGRvFn7gzD4Gl6JowNJX8JSqO2thk5eXW8JT2zBsWl9fDzaWmAqqiw4ONpgIdPKkRuIzO7BlM/vY0ZC+7wluvxJbj3oBwzFtxBYTG3d+3BYzbsrPmv2rG11kJ+oewmTHL3hSPuJD7gW38n8SE8XbuJqSUCw6CxsfF1RSTur/9aeVwiTIYG8K0zHd4f7LsPwTRx4yyLS4TJUP4xeJNh/VEWK37cXlpqGjowMLXnLUbmXaCla4qslJbu5uamBuSk3oalg/i5FhYOPshK5u+izky+AQsHH6Gyj+NPQlPHGA5ug+STgwU3h8xkgRye3Yal42tySJEyB3fZ5CArspzz0FomJiZQVlYW6mUoLCwU6l14ycLCQmR5FRUVGBvL57MfaMeEyVu3bmHFihXQ0uJ+KKqrq+Pbb79FXFzca+uqq6tDT0+Pb5GmVTZu3HhERoQjMjICmZmZCA3diaKiQowc+Q4AYN/ePVi/7lde+ejoK9iwfh1mzZ4DF1dXlJaWorS0FNXV1bwyI98ZhcrKSuzcuQM52dmIj7+FY8fC8M6od1sdlzQCx0zB1YuncfXiGeRmpePI7vUoKc7HkBETAAB//bkVuzbxX+ucmZaMzLRk1NfVorKiDJlpycjJSuM9fjosFA8SYlGYn43MtGTs2fodstKTeduUh0nvvo3zl2Jw/lIMMrJzsGXPIRQUl2Bs4FsAgB0Hj+H7zTt55U9cuIjrtxOQlZuPrNx8/H3pKo6cvYDAQS0f/nuOnsKthPvIyS/E0/TnCPn9DzzNyMTYEW/JLQ8A+OtsDqZOtMPAvsZwtNPCN4tcUF/fjMiYQl6Zbxe7YN7HjgCAhkYG6Zk1fEtVdRNqapuRnlmDpibup8bRMznwcNHF1Il2sLbUwPBBZhg9whIn/xY/ZtwW748ZifMXr+Dvi9HIyMrBb7v/RGFxMca8uOxy559h+HHTNl75k/9E4kb8XWTl5iErNw//XIpG2Jm/MXxwf16Zg8fP4HbiA+TmF+B5dg6OnvkbEdHXEPhKGVlT1taCnrcr9Ly5PZhajjbQ83aFhi23+9Xlh2B47225jPd5aBg07a3g9utS6Lg6wWb6BNjOmIC0DXt4ZTK2HoDJ8H5wWjIH2i5OcFoyByZD/ZHx237IC4vFgvfAj3Hn4k6k3o9CSV4KLh5ZBhU1DXTrOYpXLurw17h5fj3vb+8BU5GZcgN3L+1CWUEa7l7aheyUWHgP5L8yhOFw8OT2Kbj6jYWSsnymr7FYLPgMEs5BVSCHyEP8OfgMnIrMZG4Opa/k4DNIOIfH8fLNoSNRU1NDr169EBXFf6VRVFQUr6dfkL+/v1D5yMhI+Pr6ym2+A9CGOQ8vu0Hq6+tFjrMUFYmeECNLAwcNQkVlBY4cPoTS0jLYO9hjzZrvYfYintKyUhQVtXzgh1/4B83Nzdi+7Xds3/Y7b/3QYcMQHLwEAGBqaorvf/gRu0JD8emn/4OxsQlGjxmL996bKJcc+vQPRHUFG2eP/gF2WTGs7ZyxeMVmmJhxPyDZpcUoKeJvTa4Kbpl7kZH6GHFXw2Fsaol1u84BAGqrK7F/249gl5VAU1sHdo4uWPrjLjh1E33zLFkY2r8v2JVV2HfsDErKyuFoZ4Nfv/kCFmbc7smSsnIUFLcMzzAcDnYePIa8wiIoKyvD2twM8z96n+8eD1XVNfhl+16UlrOhraWJbk72+P2H5XDv6iy3PADg0IksqKspIfh/XaGro4pHKRVYvPI+3z0ezE01pJ5I9eRpJZb/lIR5Hzti+iR75BXUYsuuZ4h6pVEiC0P7+6Oiogr7j57k7YufV3wFCzNul35JaTkKil7dFwxCDx5FXkERlJWVYGVhjnlTJ/Hu8QAAtfX12LBzD4pKSqGupgY7ayt8u/gTDO0veohJFvR7ecL/0p+8v93XLQcAZB04ifuzlkHd0hSati3juLUZ2bj97ly4r18G+/9NQX1uIZIW/8i7xwMAlMUmIGFKMFzWLILLmgWoSc1CwuTFcr3HAwD0fGs2mhrrEHPiO9TXsmFu1x1j5u3muz9CZVkuX/eypWNPjJi6HnEXNuNW+BboG9tixMcbePdHeCnr6U1UluXCrff4/ySH6OMvcrDvjjHz+XOoEpHD21PXI/bCZsRdeJHDNBE5pHBzcO8j3xzaQlE/jBUcHIypU6fC19cX/v7+CA0NRWZmJu++DcuWLUNOTg4OHDgAAJg/fz62bt2K4OBgzJkzB7Gxsdi9ezeOHDki1zhZDNP6ThUlJSV4enpCRUUFT58+xYEDBzBuXMvs2KtXr2Ly5MnIzs6WOpBnqelS13nTFDbI954K/5WunEeKDkEmxi2V7X0UFOHEL5Lu6dFx3Ok+WdEhtFvaafld9vxfekOuhGy3z0bKN5G9V2S3rRlDXl/mVdu2bcMvv/yCvLw8eHp6YuPGjRg4kHt14PTp05GRkYHo6Ghe+ZiYGCxevJh3k6ivv/5a7jeJkqrnYdWqVXx/vxyyeOncuXMS74JFCCGEEMk++eQTfPLJJyIf27dvn9C6QYMG4d69e3KOil+7Gg+Cfv31V4mPE0IIIR0B/TCWZDRDhRBCCBGgqDkPHQU1HgghhBAB1PMgWYf7bQtCCCGEKBb1PBBCCCECXrlfIBGBGg+EEEKIABq2kIyGLQghhBAiFep5IIQQQgRQz4Nk1HgghBBCBNClmpLRsAUhhBBCpEI9D4QQQogAKX72qRU6yQ+KvIIaD4QQQogAmvMgGQ1bEEIIIUQq1PNACCGECKCbRElGjQdCCCFEAA1bSEaNB0IIIUQAXaopGc15IIQQQohU3pieh7/u2ik6hHZzsO4cbbFCNV9FhyATf2zKU3QI7XYhy0bRIchE5eknig6h3ZzGuio6BJmoiO74++K/QMMWkr0xjQdCCCHkTcHIdNyi893noXOcKhNCCCHkP0M9D4QQQogAmjApGTUeCCGEEAE050EyGrYghBBCiFSo54EQQggRwKFxC4mo8UAIIYQIoGELyWjYghBCCCFSoZ4HQgghRAD1PEhGjQdCCCFEAIdaDxJR44EQQggRwNBPcktEcx4IIYQQIhXqeSCEEEIEMDRsIRE1HgghhBABHBq2kIiGLQghhBAiFep5IIQQQgTQsIVk1HgghBBCBNDdqSXr0I2H/h4s+DixoKEK5JYCkfc4KK4QX95EDxjgqQQLQ8BAm4WLCRzcfsp/hPi7suBiw4KRLtDUDOSUAFfuc1BaKfv44y8fxs3w3agsL4KZdRe8/eFy2HfzFVs+IzkeEWFrUZjzDLoGZugXNBt+QybxHi/MeYorp7cgNyMJ7JJcjJi0DP6B02QfuIDYqCOI+WcPKsuLYG7dBe9+tBSOruLzSHt8G+cP/YyCnGfQMzDDoFEz0XdoSx53rp7CX6HfCNX7YU8CVNXU5ZIDAPxz/gxOnTiGstIS2Nk7YNbcT+Dh2V1k2dgb13Dh77NIT0tFY2Mj7OztMWnKNPTs5Sey/NWYy1j/84/o0zcAy1d+L7ccAO4Z0/XzW5F47Sjqaipg5eiNwA9XwtSqq8R6T+5F4OrZzSgvyoSBqR0GjVkMlx7DeY/fvLATyQmRKM1Pg4qaBqydemDI+CUwtnCSSw7xEVuRFHcM9TUVMLfvjkETVsLYQnIOz/6NwK3wLWAXZ0LfxA59gxbBuXtLDvu/fwuVZblC9bz6TcagCStlFr9Rf184fTEL+j09oWFlhjsTPkHB2UuS6wzwg/u6pdBx74r63EKkrv8DmaFhfGUsxgWi2+qF0HK2Q01qJpJXbkTBmYsyi1uUzvI5RWSrw8556OvKQu9uLETe42DfRQ6q6xhMGqQENQnNIVVloLyKQfR9BlW1opuVdqYs3H3G4MAlDsJiOFBiAZMGKkFVWbbxP4z/B+FHQjBg1HzMX30Kdl19cXDjXJSXCH+wAUBZUTYObZwHu66+mL/6FAaMmocLh3/EozsRvDKNDXUwNLXFsPe+gI6+qWwDFuPfuAs4dzAEb42ehwU/nICDSy/s+XUeyopF51FamI096+bDwaUXFvxwAkNGz8XZAz/hQXwkXzl1TR18uzWGb5Fnw+FazBXsDt2GiR9MxsbfdsLdwwvfrVyGosICkeWTHt6HT49eWPndT9iwZTu8uvvgxzXfIi31qVDZwoIC7PuDu83/QlzELsRf3IvASSsxfdlxaOuZIGzTDNTXVYmtk52agNO7FsOzzxjMWnEGnn3G4HToIuSk/8srk5kSj16Dp+DjpccwaeFecDjNCNs8Cw31NTLP4d7lP5AYsw+Dxq/A+4v/grauKc7smIkGCTnkZSQg4s9guPQajQ+XnIFLr9GIOLAY+c9bcnh/8XHMWH2Nt4yZvwcA4Ow9QqbxK2troeJ+MpIWfteq8poONvA7F4rS63dx3W8snv28Ax4bv4HFuEBeGYO+PuhxeCNyDp3BtV5jkHPoDHoe2QSD3qIbuLLQWT6n2oLhMDJbOqMO23jw68rCzccMUnKA4grgfDwDVWXA3Y4ltk5eGXDlPoPHWQyaxMykPXqNgwcZDIorgEI2cP42B/raLFgYyjb+2Ih96DlgAnoNnAhTK2cETV4OfSML3LlyRGT5O9Fh0De2RNDk5TC1ckavgRPRY8B43IzYwytj7eiFwPe/glefd6CsoirbgMW4dmEf/AZPQO8h78Hc2hmjpy6DvrEl4i6FiSwfd/koDIwtMXrqMphbO6P3kPfgO2g8rv6zl68ci8WCroEp3yJPZ04dx7DAIAS+/Q5s7ewxe96nMDE1w4W/z4ksP3vepxg/cRK6dnOFlbUNpk6fDUsra8TfiuUr19zcjA2//oQPP5oGC0tLueYAcM/Yb186gICg+XDpGQhT624YNf1nNDbU4VH8ebH17lzaD0e3AAQEzYOxhTMCgubB3rUvbl/azyszaeFudA8YD1OrrjC3dcWoaSGoKM1F/vMkmefw79UD8B02H87dA2Fs2Q3DJq9FU0MdUu6Jz+Hfqwdg2y0AvsPmwdDcCb7D5sGma1/8e7UlB00dI2jrmfKWjKRo6Bvbwdq5t0xzKIq4ipRVm5B/OqpV5e3nTkJdZh4effETqp6kIWvPcWTtOwmn4Jm8Mo6fT0PxxZtI/SUU1clpSP0lFMWX4+DwufzO2jvL51RbMIzsls6oQzYeDLQBHU0W0vNb9kozB8gsAmxMZPtcGi+O7doG2W2zqakBuc+T4OzRj2+9s0c/ZD1LEFknKzVRqHwXj/7IzUhCc1Oj7IKTQlNTA3LSH6GrJ39c3TwD8Pxposg6mU8T0c0zgL+8V39kp/Pn0VBXg5CFQ/Hj50Owd93/kJPxSObxv9TY2IjUZynw6cnfFevToxeePG7dFyOHw0FtbS10dfX41h898if09PUxfMRImcUrSXlxNqoriuDo3p+3TkVVDXbd/JCdKvrYAoCctES+OgDg5DEAORLq1NVyx/I0tfXbGTW/itJs1FQWwc6l5bhSVlGDtbMf8jLEx5OfkchXBwDsXPsjPyNRZPnmpgYk3zsLtz7jwWKJP+n4Lxj09UHRxRt864oir0G/lydYKtzuVMO+Pii+eJ2vTHHUNRj695BLTJ3lc4rIh1SNh4SEBKSnp/P+PnjwIPr16wdbW1v0798fYWGizzYF1dfXo6Kigm9paqxvdRzaGtx/q+v411fXMdDWkO2HwFBvJWQVMRLnUkirprIMDKcZ2vrGfOu19YxRxS4WWaeKXQRtPYHy+sbgNDehpqpMdsFJoaayHBxOM3QE8tDRN0Zlueg8KtnFIstzmptQXVkOADC1csLEuT9iWvDvmPzpr1BRVcf27z5CcX6GPNJARQUbHA4HBgb83UsGhoYoKytt1TZOn/wL9XW16DdgEG/d46SHuBhxAZ8t+EKm8UpSXVEEAMLHiq4JqitE7xMAqKooFq6jZ8zbniCGYXDprxDYdOkFU+tu7YyaX82L59TU5Y9HU9cYNZXic6ipLIamjkAdHfE5pD28hPraSrj6jWtnxO2nbm6C+gL+3BoKS6Ckqgo1E+5xqW5hgvqCEr4y9QUlULeQT69cZ/mcaisOh5HZIi9lZWWYOnUq9PX1oa+vj6lTp6K8vFxs+cbGRnz99dfw8vKCtrY2rKys8PHHHyM3V/QwlCRSNR5mzZqFjIwMAMAff/yBuXPnwtfXF9988w38/PwwZ84c7NmzR/JGAISEhPCSfblEn14rtryHHQtfjFPiLUovohbcJSyWiJXtENiTBVMD4EycfO4WwoJAQ4fBiyTElBd8jOE9INO4pCV81sZIPJMTVZ67nvuXfRdv9Ow/Glb2rnB09cWUzzfAxMIeNyIPyS5okXEJRMWIilXY1ejLCDt0AEuWruA1QGpqarBhXQg+XRAMPX3Znpm/6uGts1i3oAdv4TQ3ARCOm2nVG0OgDsMIrXsp8sh3KMpJwZjZG9oSNp/ku+ewc2lP3iIuBzAi3jMCRO0vcfvw0a3jsHcdAB1987YFLmuC/dsv4351vagycu4X7yyfU9JiGEZmi7xMnjwZiYmJCA8PR3h4OBITEzF16lSx5WtqanDv3j2sWLEC9+7dw8mTJ5GSkoLRo0dL/dxSXW2RnJwMZ2dnAMC2bduwadMmzJ07l/e4n58ffvzxR8ycOVPcJgAAy5YtQ3BwMN+6zefEh/I0l0FuacsOUH7ReNDR4O990FJnobpeNjtqeA8WulqxcPAKB5W1Mtkkj5auIVhKykKt9+rKEugItNpf0tE3FS5fUQIlZRVoaRvINsBW0tI1gJKSslAvQxW7VKh34SVdfROR5ZWUVaClYyCyjpKSEmycvFCc/1wmcQvS09OHkpISysr4z4zY5WVCvRGCrsVcwW+b1+HrZSvh06MXb31+Xi4KC/Lxw5pveetefoiMGzUc23bth6WlVbtj7+r9FqwcvXl/Nzdxx9eq2MXQ0Tfjra+pLIG2nvgxPR094Z6JmspSkXUij3yPp/cv46MlB6FnaNHeFODoMQTmdi2T/pqbuTnUVBRDW68lh9qqEqHeiFdp6ZoI9UzUVpVAS1c4h4rSHGSnxCJoxm/tDV8m6guKhXoQ1EyNwGlsRENJObdMfjHULfhzUTczEuqxkJXO8jnVVm/6D2M9fvwY4eHhiIuLQ58+fQAAu3btgr+/P5KTk+Hi4iJUR19fH1FR/PNwfvvtN/Tu3RuZmZmws7Nr9fNL1fOgqamJoiJuF2BOTg4v4Jf69OnDN6whjrq6OvT09PgWFVXxM+kbmoCyqpaluAKoqmXgYN7SklVSAuxMgWwZvI8Ce7DgYs3C4WgO2NXt354gFRU1WNl7IPXRTb71qUk3YdtF9PilrbMPUpMEy9+AlYOHwiYdqaiowdrRHU8f8sf19OFN2Hf1EVnHrquPiPI3YOMoPg+GYZD3/An05DRpUlVVFc5duuHfhLt86xMT7sLVzUNsvavRl7Fl4y/44svl8O3dl+8xG1s7bNn2BzZtDeUtvfv4w6u7DzZtDYWJiWxyUdfQgZGZPW8xsezCnQj4uGX8vLmpAZkpt2HjLH5s3NrJB+mP+cfc0x9dh/UrdRiGQcSR75CcGInJi/fDwMRWJjmoaejAwNSetxiZd4GWrimyUlqOk+amBuSk3oalg/gcLBx8kJXMf2xlJt+AhYOPUNnH8SehqWMMB7dBQo8pQnlcIkyG8s8FMh3eH+y7D8E0cXtiyuISYTKUfz6BybD+KIsVPw+kPTrL59SbQNRQfX1964fqRYmNjYW+vj7f93Dfvn2hr6+PmzdvSqjJj81mg8ViwcDAQKrnl6rxEBQUhO3btwMABg0ahOPHj/M9fuzYMXTp0kWqANrq9lMGAW4sdLPm3r9hlB8Ljc3Ao8yWnodRvVkY5MXfwDAz4C7KSoCOJvf/hjot2x3RkwUPexbO3OKgoYk7v0JbA1CR8aWa/iOm497V47h37QSKclMRfiQE7NI8+A7mXg998fh6nNz1Na+87+BJYJfkIjwsBEW5qbh37QTuXTuBgBEtvTxNTQ3Iy3yMvMzHaG5qRGV5AfIyH6OkQD5n7AAwIGg6bkcfx+2YEyjIScW5g2tRXpKHvkM/AABcOLoBR3cs5ZXv+9YHKCvJw7mDP6MgJxW3Y07gdvQJDBw5g1cm6uTvSL5/HSWFWch9/hjHd32L3MwnvG3Kw5hx7yEq4h9cjLyArMzn+CN0G4qLCvH2yHcBAAf2/oGN61qG1q5GX8am9WsxY/Z8uLi6o6y0FGWlpaiu5l5KqKamBnsHR75FW0cHmpqasHdwhKqqfD5IWSwW/IZ+/OKeDFEoyknB+X3LoKqmAffeo3jlzu39CtGn1vP+9h36MdIf3UBseChK8lMRGx6KjMex8BvaMpM/4sgaJN06izGz1kNNQxtV7CJUsYvQ2CAw+UgGOXgP/Bh3Lu5E6v0olOSl4OKRZVBR00C3ni05RB3+GjfPt+TgPWAqMlNu4O6lXSgrSMPdS7uQnRIL74H8VyMwHA6e3D4FV7+xUFKWz61ulLW1oOftCj1vVwCAlqMN9LxdoWHLveLG5YdgeO/9mVf+eWgYNO2t4PbrUui4OsFm+gTYzpiAtA0tw8AZWw/AZHg/OC2ZA20XJzgtmQOTof7I+G0/5KWzfE61BYdhZLaIGqoPCQlpV3z5+fkwMzMTWm9mZob8/PxWbaOurg5Lly7F5MmToaen9/oKr5DqnfPzzz+jX79+GDRoEHx9fbF+/XpER0fDzc0NycnJiIuLw6lTp6QKoK3injBQUQZG9FSChhqQWwKExXC/8F/S02LxjTfpagCzAltaAX1dWejrCjwvZHA4mttH1bMLtz310RD+1sL5eO4lnLLi2XskaqrKEXP2d1Sxi2Bm3RVTFu2EgYk1AKCSXQR2acskFkNTG0xZvBPhR9bi9uXD0DUwQ9Dkb+Du23J9emV5IXaubpn8dTN8D26G74G9ix9mfP2nzGJ/lXffINRUluPSqe2oKC+ChU1XzPhyJwxf5lFejPLiPF55IzMbzFyyA+cOrkXsxcPQMzTD6I+Xw6t3y/XsdTWVOLl7FSrZxdDQ0oWVvRvmf3sAts7yu559wKAhqKyswNHDf6K0tBT2Dg5YuSYEZubc8fCyshIUFxXyykdcOI/m5mbs3LYFO7dt4a1/a1ggFgZ/LbT9/1LfEXPQ1FiPiMNrUFfDhpWjNyYt3AN1jZZWckVpHlislnMHG+eeGDt7A2LObMLVs1tgaGqLsXM2wvqVIZGEGO7leYfW84+pvjMtBN0Dxss0h55vzUZTYx1iTnyH+lo2zO26Y8y83VB7JYfKsly+8XVLx54YMXU94i5sxq3wLdA3tsWIjzfAwt6bb9tZT2+isiwXbr1lG/Or9Ht5wv9Sy3vOfd1y7nMfOIn7s5ZB3dIUmrYtl+7WZmTj9rtz4b5+Gez/NwX1uYVIWvwj8k+13P+kLDYBCVOC4bJmEVzWLEBNahYSJi9Gefx9ueXRWT6n2kKWcxVEDdWrq4vubV+9ejXWrFkjcXu3b98GIHo+D8NInnP2UmNjIyZNmgQOh4Nt27a9trwgFiPlK1ReXo61a9fi3LlzSEtLA4fDgaWlJfr164fFixfD11f8ncckCTnW3KZ6bxIH6w555asQTbU3fLCvlVyN8l5f6A0Xl2Wj6BBkorK641/s7jTWVdEhyERF9BNFhyATH/aT7wTML7bJbsx6/SfarS5bXFyM4mLJ4+8ODg44fPgwgoODha6uMDAwwMaNGzFjxgzRlcFtOLz//vtIS0vD5cuXYWwsfi6ROFL32RkYGGDt2rVYu1b81RGEEEJIRybPSywlMTExgYnJ629Y5O/vDzabjfj4ePTuzb3J2a1bt8BmsxEQECC23suGw9OnT3HlypU2NRyADnqTKEIIIUSe3vQ7TLq5ueHtt9/GnDlzEBcXh7i4OMyZMwejRo3iu9LC1dWVN52gqakJ7733Hu7cuYNDhw6hubkZ+fn5yM/PR0ODdHdCpMYDIYQQ0gEdOnQIXl5eCAwMRGBgILp3744//+SfN5KcnAw2mw0AyM7OxtmzZ5GdnQ0fHx9YWlryFmmu0AA6+K9qEkIIIfLQEX7QysjICAcPHpRY5tVpjQ4ODjKbCEqNB0IIIUQAp7P+opWM0LAFIYQQQqRCPQ+EEEKIgI4wbKFI1HgghBBCBFDjQTJqPBBCCCECqO0gGc15IIQQQohUqOeBEEIIEUDDFpJR44EQQggRIMsfxuqMaNiCEEIIIVKhngdCCCFEgKJ+GKujoMYDIYQQIoCGLSSjYQtCCCGESIV6HgghhBABdLWFZG9M46GpuePvqPpGlqJDkIlb92oVHYJM6A42UXQI7aai3PHfFwDA6gRvjYroJ4oOQSb0BrsqOgTZaEyW6+ap8SAZDVsQQgghRCpvTM8DIYQQ8qagn+SWjBoPhBBCiAAatpCMGg+EEEKIALpUUzKa80AIIYQQqVDPAyGEECKA7jApGTUeCCGEEAE050EyGrYghBBCiFSo54EQQggRQBMmJaPGAyGEECKA4XAUHcIbjYYtCCGEECIV6nkghBBCBNDVFpJR44EQQggRQHMeJKNhC0IIIYRIhXoeCCGEEAF0nwfJqPFACCGECKDGg2TUeCCEEEIEcBi6VFOSDt14GOiphJ7OLGioATklQPidZhRViC9vqgcM6q4ES0MWDHRYiLjXjPhk8a3Lfu4svOWtjFvJHETek8+BxDAMrp/fisRrR1FXUwErR28EfrgSplZdJdZ7ci8CV89uRnlRJgxM7TBozGK49BjOe/zmhZ1ITohEaX4aVNQ0YO3UA0PGL4GxhZNc8ni7txr8PVSgqcFCZj4Hx2PqkV8q/jXr66ECP1dVWBpxp91kFTXj79gGZBa01BnWSxXdnVVgZqiExiYGGfkcnLtRj8Jy+ZwRxIQfxcWz+8AuK4alrTMmTv8KXdx7iizLLivCif3rkZn2CEV5mRg8cjImzviKr0xu1jOcD9uGzLTHKC3KxXvTv8Rboz6SS+yvYhgGV89uxb2rx1BXUwFrx+54e8pKmFlLPqYe341A9OktKCvKhKGpHYaMWwTXnsP5yty5chixEbtRWV4EU6suGDFpOey6+colh/iIrUiKPYa62gpY2HXHoAkrYWwpOYdn/0Yg7sIWsIszoW9iB/+Ri+DcvSWHfd+9hcqyXKF6Xv0mY/B7K2WaQ/zlw7gZzn2tzKy74O0Pl8NewmuVkRyPiLC1KMx5Bl0DM/QLmg2/IZN4jxfmPMWV01uQm5EEdkkuRkxaBv/AaTKNWZBRf184fTEL+j09oWFlhjsTPkHB2UuS6wzwg/u6pdBx74r63EKkrv8DmaFhfGUsxgWi2+qF0HK2Q01qJpJXbkTBmYvyTIXIWIedMBngxkJfVxbC73KwO7IZ1XUMpgxRhpqE5pCKClBWBVz+l4PKWslfQJZGQA9nJRSUybfrKi5iF+Iv7kXgpJWYvuw4tPVMELZpBurrqsTWyU5NwOldi+HZZwxmrTgDzz5jcDp0EXLS/+WVyUyJR6/BU/Dx0mOYtHAvOJxmhG2ehYb6GpnnMLSnKgb3UMWJq/XYcLQWFTUc/G+MBtRVxdfpYq2MeymN+P1ULTYdr0F5JYP/jdGEvjaLV8bZWhnX7zdi01+12H6mDkosYP4YTYn7uK3u3AjH8X2/4O3xc7Ds16Po4tYTv//0CUqL8kSWb2psgI6eId4ePwfW9t1Elmmor4OJuQ3GTlkAPQMT2Qctxs3wPxAXtQ9vT16BWd/+BW19UxzaMPO1x9SJncHw8h+NuavOwMt/NE7sXIyctJZjKin+H0SEhaD/yPmYs/IU7Lr54vDmuWCXCH8Zt9e9y38gIXofBk5YgQ8W/wUtPVOc2TETDRJyyMtIQPiBYLj6jsaHX56Bq+9ohO9fjPznLTl8EHwcM9dc4y1j5u8BAHTxGSHT+B/G/4PwIyEYMGo+5q8+Bbuuvji4cS7KxbxWZUXZOLRxHuy6+mL+6lMYMGoeLhz+EY/uRPDKNDbUwdDUFsPe+wI6+qYyjVccZW0tVNxPRtLC71pVXtPBBn7nQlF6/S6u+43Fs593wGPjN7AYF8grY9DXBz0Ob0TOoTO41msMcg6dQc8jm2DQu7u80mgThsPIbOmMOmzjobeLEq4ncfAkm0ERGzgTx4GqCuBpzxJbJ68UuJTIQVImg+Zm8dtWVQHG+Svj73gOahvkEPwLDMPg9qUDCAiaD5eegTC17oZR039GY0MdHsWfF1vvzqX9cHQLQEDQPBhbOCMgaB7sXfvi9qX9vDKTFu5G94DxMLXqCnNbV4yaFoKK0lzkP0+SeR4DfVQRdbsB91ObkV/KwaGoeqipstCrm/hv+YOR9bjxoAk5xRwUljEIu1wPFgvoZqvMK7PzbB3inzQhv5SD3GIODl+sg5GeEmzMZH/YXj73JwLeGod+w8bD0sYJE2d8BQNjC1yNPCayvLGZNd6f+TX6Dn4Xmlq6Iss4dPHE+I+D4ds/CCqqajKPWRSGYRB/8QD6vzMfbr0CYWbdDWNmrkVjQx0e3hJ/TN2KOgAn9wD0HzkPJpZO6D9yHhxd++LWxZZjKi5qH3r0n4AeAyfC1MoZIyYth56hBe5EH5F5DokxB+A3fD66dA+EsWU3DJ/MzSHlnvgcEmMOwLZbAHyHzYORuRN8h82DTbe+SIxpyUFTxwjaeqa8JeNRNPRN7GDt3FumOcRG7EPPARPQ68VrFTR5OfSNLHDniujX6k50GPSNLRE0eTlMrZzRa+BE9BgwHjcj9vDKWDt6IfD9r+DV5x0oq0homctQUcRVpKzahPzTUa0qbz93Euoy8/Doi59Q9SQNWXuOI2vfSTgFz+SVcfx8Goov3kTqL6GoTk5D6i+hKL4cB4fP5duLIi1qPEjWIRsPBtqAriYLafktO6WZAzwvZGBjKr7x0FpBvkp4mssgvUC+O728OBvVFUVwdO/PW6eiqga7bn7ITk0QWy8nLZGvDgA4eQxAjoQ6dbWVAABNbf12Rs3PWI8FfW0lPMlsaY01c4BnOc1wsFSWUJOfmgqgpARU14l/zTXVufu2pq7t8YrS1NiIzLTHcPP251vv5u2PtOR/xdR6M5UXZ6OKXQQnj368dSqqarB38UP2M/HHR3ZaIpzc+/Gtc/Loj+xniQCA5qYG5D1P4tsuADh79JN4rLZFRUk2aiqLYOfS8lzKKmqw7uKHvHTxz5WfkchXBwDsXPojPyNRZPnmpgYk3z0Lt97jwWK1/3PjpaamBuQ+T4KziNcqS8w+yEpNFCrfxaM/cjOS0NzUKLPY5M2grw+KLt7gW1cUeQ36vTzBUuGeTBj29UHxxet8ZYqjrsHQv8d/FidpP6kaD59//jmuXbvW7ietr69HRUUF39LUWN/q+jqa3H+rBL5EqusAHY32xeZhx4KlIQuX/5X/ZJnqiiIAgLaeMd96bV0TVFcUi61XVVEsXEfPmLc9QQzD4NJfIbDp0gum1qK72NtKV4v7oSs4DFRZw0BPq/UfyKMC1MCuYpCSJb5LaGx/daTmNkucS9EWVZVl4HCaoavP/5rq6Rujolz8fngTVbG5x4COiOOjStIxxS6GtkD+2vrGqHpxTNVUlYHhNIs87qrYsn2Naiq5z6mpy/9cWjrGqKkU/1w1lcXQEqyjK/59kfbgEuprK+HWe1w7IxaM48VrJfh6SnitqthFwq+tvjE4zU2oqSqTaXzypG5ugvoC/hwbCkugpKoKNRNDbhkLE9QXlPCVqS8ogbrFfzMU01oMw8hs6YykGj3+/fffsW3bNjg7O2PWrFmYNm0aLCwspH7SkJAQrFmzhm/d4PEr8JaYCUue9iy849fSzjkS8+ILRsQ+ac9u0tMCAnsp4fCVZjTLoe3w8NZZhB9axfv7/c92AoDQWQ/TqiwE6jCM0LqXIo98h6KcFHz05WGp4hWlVzcVvD9Enfd36LnaFwEIRMdq/b54q6cqenZTxdaTtWgS03aYMEgNViZK2Hy8VvqgW0nUfmCJeU3fFA/izuHvP1uOqQ8X7HjxP4G4Gbw2F6HHGeHtCL1GjPA6aSXfPYcrx1pyeHfODpHxcMN5TQ4iHhcX36Nbx2HvOgA6+ubSBdxKIl9PCfELxcnwHpBpXHIn+GX5Mv5X14sq84Z9yXLoh7EkknrqWWRkJM6dO4d169ZhxYoVCAoKwpw5czBy5EgoKbWuI2PZsmUIDg7mW7f+tPgu7pQcBjklLd8qKi+eRkeTv/dBW4Pb+9BWloYs6GiwMHtESyxKSizYmwF+XZXx07Hmdh3fXb3fgpWjN+/v5ibuhIoqdjF09M1462sqS6CtJ36CnY6ecM9ETWWpyDqRR77H0/uX8dGSg9AzlL6hJ+hhehOeF7yyL5S5Hwy6WixU1LS8ODqaLFTWvP7FGtJDFcN91bDtdC3ySkS/WccPVIOnowp+O1kLdrXsP2B0dA2hpKQs1MtQyS6FroGxmFpvhm4+Q2Dt2DLRrOnlMVVRDF2DlmOqurJE6Mz2VTr6JkJnxdUVJdB5cUxp6RiCpaQsVKbmNdttDUePITBf0pLDy/dFTWUxtF95X9RWlUBLR/xzaYnosaupLIGWrvD7oqI0B1kpsRg547d2xS46DtGvVXVliVCP0Es6+qYiX38lZRVoaRvIPEZ5qS8oFupBUDM1AqexEQ0l5dwy+cVQt+DfJ+pmRkI9FuTNJvWcBy8vL2zatAm5ubk4ePAg6uvrMXbsWNja2uKbb77Bs2fPXrsNdXV16Onp8S0qqupiyzc0ca+SeLkUVXC7yR0tWlrkSkqAvRkL2UVt/3JJL2Cw458mhIY385bcEgYPMhiEhrev4QAA6ho6MDKz5y0mll24k7Yet4wRNjc1IDPlNmycxY//WTv5IP0x/7hi+qPrsH6lDsMwiDjyHZITIzF58X4YmNi2L/gX6huBYjbDW/JLOWBXc+Bi19LgUlbiXk2RkSdhViq4DYdAPzXsOFOLrELRDYcJg9TQ3VkFv5+qRWmFfM5MVFRVYefkhsf34/jWP7kfBycXbzG13gzqGjowMrfnLaZWXaCjb4r0pJu8Ms1NDXiefBs2XcQfUzZOPkh/dJNvXdqjG7Dp4gOAO+fA0t4DaUJlbko8VltDTUMHBqb2vMXIogu0dE2RmcyfQ86z27B0FP9cFg4+yErhjy8z+QYsHHyEyj6OPwlNHWM4uA9qV+yiqKiowcreA6kCr1Vq0k3YitkHts4+SE0SLH8DVg4e/9nkSFkoj0uEydAAvnWmw/uDffchmKYmAEBZXCJMhvLP7zAZ1h9lsbKdO9NeNGFSsjZPmFRVVcX777+P8PBwpKWlYc6cOTh06BBcXFxkGZ9Y8ckc9HdXgosNC6b6wJg+SmhsAh4+b9lRY/oq4S3vlhSVlABzA+6irMSddGluABjqcB9vaAKK2PxLQxNQ28D9v6yxWCz4Df34xT0ZolCUk4Lz+5ZBVU0D7r1H8cqd2/sVok+t5/3tO/RjpD+6gdjwUJTkpyI2PBQZj2PhN7RltnLEkTVIunUWY2ath5qGNqrYRahiF6GxQcazDQFcTWzEcF81eDkpw8JICZOHqaOhkcHdlCZemSnD1THKv+WKg7d6quIdfzUcuVSH0koGulos6GqxoPbK5+R7g9Th66KKPyPqUN8IXhnV1s/DbLW33p2Km5dO4ualU8jLTsPxvb+irDgPAwInAgBOH9qMfVu+4auTlf4EWelPUF9Xgyp2GbLSnyAvK5X3eFNjI69Mc1MjyksLkZX+BIV5mbJP4AUWi4Xewz7G9X924sm9KBTmpODMHu4x5dmn5Zg6vftrXDrRckz1HjYVqY9u4MaFXSjOS8ONC7uQ/jgWfYa1HFN9h09HwrXjSLx+AkW5qYgMCwG7NA+9Bk+CLLFYLPgM+hh3Lu5E6v0olOSl4OIRbg7derbkEHnoa9w835KDz8CpyEy+gbuXdqG0IA13L+1CdkosfAbxz+JnOBw8jj8FV7+xUFKWz61u/EdMx72rx3HvGve1Cj/Cfa18X7xWF4+vx8ldX/PK+w6eBHZJLsLDQlCUm4p7107g3rUTCBjRcpVCU1MD8jIfIy/zMZqbGlFZXoC8zMcoKXgulxwA7qWaet6u0PN2BQBoOdpAz9sVGraWAACXH4LhvfdnXvnnoWHQtLeC269LoePqBJvpE2A7YwLSNrRcNZKx9QBMhveD05I50HZxgtOSOTAZ6o+M3/bjTcIwHJktnZFM3jl2dnZYvXo1Vq1ahYsX/5sbfdx8zEBFmUGQrxI0X9wk6lB0Mxpavq+gp8Xim6yiqwnMDWpJOcCNhQA3JWQUMPjzsuSzZHnpO2IOmhrrEXF4Depq2LBy9MakhXugrqHDK1NRmgcWq6URZOPcE2Nnb0DMmU24enYLDE1tMXbORli/MiSSEMO9JOzQ+ql8z/fOtBB0Dxgv0xwu3WuEqgoL7w1Wh5Y6C88LONh+hvuF/5KhjhLfm6i/lypUlFmYOVKTb1vhtxoQHs/ttu7fnduS+HyCFl+Zw1HcSzhlybff26iuZOOf46GoKCuCpV0XfLL8dxibWgEAKsqKUVacz1cn5MsPeP/PTHuE29f/gZGpFX7YfgEAwC4r5Ctz8ex+XDy7H13dfbH4u90yjf9VAW/PRlNDHS4c+g611WxYO3XHlODd/MdUSS7fGLttl54YP3c9ok9vRvRp7jE1fu4GWDu1HFMevUeitrocV8/9jip2EUytuuLDhTthYGwt8xx6vjUbTY11iD7+Hepr2TC3744x83dD7ZUcqsr4c7B07Im3p65H7IXNiLuwBfrGthgxbQMs7Pl7j7JSbqKyLBfufWT7PniVZ++RqKkqR8xZ7mtlZt0VUxbthIEJ97WqZBeBXdpyzwdDUxtMWbwT4UfW4vblw9A1MEPQ5G/g7tty/4nK8kLsXN0yufNm+B7cDN8Dexc/zPj6T7nkod/LE/6XWrbtvm45ACDrwEncn7UM6pam0HzRkACA2oxs3H53LtzXL4P9/6agPrcQSYt/RP6pSF6ZstgEJEwJhsuaRXBZswA1qVlImLwY5fH35ZJDZ1ZWVoYFCxbg7NmzAIDRo0fjt99+g4GBQavqz5s3D6Ghodi4cSMWLVok1XOzGCmmgjo6OuLOnTswNpb9OPD3R2T7ZaAItpYd+oadPIkPxN+IpyN5d3DH3x955eKH8zqS8kpFR9B+xrK9yllh9Aa7KjoEmXinMVmu2x8584HMtvXPHi+ZbetVQUFByM7ORmhoKABg7ty5cHBwwLlz515b9/Tp01i9ejWKiorw5ZdfSt14kOrTNT09XaqNE0IIIR3Rmz5X4fHjxwgPD0dcXBz69OkDANi1axf8/f2RnJwscQpBTk4OPvvsM0REROCdd95p0/N3/FMzQgghRMZk+cNY9fX1qK/nv5eRuro61NXb3rMYGxsLfX19XsMBAPr27Qt9fX3cvHlTbOOBw+Fg6tSp+PLLL+Hh4dHm5++Qd5gkhBBCOoqQkBDo6+vzLSEhIe3aZn5+PszMzITWm5mZIT8/X0QNrp9//hkqKipYsGBBu56feh4IIYQQAbIcthB1byNxvQ6rV68WuomioNu3bwMQfQM0hmHE3hjt7t272Lx5M+7du9fum7tR44EQQggRwMjwDpPSDFF89tlnmDRJ8uXPDg4OuH//PgoKCoQeKyoqgrm56LumXrt2DYWFhbCzs+Ota25uxhdffIFNmzYhIyOjVTEC1HgghBBC3hgmJiYwMRF/h+GX/P39wWazER8fj969ub8Ke+vWLbDZbAQEBIisM3XqVAwbNoxv3YgRIzB16lTMmDFDqjip8UAIIYQIeNOvtnBzc8Pbb7+NOXPmYOdO7u8kzZ07F6NGjeKbLOnq6oqQkBCMGzcOxsbGQrdaUFVVhYWFhdQ3eKQJk4QQQoiAjnCHyUOHDsHLywuBgYEIDAxE9+7d8eef/DcMS05OBpst+1skU88DIYQQ0gEZGRnh4MGDEsu87j6Q0sxzeBU1HgghhBABnDd82ELRqPFACCGECJDl1RadEc15IIQQQohUqOeBEEIIEfCmX22haNR4IIQQQgTI8yqJzoAaD4QQQogA6nmQjOY8EEIIIUQq1PNACCGECKCrLV6D+X+irq6OWbVqFVNXV6foUNqsM+TAMJ0jj86QA8NQHm+SzpADw3SePIhkLIZ5ze2nOomKigro6+uDzWZDT09P0eG0SWfIAegceXSGHADK403SGXIAOk8eRDKa80AIIYQQqVDjgRBCCCFSocYDIYQQQqTy/6bxoK6ujlWrVkFdXV3RobRZZ8gB6Bx5dIYcAMrjTdIZcgA6Tx5Esv83EyYJIYQQIhv/b3oeCCGEECIb1HgghBBCiFSo8UAIIYQQqVDjgRBCCCFSocYDIYQQQqTy/6LxsG3bNjg6OkJDQwO9evXCtWvXFB2SVK5evYp3330XVlZWYLFYOH36tKJDklpISAj8/Pygq6sLMzMzjB07FsnJyYoOS2rbt29H9+7doaenBz09Pfj7++PChQuKDqtdQkJCwGKxsGjRIkWHIpXVq1eDxWLxLRYWFooOq01ycnLw0UcfwdjYGFpaWvDx8cHdu3cVHVarOTg4CO0LFouFTz/9VNGhETnp9I2Ho0ePYtGiRfjmm2+QkJCAAQMGICgoCJmZmYoOrdWqq6vh7e2NrVu3KjqUNouJicGnn36KuLg4REVFoampCYGBgaiurlZ0aFKxsbHB2rVrcefOHdy5cwdvvfUWxowZg6SkJEWH1ia3b99GaGgounfvruhQ2sTDwwN5eXm85cGDB4oOSWplZWXo168fVFVVceHCBTx69Ajr16+HgYGBokNrtdu3b/Pth6ioKADAxIkTFRwZkRvF/i6X/PXu3ZuZP38+3zpXV1dm6dKlCoqofQAwp06dUnQY7VZYWMgAYGJiYhQdSrsZGhoyf/zxh6LDkFplZSXTtWtXJioqihk0aBCzcOFCRYcklVWrVjHe3t6KDqPdvv76a6Z///6KDkOmFi5cyDg7OzMcDkfRoRA56dQ9Dw0NDbh79y4CAwP51gcGBuLmzZsKiooAAJvNBgAYGRkpOJK2a25uRlhYGKqrq+Hv76/ocKT26aef4p133sGwYcMUHUqbPX36FFZWVnB0dMSkSZOQlpam6JCkdvbsWfj6+mLixIkwMzNDjx49sGvXLkWH1WYNDQ04ePAgZs6cCRaLpehwiJx06sZDcXExmpubYW5uzrfe3Nwc+fn5CoqKMAyD4OBg9O/fH56enooOR2oPHjyAjo4O1NXVMX/+fJw6dQru7u6KDksqYWFhuHfvHkJCQhQdSpv16dMHBw4cQEREBHbt2oX8/HwEBASgpKRE0aFJJS0tDdu3b0fXrl0RERGB+fPnY8GCBThw4ICiQ2uT06dPo7y8HNOnT1d0KESOVBQdwH9BsPXLMAy1iBXos88+w/3793H9+nVFh9ImLi4uSExMRHl5OU6cOIFp06YhJiamwzQgsrKysHDhQkRGRkJDQ0PR4bRZUFAQ7/9eXl7w9/eHs7Mz9u/fj+DgYAVGJh0OhwNfX1/89NNPAIAePXogKSkJ27dvx8cff6zg6KS3e/duBAUFwcrKStGhEDnq1D0PJiYmUFZWFuplKCwsFOqNIP+Nzz//HGfPnsWVK1dgY2Oj6HDaRE1NDV26dIGvry9CQkLg7e2NzZs3KzqsVrt79y4KCwvRq1cvqKioQEVFBTExMdiyZQtUVFTQ3Nys6BDbRFtbG15eXnj69KmiQ5GKpaWlUMPTzc2tQ03qfun58+e4ePEiZs+erehQiJx16saDmpoaevXqxZv5+1JUVBQCAgIUFNX/TwzD4LPPPsPJkydx+fJlODo6KjokmWEYBvX19YoOo9WGDh2KBw8eIDExkbf4+vpiypQpSExMhLKysqJDbJP6+no8fvwYlpaWig5FKv369RO6bDklJQX29vYKiqjt9u7dCzMzM7zzzjuKDoXIWacftggODsbUqVPh6+sLf39/hIaGIjMzE/Pnz1d0aK1WVVWFZ8+e8f5OT09HYmIijIyMYGdnp8DIWu/TTz/F4cOHcebMGejq6vJ6g/T19aGpqang6Fpv+fLlCAoKgq2tLSorKxEWFobo6GiEh4crOrRW09XVFZproq2tDWNj4w41B2XJkiV49913YWdnh8LCQvzwww+oqKjAtGnTFB2aVBYvXoyAgAD89NNPeP/99xEfH4/Q0FCEhoYqOjSpcDgc7N27F9OmTYOKSqf/aiGKvdjjv/H7778z9vb2jJqaGtOzZ88Od3nglStXGABCy7Rp0xQdWquJih8As3fvXkWHJpWZM2fyjiVTU1Nm6NChTGRkpKLDareOeKnmBx98wFhaWjKqqqqMlZUVM378eCYpKUnRYbXJuXPnGE9PT0ZdXZ1xdXVlQkNDFR2S1CIiIhgATHJysqJDIf8BFsMwjGKaLYQQQgjpiDr1nAdCCCGEyB41HgghhBAiFWo8EEIIIUQq1HgghBBCiFSo8UAIIYQQqVDjgRBCCCFSocYDIYQQQqRCjQdCCCGESIUaD4QQQgiRCjUeCCGEECIVajwQQgghRCr/BwnZY7RQfu9FAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = np.corrcoef(bike_d2, rowvar = False)\n",
    "\n",
    "sns.heatmap(corr_matrix, annot = True, cmap = 'coolwarm', fmt = '.2f', \n",
    "            xticklabels = range(bike_d2.shape[1]), yticklabels = range(bike_d2.shape[1]))\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4860ee87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues: [2.30501078 1.48845607 0.22373965 0.43508645 0.62660268 0.8840208\n",
      " 0.96495307 1.07213051]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "eigenvalues, _ = np.linalg.eig(corr_matrix)\n",
    "print(\"Eigenvalues:\", eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de54e10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition Number: 3.2097041653301455\n"
     ]
    }
   ],
   "source": [
    "condition_number = np.sqrt(np.max(eigenvalues) / np.min(eigenvalues))\n",
    "print(\"Condition Number:\", condition_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37e9d0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs of highly correlated variables: [(0, 2)]\n"
     ]
    }
   ],
   "source": [
    "def find_highly_correlated_vars(corr_matrix, threshold = 0.5):\n",
    "    if isinstance(corr_matrix, pd.DataFrame):\n",
    "        corr_matrix = corr_matrix.values\n",
    "    rows, cols = np.where(np.abs(corr_matrix) > threshold)\n",
    "    unique_pairs = set((min(r, c), max(r, c)) for r, c in zip(rows, cols) if r != c)\n",
    "    return list(unique_pairs)\n",
    "\n",
    "corr_matrix = bike_d2.corr()\n",
    "highly_corr_vars = find_highly_correlated_vars(corr_matrix, threshold=0.5)\n",
    "\n",
    "print(\"Pairs of highly correlated variables:\", highly_corr_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83931d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fba339a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>37</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rented Bike Count  Hour  Temperature(°C)  Humidity(%)  Wind speed (m/s)  \\\n",
       "0                254     0             -5.2           37               2.2   \n",
       "1                204     1             -5.5           38               0.8   \n",
       "\n",
       "   Solar Radiation (MJ/m2)  Rainfall(mm)  Snowfall (cm)  \n",
       "0                      0.0           0.0            0.0  \n",
       "1                      0.0           0.0            0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_d2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12a40c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_d3 = bike.drop([\"Date\", \n",
    "                     \"Humidity(%)\", \"Wind speed (m/s)\", \n",
    "                     \"Visibility (10m)\", \"Dew point temperature(°C)\",\n",
    "                     \"Solar Radiation (MJ/m2)\", \"Rainfall(mm)\",\n",
    "                     \"Snowfall (cm)\",\n",
    "                     \"Seasons\", \"Holiday\", \"Functioning Day\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67fe0abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rented Bike Count  Hour  Temperature(°C)\n",
       "0                254     0             -5.2\n",
       "1                204     1             -5.5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_d3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525c5877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d696a49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5f429f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e4a3862",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_array = bike_d3.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "031a6c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bike_array[:, 1:]\n",
    "\n",
    "y = bike_array[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68998cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([254., 204., 173., ..., 694., 712., 584.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90223a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. , -5.2],\n",
       "       [ 1. , -5.5],\n",
       "       [ 2. , -6. ],\n",
       "       ...,\n",
       "       [21. ,  2.6],\n",
       "       [22. ,  2.1],\n",
       "       [23. ,  1.9]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "898ac511",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20e33953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8760, 2), (8760,), (7008, 2), (1752, 2), (7008,), (1752,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aea68f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe5b3d",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590b4100",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c2a959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35d12d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 242817.70559788027\n",
      "Root Mean Squared Error: 492.76536566390325\n",
      "R-squared: 0.3991796133882427\n",
      "Adjusted R-squared: 0.39849256892099083\n"
     ]
    }
   ],
   "source": [
    "linear_reg = LinearRegression()\n",
    "\n",
    "linear_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "yp_lr = linear_reg.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, yp_lr)\n",
    "mse_r = mean_squared_error(y_test, yp_lr, squared = False)\n",
    "r2 = r2_score(y_test, yp_lr)\n",
    "\n",
    "n = len(y_test)\n",
    "k = X_train_scaled.shape[1]\n",
    "adj_r2 = 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {mse_r}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Adjusted R-squared: {adj_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a3cb88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 246198.12060337863\n",
      "Validation MSE: 242817.70559788027\n"
     ]
    }
   ],
   "source": [
    "train_pred = linear_reg.predict(X_train_scaled)\n",
    "test_pred = linear_reg.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "train_mse = mean_squared_error(y_train, train_pred)\n",
    "test_mse = mean_squared_error(y_test, test_pred)\n",
    "\n",
    "print(f'Training MSE: {train_mse}')\n",
    "print(f'Validation MSE: {test_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b11085b",
   "metadata": {},
   "source": [
    "## No overfitting but low R2\n",
    "\n",
    "## 30% Training MSE: 242346.04562180358\n",
    "Validation MSE: 253067.87962849034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75828c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Huber Loss: 360.61065113969966\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def huber_loss(y_test, yp_lr, delta=1.0):\n",
    "    error = y_test - yp_lr\n",
    "    condition = tf.abs(error) < delta\n",
    "    squared_loss = 0.5 * tf.square(error)\n",
    "    linear_loss = delta * (tf.abs(error) - 0.5 * delta)\n",
    "    return tf.where(condition, squared_loss, linear_loss)\n",
    "\n",
    "loss = huber_loss(y_test, yp_lr, delta=1.0)\n",
    "#print(\"Huber Loss:\", loss.numpy())\n",
    "\n",
    "mean_huber_loss = np.mean(loss)\n",
    "print(f\"Mean Huber Loss: {mean_huber_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "297a10e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39460955763442185"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_l = cross_val_score(LinearRegression(), X_test_scaled, y_test, cv = 5, scoring = 'r2').mean()\n",
    "score_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7bb2d981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278.0</td>\n",
       "      <td>831.860917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.0</td>\n",
       "      <td>-22.764604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215.0</td>\n",
       "      <td>603.995434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1290.0</td>\n",
       "      <td>967.730262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165.0</td>\n",
       "      <td>718.654236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual   Predicted\n",
       "0   278.0  831.860917\n",
       "1    96.0  -22.764604\n",
       "2   215.0  603.995434\n",
       "3  1290.0  967.730262\n",
       "4   165.0  718.654236"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pd.DataFrame({'Actual': y_test, 'Predicted': yp_lr})\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc2c325",
   "metadata": {},
   "source": [
    "## Polynomial 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34597a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2de30d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 220932.85232122723\n",
      "Root Mean Squared Error: 470.0349479785809\n",
      "R-squared: 0.4533307963682661\n",
      "Adjusted R-squared: 0.4527056743515345\n"
     ]
    }
   ],
   "source": [
    "poly_features = PolynomialFeatures(degree = 2)\n",
    "\n",
    "X_train_poly = poly_features.fit_transform(X_train_scaled)\n",
    "X_test_poly = poly_features.transform(X_test_scaled)\n",
    "\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(X_train_poly, y_train)\n",
    "\n",
    "yp_p2 = poly_reg.predict(X_test_poly)\n",
    "\n",
    "mse = mean_squared_error(y_test, yp_p2)\n",
    "mse_r = mean_squared_error(y_test, yp_p2, squared = False)\n",
    "r2 = r2_score(y_test, yp_p2)\n",
    "\n",
    "n = len(y_test)\n",
    "k = X_train_scaled.shape[1]  # Number of features\n",
    "adj_r2 = 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {mse_r}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Adjusted R-squared: {adj_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c28660de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39460955763442185"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_lp2 = cross_val_score(poly_reg, X_test_scaled, y_test, cv = 5, scoring = 'r2').mean()\n",
    "score_lp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0268788d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278.0</td>\n",
       "      <td>524.901708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.0</td>\n",
       "      <td>205.002854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215.0</td>\n",
       "      <td>519.436048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1290.0</td>\n",
       "      <td>990.160071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165.0</td>\n",
       "      <td>582.496980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual   Predicted\n",
       "0   278.0  524.901708\n",
       "1    96.0  205.002854\n",
       "2   215.0  519.436048\n",
       "3  1290.0  990.160071\n",
       "4   165.0  582.496980"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_p2 = pd.DataFrame({'Actual': y_test, 'Predicted': yp_p2})\n",
    "pred_p2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1a0e82",
   "metadata": {},
   "source": [
    "train_pred = poly_reg.predict(X_train_poly)\n",
    "test_pred = poly_reg.predict(X_test_poly)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "train_mse = mean_squared_error(y_train, train_pred)\n",
    "test_mse = mean_squared_error(y_test, test_pred)\n",
    "\n",
    "print(f'Training MSE: {train_mse}')\n",
    "print(f'Validation MSE: {test_mse}')\n",
    "\n",
    "import tensorflow as tf\n",
    "def huber_loss(y_test, yp_p2, delta=1.0):\n",
    "    error = y_test - yp_p2\n",
    "    condition = tf.abs(error) < delta\n",
    "    squared_loss = 0.5 * tf.square(error)\n",
    "    linear_loss = delta * (tf.abs(error) - 0.5 * delta)\n",
    "    return tf.where(condition, squared_loss, linear_loss)\n",
    "\n",
    "loss = huber_loss(y_test, yp_p2, delta=1.0)\n",
    "print(\"Huber Loss:\", loss.numpy())\n",
    "\n",
    "mean_huber_loss = np.mean(loss)\n",
    "print(f\"Mean Huber Loss: {mean_huber_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be519e94",
   "metadata": {},
   "source": [
    "## Not overfitting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3e34cb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5aed552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 202259.78873932717\n",
      "R-squared: 0.4995348293603358\n"
     ]
    }
   ],
   "source": [
    "degree = 3\n",
    "poly_features = PolynomialFeatures(degree=degree)\n",
    "\n",
    "X_train_poly = poly_features.fit_transform(X_train_scaled)\n",
    "X_test_poly = poly_features.transform(X_test_scaled)\n",
    "\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(X_train_poly, y_train)\n",
    "\n",
    "yp_p3 = poly_reg.predict(X_test_poly)\n",
    "\n",
    "mse = mean_squared_error(y_test, yp_p3)\n",
    "r2 = r2_score(y_test, yp_p3)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a86ab62",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4102f4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Ridge): 242788.79081971946\n",
      "R-squared (Ridge): 0.39925115919315257\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_reg = Ridge(alpha=1.0)  # Adjust alpha based on the strength of regularization\n",
    "ridge_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "yp_lnR = ridge_reg.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, yp_lnR)\n",
    "r2 = r2_score(y_test, yp_lnR)\n",
    "\n",
    "print(f'Mean Squared Error (Ridge): {mse}')\n",
    "print(f'R-squared (Ridge): {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64ba5acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278.0</td>\n",
       "      <td>830.886403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.0</td>\n",
       "      <td>-21.193754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215.0</td>\n",
       "      <td>603.804502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1290.0</td>\n",
       "      <td>967.492646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165.0</td>\n",
       "      <td>719.198340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual   Predicted\n",
       "0   278.0  830.886403\n",
       "1    96.0  -21.193754\n",
       "2   215.0  603.804502\n",
       "3  1290.0  967.492646\n",
       "4   165.0  719.198340"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_lnR = pd.DataFrame({'Actual': y_test, 'Predicted': yp_lnR})\n",
    "pred_lnR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "05ceb1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Ridge): 223465.61354643287\n",
      "Root Mean Squared Error: 472.72149681015446\n",
      "R-squared (Ridge): 0.4470638127692883\n",
      "Adjusted R-squared: 0.3985641965392853\n"
     ]
    }
   ],
   "source": [
    "degree = 2\n",
    "\n",
    "poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "X_test_poly = poly.transform(X_test_scaled)\n",
    "\n",
    "ridge_reg2 = Ridge(alpha = 10.0) \n",
    "ridge_reg2.fit(X_train_poly, y_train)\n",
    "\n",
    "yp_rp2 = ridge_reg2.predict(X_test_poly)\n",
    "\n",
    "mse_ridge = mean_squared_error(y_test, yp_rp2)\n",
    "mse_ridge_r = mean_squared_error(y_test, yp_rp2, squared = False)\n",
    "r2_ridge = r2_score(y_test, yp_rp2)\n",
    "\n",
    "n = len(y_test)\n",
    "k = X_train_scaled.shape[1]  \n",
    "adj_r2 = 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "print(f'Mean Squared Error (Ridge): {mse_ridge}')\n",
    "print(f'Root Mean Squared Error: {mse_ridge_r}')\n",
    "print(f'R-squared (Ridge): {r2_ridge}')\n",
    "print(f'Adjusted R-squared: {adj_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "833cbaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38995153345812467"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rp2 = cross_val_score(ridge_reg2, X_test_scaled, y_test, cv = 5, scoring = 'r2').mean()\n",
    "score_rp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00cbb057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 226873.3318295576\n",
      "Validation MSE: 223465.61354643287\n",
      "Mean Huber Loss: 335.1979898962455\n"
     ]
    }
   ],
   "source": [
    "train_pred = ridge_reg2.predict(X_train_poly)\n",
    "test_pred = ridge_reg2.predict(X_test_poly)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "train_mse = mean_squared_error(y_train, train_pred)\n",
    "test_mse = mean_squared_error(y_test, test_pred)\n",
    "\n",
    "print(f'Training MSE: {train_mse}')\n",
    "print(f'Validation MSE: {test_mse}')\n",
    "\n",
    "import tensorflow as tf\n",
    "def huber_loss(y_test, yp_rp2, delta = 1.0):\n",
    "    error = y_test - yp_rp2\n",
    "    condition = tf.abs(error) < delta\n",
    "    squared_loss = 0.5 * tf.square(error)\n",
    "    linear_loss = delta * (tf.abs(error) - 0.5 * delta)\n",
    "    return tf.where(condition, squared_loss, linear_loss)\n",
    "\n",
    "loss = huber_loss(y_test, yp_rp2, delta = 1.0)\n",
    "#print(\"Huber Loss:\", loss.numpy())\n",
    "\n",
    "mean_huber_loss = np.mean(loss)\n",
    "print(f\"Mean Huber Loss: {mean_huber_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1962cb",
   "metadata": {},
   "source": [
    "## No overfitting but significant difference between R2 and Adjusted R2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acc9d3d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec8b581e",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e1e9c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Lasso): 242764.9455925631\n",
      "R-squared (Lasso): 0.39931016106273887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_reg = Lasso(alpha=1.0) \n",
    "lasso_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "yp_lnL = lasso_reg.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, yp_lnL)\n",
    "r2 = r2_score(y_test, yp_lnL)\n",
    "\n",
    "print(f'Mean Squared Error (Lasso): {mse}')\n",
    "print(f'R-squared (Lasso): {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5922ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Lasso): 226845.03330264846\n",
      "R-squared (Lasso): 0.4387018843034318\n"
     ]
    }
   ],
   "source": [
    "degree = 2\n",
    "\n",
    "poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "X_test_poly = poly.transform(X_test_scaled)\n",
    " \n",
    "lasso_reg = Lasso(alpha = 10.0, max_iter = 100000)\n",
    "lasso_reg.fit(X_train_poly, y_train)\n",
    "\n",
    "yp_lp2 = lasso_reg.predict(X_test_poly)\n",
    "\n",
    "mse_lasso = mean_squared_error(y_test, yp_lp2)\n",
    "r2_lasso = r2_score(y_test, yp_lp2)\n",
    "\n",
    "print(f'Mean Squared Error (Lasso): {mse_lasso}')\n",
    "print(f'R-squared (Lasso): {r2_lasso}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63b392d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd85fb6b",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be5d6dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c38de7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 4, 'n_estimators': 100}\n",
      "Mean Squared Error: 167026.3267661557\n",
      "Root Mean Squared Error: 408.6885449412005\n",
      "R-squared (Best Model): 0.5867153839754451\n",
      "Adjusted R-squared: 0.3986232658781337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestRegressor(random_state = 12), param_grid, cv = 5, scoring = 'r2')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred_best)\n",
    "mse_r = mean_squared_error(y_test, y_pred_best, squared = False)\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "n = len(y_test)\n",
    "k = X_train_scaled.shape[1]  \n",
    "adj_r2 = 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "print(f'Best Hyperparameters: {best_params}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {mse_r}')\n",
    "print(f'R-squared (Best Model): {r2_best}')\n",
    "print(f'Adjusted R-squared: {adj_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71731a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5410243375530565"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rf = cross_val_score(RandomForestRegressor(max_depth = 10,\n",
    "                                              min_samples_leaf = 4, \n",
    "                                              n_estimators = 200,\n",
    "                                              random_state = 12), X_test_scaled, y_test, \n",
    "                           cv = 10, scoring = 'r2').mean()\n",
    "score_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0214ede1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278.0</td>\n",
       "      <td>338.867429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.0</td>\n",
       "      <td>158.759999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215.0</td>\n",
       "      <td>166.600270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual   Predicted\n",
       "0   278.0  338.867429\n",
       "1    96.0  158.759999\n",
       "2   215.0  166.600270"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_rf = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_best})\n",
    "pred_rf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592c5f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20fc16cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 121619.56725421119\n",
      "Validation MSE: 167026.3267661557\n",
      "Mean Huber Loss: 257.91922503534374\n"
     ]
    }
   ],
   "source": [
    "train_pred = best_model.predict(X_train_scaled)\n",
    "test_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "train_mse = mean_squared_error(y_train, train_pred)\n",
    "test_mse = mean_squared_error(y_test, test_pred)\n",
    "\n",
    "print(f'Training MSE: {train_mse}')\n",
    "print(f'Validation MSE: {test_mse}')\n",
    "\n",
    "import tensorflow as tf\n",
    "def huber_loss(y_test, y_pred_best, delta = 1.0):\n",
    "    error = y_test - y_pred_best\n",
    "    condition = tf.abs(error) < delta\n",
    "    squared_loss = 0.5 * tf.square(error)\n",
    "    linear_loss = delta * (tf.abs(error) - 0.5 * delta)\n",
    "    return tf.where(condition, squared_loss, linear_loss)\n",
    "\n",
    "loss = huber_loss(y_test, y_pred_best, delta = 1.0)\n",
    "#print(\"Huber Loss:\", loss.numpy())\n",
    "\n",
    "mean_huber_loss = np.mean(loss)\n",
    "print(f\"Mean Huber Loss: {mean_huber_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6242d3fd",
   "metadata": {},
   "source": [
    "## Overfitting here and big difference between R2 and Adjusted R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c78a37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b412d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d6d7853",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "665034be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.15.0 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.59.3)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: keras in /Users/izaiaszacca/anaconda3/lib/python3.11/site-packages (2.15.0)\n"
     ]
    }
   ],
   "source": [
    " !pip install tensorflow\n",
    " !pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "16fec597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5178b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 917322.6250 - val_loss: 925312.8125\n",
      "Epoch 2/300\n",
      "88/88 [==============================] - 0s 509us/step - loss: 908341.6250 - val_loss: 889459.5000\n",
      "Epoch 3/300\n",
      "88/88 [==============================] - 0s 577us/step - loss: 743071.9375 - val_loss: 523334.6250\n",
      "Epoch 4/300\n",
      "88/88 [==============================] - 0s 542us/step - loss: 369757.6250 - val_loss: 326876.5000\n",
      "Epoch 5/300\n",
      "88/88 [==============================] - 0s 539us/step - loss: 321977.1875 - val_loss: 322288.9688\n",
      "Epoch 6/300\n",
      "88/88 [==============================] - 0s 545us/step - loss: 317416.9688 - val_loss: 317448.9375\n",
      "Epoch 7/300\n",
      "88/88 [==============================] - 0s 535us/step - loss: 312687.4375 - val_loss: 312884.1875\n",
      "Epoch 8/300\n",
      "88/88 [==============================] - 0s 520us/step - loss: 307883.8750 - val_loss: 307894.6875\n",
      "Epoch 9/300\n",
      "88/88 [==============================] - 0s 523us/step - loss: 303169.8125 - val_loss: 302939.6875\n",
      "Epoch 10/300\n",
      "88/88 [==============================] - 0s 541us/step - loss: 298402.1562 - val_loss: 297994.0000\n",
      "Epoch 11/300\n",
      "88/88 [==============================] - 0s 536us/step - loss: 293691.2500 - val_loss: 292940.9062\n",
      "Epoch 12/300\n",
      "88/88 [==============================] - 0s 539us/step - loss: 288545.8125 - val_loss: 287474.1562\n",
      "Epoch 13/300\n",
      "88/88 [==============================] - 0s 539us/step - loss: 283423.3125 - val_loss: 282325.5625\n",
      "Epoch 14/300\n",
      "88/88 [==============================] - 0s 555us/step - loss: 278529.0312 - val_loss: 277120.6875\n",
      "Epoch 15/300\n",
      "88/88 [==============================] - 0s 565us/step - loss: 273460.7812 - val_loss: 271758.5000\n",
      "Epoch 16/300\n",
      "88/88 [==============================] - 0s 533us/step - loss: 268700.1875 - val_loss: 266913.5312\n",
      "Epoch 17/300\n",
      "88/88 [==============================] - 0s 551us/step - loss: 264015.5938 - val_loss: 262513.6875\n",
      "Epoch 18/300\n",
      "88/88 [==============================] - 0s 545us/step - loss: 259724.2344 - val_loss: 257898.1406\n",
      "Epoch 19/300\n",
      "88/88 [==============================] - 0s 568us/step - loss: 255981.6406 - val_loss: 254036.4531\n",
      "Epoch 20/300\n",
      "88/88 [==============================] - 0s 547us/step - loss: 252588.0000 - val_loss: 250997.2969\n",
      "Epoch 21/300\n",
      "88/88 [==============================] - 0s 542us/step - loss: 250127.7031 - val_loss: 247677.1406\n",
      "Epoch 22/300\n",
      "88/88 [==============================] - 0s 536us/step - loss: 247428.5469 - val_loss: 245285.5625\n",
      "Epoch 23/300\n",
      "88/88 [==============================] - 0s 520us/step - loss: 245178.2031 - val_loss: 242878.2188\n",
      "Epoch 24/300\n",
      "88/88 [==============================] - 0s 616us/step - loss: 243664.2344 - val_loss: 241932.7812\n",
      "Epoch 25/300\n",
      "88/88 [==============================] - 0s 642us/step - loss: 242202.0938 - val_loss: 239495.4844\n",
      "Epoch 26/300\n",
      "88/88 [==============================] - 0s 606us/step - loss: 241125.6250 - val_loss: 238112.9531\n",
      "Epoch 27/300\n",
      "88/88 [==============================] - 0s 617us/step - loss: 240275.6562 - val_loss: 236828.6875\n",
      "Epoch 28/300\n",
      "88/88 [==============================] - 0s 568us/step - loss: 239150.4688 - val_loss: 236261.6562\n",
      "Epoch 29/300\n",
      "88/88 [==============================] - 0s 673us/step - loss: 238408.2031 - val_loss: 236007.1406\n",
      "Epoch 30/300\n",
      "88/88 [==============================] - 0s 604us/step - loss: 237536.4062 - val_loss: 234551.7344\n",
      "Epoch 31/300\n",
      "88/88 [==============================] - 0s 609us/step - loss: 237418.0625 - val_loss: 233567.0469\n",
      "Epoch 32/300\n",
      "88/88 [==============================] - 0s 610us/step - loss: 236817.8594 - val_loss: 232844.8906\n",
      "Epoch 33/300\n",
      "88/88 [==============================] - 0s 551us/step - loss: 236136.5312 - val_loss: 232827.2031\n",
      "Epoch 34/300\n",
      "88/88 [==============================] - 0s 516us/step - loss: 235761.2500 - val_loss: 231908.4688\n",
      "Epoch 35/300\n",
      "88/88 [==============================] - 0s 537us/step - loss: 235655.0781 - val_loss: 231646.6562\n",
      "Epoch 36/300\n",
      "88/88 [==============================] - 0s 522us/step - loss: 235381.0625 - val_loss: 231137.6250\n",
      "Epoch 37/300\n",
      "88/88 [==============================] - 0s 566us/step - loss: 235226.0312 - val_loss: 230964.6094\n",
      "Epoch 38/300\n",
      "88/88 [==============================] - 0s 538us/step - loss: 235427.0312 - val_loss: 230767.9062\n",
      "Epoch 39/300\n",
      "88/88 [==============================] - 0s 546us/step - loss: 234968.6562 - val_loss: 230447.8125\n",
      "Epoch 40/300\n",
      "88/88 [==============================] - 0s 523us/step - loss: 234724.9844 - val_loss: 231154.9688\n",
      "Epoch 41/300\n",
      "88/88 [==============================] - 0s 529us/step - loss: 234944.4844 - val_loss: 230473.4688\n",
      "Epoch 42/300\n",
      "88/88 [==============================] - 0s 514us/step - loss: 234663.5469 - val_loss: 230067.4844\n",
      "Epoch 43/300\n",
      "88/88 [==============================] - 0s 513us/step - loss: 234513.4219 - val_loss: 229865.9062\n",
      "Epoch 44/300\n",
      "88/88 [==============================] - 0s 532us/step - loss: 234613.2500 - val_loss: 229942.5781\n",
      "Epoch 45/300\n",
      "88/88 [==============================] - 0s 543us/step - loss: 234340.3281 - val_loss: 229681.3750\n",
      "Epoch 46/300\n",
      "88/88 [==============================] - 0s 540us/step - loss: 234539.7969 - val_loss: 229635.5625\n",
      "Epoch 47/300\n",
      "88/88 [==============================] - 0s 547us/step - loss: 234308.4219 - val_loss: 229534.1562\n",
      "Epoch 48/300\n",
      "88/88 [==============================] - 0s 521us/step - loss: 234351.1562 - val_loss: 229430.5000\n",
      "Epoch 49/300\n",
      "88/88 [==============================] - 0s 522us/step - loss: 234243.2812 - val_loss: 229451.2812\n",
      "Epoch 50/300\n",
      "88/88 [==============================] - 0s 528us/step - loss: 234338.4062 - val_loss: 230041.3125\n",
      "Epoch 51/300\n",
      "88/88 [==============================] - 0s 540us/step - loss: 234161.1875 - val_loss: 229618.4219\n",
      "Epoch 52/300\n",
      "88/88 [==============================] - 0s 532us/step - loss: 234638.1094 - val_loss: 229426.8750\n",
      "Epoch 53/300\n",
      "88/88 [==============================] - 0s 556us/step - loss: 234194.5781 - val_loss: 229236.8906\n",
      "Epoch 54/300\n",
      "88/88 [==============================] - 0s 546us/step - loss: 234288.3125 - val_loss: 230121.9531\n",
      "Epoch 55/300\n",
      "88/88 [==============================] - 0s 517us/step - loss: 234102.0000 - val_loss: 230333.8594\n",
      "Epoch 56/300\n",
      "88/88 [==============================] - 0s 517us/step - loss: 234080.0781 - val_loss: 229667.6250\n",
      "Epoch 57/300\n",
      "88/88 [==============================] - 0s 499us/step - loss: 234337.5000 - val_loss: 229328.2500\n",
      "Epoch 58/300\n",
      "88/88 [==============================] - 0s 516us/step - loss: 234246.9375 - val_loss: 229646.7969\n",
      "Epoch 59/300\n",
      "88/88 [==============================] - 0s 512us/step - loss: 234388.0938 - val_loss: 229330.1250\n",
      "Epoch 60/300\n",
      "88/88 [==============================] - 0s 508us/step - loss: 234106.8125 - val_loss: 229288.6250\n",
      "Epoch 61/300\n",
      "88/88 [==============================] - 0s 496us/step - loss: 234168.5625 - val_loss: 229387.0312\n",
      "Epoch 62/300\n",
      "88/88 [==============================] - 0s 529us/step - loss: 234267.1875 - val_loss: 229068.6406\n",
      "Epoch 63/300\n",
      "88/88 [==============================] - 0s 520us/step - loss: 234011.8594 - val_loss: 229102.3125\n",
      "Epoch 64/300\n",
      "88/88 [==============================] - 0s 499us/step - loss: 234153.1875 - val_loss: 229206.9844\n",
      "Epoch 65/300\n",
      "88/88 [==============================] - 0s 493us/step - loss: 234001.2344 - val_loss: 229060.1719\n",
      "Epoch 66/300\n",
      "88/88 [==============================] - 0s 527us/step - loss: 234082.1406 - val_loss: 228955.5938\n",
      "Epoch 67/300\n",
      "88/88 [==============================] - 0s 503us/step - loss: 234188.2344 - val_loss: 229151.6094\n",
      "Epoch 68/300\n",
      "88/88 [==============================] - 0s 501us/step - loss: 234091.9531 - val_loss: 228924.2500\n",
      "Epoch 69/300\n",
      "88/88 [==============================] - 0s 495us/step - loss: 233866.2500 - val_loss: 229106.4844\n",
      "Epoch 70/300\n",
      "88/88 [==============================] - 0s 519us/step - loss: 233972.3750 - val_loss: 228897.3281\n",
      "Epoch 71/300\n",
      "88/88 [==============================] - 0s 506us/step - loss: 234091.3750 - val_loss: 229174.8906\n",
      "Epoch 72/300\n",
      "88/88 [==============================] - 0s 501us/step - loss: 234186.8750 - val_loss: 228835.2812\n",
      "Epoch 73/300\n",
      "88/88 [==============================] - 0s 497us/step - loss: 234108.1406 - val_loss: 229243.2812\n",
      "Epoch 74/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 522us/step - loss: 234326.8750 - val_loss: 228818.7812\n",
      "Epoch 75/300\n",
      "88/88 [==============================] - 0s 490us/step - loss: 233589.5469 - val_loss: 230870.7500\n",
      "Epoch 76/300\n",
      "88/88 [==============================] - 0s 484us/step - loss: 234442.9844 - val_loss: 229645.2344\n",
      "Epoch 77/300\n",
      "88/88 [==============================] - 0s 515us/step - loss: 233908.9688 - val_loss: 228806.8438\n",
      "Epoch 78/300\n",
      "88/88 [==============================] - 0s 502us/step - loss: 233823.3750 - val_loss: 229249.8906\n",
      "Epoch 79/300\n",
      "88/88 [==============================] - 0s 498us/step - loss: 233891.8750 - val_loss: 229797.4531\n",
      "Epoch 80/300\n",
      "88/88 [==============================] - 0s 512us/step - loss: 233766.7656 - val_loss: 228729.0156\n",
      "Epoch 81/300\n",
      "88/88 [==============================] - 0s 496us/step - loss: 233897.1719 - val_loss: 228974.4062\n",
      "Epoch 82/300\n",
      "88/88 [==============================] - 0s 506us/step - loss: 234117.9531 - val_loss: 228783.9375\n",
      "Epoch 83/300\n",
      "88/88 [==============================] - 0s 506us/step - loss: 233896.0938 - val_loss: 228725.6875\n",
      "Epoch 84/300\n",
      "88/88 [==============================] - 0s 508us/step - loss: 233934.4531 - val_loss: 228910.4688\n",
      "Epoch 85/300\n",
      "88/88 [==============================] - 0s 496us/step - loss: 233800.3281 - val_loss: 229769.3594\n",
      "Epoch 86/300\n",
      "88/88 [==============================] - 0s 508us/step - loss: 233776.8594 - val_loss: 228708.5000\n",
      "Epoch 87/300\n",
      "88/88 [==============================] - 0s 516us/step - loss: 233793.8438 - val_loss: 228915.1719\n",
      "Epoch 88/300\n",
      "88/88 [==============================] - 0s 505us/step - loss: 233839.7031 - val_loss: 228762.0156\n",
      "Epoch 89/300\n",
      "88/88 [==============================] - 0s 482us/step - loss: 234235.6406 - val_loss: 228705.9688\n",
      "Epoch 90/300\n",
      "88/88 [==============================] - 0s 506us/step - loss: 233918.7031 - val_loss: 228565.4844\n",
      "Epoch 91/300\n",
      "88/88 [==============================] - 0s 508us/step - loss: 234297.5312 - val_loss: 228642.9688\n",
      "Epoch 92/300\n",
      "88/88 [==============================] - 0s 502us/step - loss: 233975.5469 - val_loss: 228566.7500\n",
      "Epoch 93/300\n",
      "88/88 [==============================] - 0s 498us/step - loss: 233977.1250 - val_loss: 228524.9219\n",
      "Epoch 94/300\n",
      "88/88 [==============================] - 0s 500us/step - loss: 233594.2031 - val_loss: 230640.7344\n",
      "Epoch 95/300\n",
      "88/88 [==============================] - 0s 499us/step - loss: 233707.1094 - val_loss: 228902.1406\n",
      "Epoch 96/300\n",
      "88/88 [==============================] - 0s 508us/step - loss: 233941.4844 - val_loss: 228387.9062\n",
      "Epoch 97/300\n",
      "88/88 [==============================] - 0s 515us/step - loss: 233755.1875 - val_loss: 228290.4375\n",
      "Epoch 98/300\n",
      "88/88 [==============================] - 0s 503us/step - loss: 233560.0938 - val_loss: 228475.6406\n",
      "Epoch 99/300\n",
      "88/88 [==============================] - 0s 510us/step - loss: 233091.2500 - val_loss: 231110.3906\n",
      "Epoch 100/300\n",
      "88/88 [==============================] - 0s 489us/step - loss: 233750.3594 - val_loss: 228208.7344\n",
      "Epoch 101/300\n",
      "88/88 [==============================] - 0s 506us/step - loss: 233349.8438 - val_loss: 228802.9844\n",
      "Epoch 102/300\n",
      "88/88 [==============================] - 0s 517us/step - loss: 233315.6406 - val_loss: 228233.8125\n",
      "Epoch 103/300\n",
      "88/88 [==============================] - 0s 486us/step - loss: 233279.2969 - val_loss: 228048.8906\n",
      "Epoch 104/300\n",
      "88/88 [==============================] - 0s 506us/step - loss: 233407.9531 - val_loss: 229877.3125\n",
      "Epoch 105/300\n",
      "88/88 [==============================] - 0s 504us/step - loss: 233393.2656 - val_loss: 227702.2500\n",
      "Epoch 106/300\n",
      "88/88 [==============================] - 0s 503us/step - loss: 233231.1875 - val_loss: 227792.8750\n",
      "Epoch 107/300\n",
      "88/88 [==============================] - 0s 493us/step - loss: 233377.8125 - val_loss: 228096.7344\n",
      "Epoch 108/300\n",
      "88/88 [==============================] - 0s 508us/step - loss: 233648.6094 - val_loss: 227496.1250\n",
      "Epoch 109/300\n",
      "88/88 [==============================] - 0s 508us/step - loss: 233020.0312 - val_loss: 227465.3594\n",
      "Epoch 110/300\n",
      "88/88 [==============================] - 0s 505us/step - loss: 233202.9688 - val_loss: 227621.3438\n",
      "Epoch 111/300\n",
      "88/88 [==============================] - 0s 500us/step - loss: 232816.1250 - val_loss: 227522.6875\n",
      "Epoch 112/300\n",
      "88/88 [==============================] - 0s 507us/step - loss: 232790.8281 - val_loss: 227130.5938\n",
      "Epoch 113/300\n",
      "88/88 [==============================] - 0s 517us/step - loss: 232717.2656 - val_loss: 227359.8438\n",
      "Epoch 114/300\n",
      "88/88 [==============================] - 0s 505us/step - loss: 232998.2969 - val_loss: 227836.3906\n",
      "Epoch 115/300\n",
      "88/88 [==============================] - 0s 505us/step - loss: 232540.3750 - val_loss: 227327.2188\n",
      "Epoch 116/300\n",
      "88/88 [==============================] - 0s 507us/step - loss: 232412.7656 - val_loss: 226852.1719\n",
      "Epoch 117/300\n",
      "88/88 [==============================] - 0s 510us/step - loss: 232108.4531 - val_loss: 226903.3906\n",
      "Epoch 118/300\n",
      "88/88 [==============================] - 0s 513us/step - loss: 232503.8438 - val_loss: 226868.4531\n",
      "Epoch 119/300\n",
      "88/88 [==============================] - 0s 500us/step - loss: 231987.2812 - val_loss: 226730.8906\n",
      "Epoch 120/300\n",
      "88/88 [==============================] - 0s 504us/step - loss: 232132.1250 - val_loss: 227201.0469\n",
      "Epoch 121/300\n",
      "88/88 [==============================] - 0s 530us/step - loss: 231986.6719 - val_loss: 226864.8281\n",
      "Epoch 122/300\n",
      "88/88 [==============================] - 0s 515us/step - loss: 232075.4375 - val_loss: 226020.8438\n",
      "Epoch 123/300\n",
      "88/88 [==============================] - 0s 500us/step - loss: 231557.8281 - val_loss: 226992.8906\n",
      "Epoch 124/300\n",
      "88/88 [==============================] - 0s 505us/step - loss: 231653.4531 - val_loss: 225527.3438\n",
      "Epoch 125/300\n",
      "88/88 [==============================] - 0s 512us/step - loss: 231315.9844 - val_loss: 225545.2500\n",
      "Epoch 126/300\n",
      "88/88 [==============================] - 0s 490us/step - loss: 230997.3438 - val_loss: 225323.1562\n",
      "Epoch 127/300\n",
      "88/88 [==============================] - 0s 503us/step - loss: 230883.6719 - val_loss: 225150.5000\n",
      "Epoch 128/300\n",
      "88/88 [==============================] - 0s 509us/step - loss: 230527.7031 - val_loss: 225418.6562\n",
      "Epoch 129/300\n",
      "88/88 [==============================] - 0s 517us/step - loss: 230541.5000 - val_loss: 224500.0156\n",
      "Epoch 130/300\n",
      "88/88 [==============================] - 0s 500us/step - loss: 230455.8750 - val_loss: 225030.3906\n",
      "Epoch 131/300\n",
      "88/88 [==============================] - 0s 507us/step - loss: 230222.7031 - val_loss: 224607.0000\n",
      "Epoch 132/300\n",
      "88/88 [==============================] - 0s 511us/step - loss: 229835.4688 - val_loss: 224033.2969\n",
      "Epoch 133/300\n",
      "88/88 [==============================] - 0s 515us/step - loss: 229795.9844 - val_loss: 223388.3750\n",
      "Epoch 134/300\n",
      "88/88 [==============================] - 0s 506us/step - loss: 229383.0938 - val_loss: 223313.8281\n",
      "Epoch 135/300\n",
      "88/88 [==============================] - 0s 504us/step - loss: 228880.2344 - val_loss: 223000.5625\n",
      "Epoch 136/300\n",
      "88/88 [==============================] - 0s 516us/step - loss: 229046.8906 - val_loss: 222491.9844\n",
      "Epoch 137/300\n",
      "88/88 [==============================] - 0s 512us/step - loss: 228838.4688 - val_loss: 222901.5312\n",
      "Epoch 138/300\n",
      "88/88 [==============================] - 0s 520us/step - loss: 228206.7812 - val_loss: 221756.6406\n",
      "Epoch 139/300\n",
      "88/88 [==============================] - 0s 505us/step - loss: 228118.5312 - val_loss: 221450.2188\n",
      "Epoch 140/300\n",
      "88/88 [==============================] - 0s 506us/step - loss: 227746.5469 - val_loss: 221161.5156\n",
      "Epoch 141/300\n",
      "88/88 [==============================] - 0s 485us/step - loss: 227354.2969 - val_loss: 221454.3125\n",
      "Epoch 142/300\n",
      "88/88 [==============================] - 0s 503us/step - loss: 226942.6094 - val_loss: 220292.7656\n",
      "Epoch 143/300\n",
      "88/88 [==============================] - 0s 496us/step - loss: 226943.9062 - val_loss: 220833.1250\n",
      "Epoch 144/300\n",
      "88/88 [==============================] - 0s 538us/step - loss: 226554.0156 - val_loss: 219911.7188\n",
      "Epoch 145/300\n",
      "88/88 [==============================] - 0s 506us/step - loss: 226052.4062 - val_loss: 219292.7656\n",
      "Epoch 146/300\n",
      "88/88 [==============================] - 0s 516us/step - loss: 225934.4531 - val_loss: 218802.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/300\n",
      "88/88 [==============================] - 0s 512us/step - loss: 225289.7500 - val_loss: 218523.3281\n",
      "Epoch 148/300\n",
      "88/88 [==============================] - 0s 508us/step - loss: 225177.1875 - val_loss: 218115.2031\n",
      "Epoch 149/300\n",
      "88/88 [==============================] - 0s 508us/step - loss: 224574.7188 - val_loss: 217940.5156\n",
      "Epoch 150/300\n",
      "88/88 [==============================] - 0s 521us/step - loss: 224335.5938 - val_loss: 217893.8594\n",
      "Epoch 151/300\n",
      "88/88 [==============================] - 0s 505us/step - loss: 224035.5312 - val_loss: 217153.6250\n",
      "Epoch 152/300\n",
      "88/88 [==============================] - 0s 501us/step - loss: 223758.9062 - val_loss: 216993.1250\n",
      "Epoch 153/300\n",
      "88/88 [==============================] - 0s 506us/step - loss: 223552.7812 - val_loss: 215835.0469\n",
      "Epoch 154/300\n",
      "88/88 [==============================] - 0s 505us/step - loss: 222931.8906 - val_loss: 215394.1250\n",
      "Epoch 155/300\n",
      "88/88 [==============================] - 0s 509us/step - loss: 222421.9375 - val_loss: 214991.9531\n",
      "Epoch 156/300\n",
      "88/88 [==============================] - 0s 505us/step - loss: 222046.2031 - val_loss: 214568.8125\n",
      "Epoch 157/300\n",
      "88/88 [==============================] - 0s 507us/step - loss: 221832.3594 - val_loss: 214214.8438\n",
      "Epoch 158/300\n",
      "88/88 [==============================] - 0s 510us/step - loss: 221810.0781 - val_loss: 213911.8750\n",
      "Epoch 159/300\n",
      "88/88 [==============================] - 0s 510us/step - loss: 221139.4688 - val_loss: 213810.9844\n",
      "Epoch 160/300\n",
      "88/88 [==============================] - 0s 502us/step - loss: 221043.2188 - val_loss: 212962.1250\n",
      "Epoch 161/300\n",
      "88/88 [==============================] - 0s 511us/step - loss: 220149.7031 - val_loss: 212505.5625\n",
      "Epoch 162/300\n",
      "88/88 [==============================] - 0s 510us/step - loss: 219930.8125 - val_loss: 212342.8281\n",
      "Epoch 163/300\n",
      "88/88 [==============================] - 0s 520us/step - loss: 219731.9062 - val_loss: 212407.0469\n",
      "Epoch 164/300\n",
      "88/88 [==============================] - 0s 504us/step - loss: 219065.1094 - val_loss: 210972.8750\n",
      "Epoch 165/300\n",
      "88/88 [==============================] - 0s 505us/step - loss: 218640.2344 - val_loss: 210505.6250\n",
      "Epoch 166/300\n",
      "88/88 [==============================] - 0s 497us/step - loss: 218337.5938 - val_loss: 209983.9375\n",
      "Epoch 167/300\n",
      "88/88 [==============================] - 0s 503us/step - loss: 217690.7188 - val_loss: 209681.6250\n",
      "Epoch 168/300\n",
      "88/88 [==============================] - 0s 506us/step - loss: 216873.2656 - val_loss: 208937.3125\n",
      "Epoch 169/300\n",
      "88/88 [==============================] - 0s 486us/step - loss: 216265.8906 - val_loss: 207973.2031\n",
      "Epoch 170/300\n",
      "88/88 [==============================] - 0s 510us/step - loss: 215636.7344 - val_loss: 207729.4531\n",
      "Epoch 171/300\n",
      "88/88 [==============================] - 0s 509us/step - loss: 215222.1562 - val_loss: 207152.4531\n",
      "Epoch 172/300\n",
      "88/88 [==============================] - 0s 510us/step - loss: 214713.7500 - val_loss: 206051.4219\n",
      "Epoch 173/300\n",
      "88/88 [==============================] - 0s 508us/step - loss: 214179.2500 - val_loss: 205284.1094\n",
      "Epoch 174/300\n",
      "88/88 [==============================] - 0s 500us/step - loss: 213585.5156 - val_loss: 205381.2969\n",
      "Epoch 175/300\n",
      "88/88 [==============================] - 0s 512us/step - loss: 212876.9219 - val_loss: 204070.1875\n",
      "Epoch 176/300\n",
      "88/88 [==============================] - 0s 504us/step - loss: 211892.9219 - val_loss: 204639.9062\n",
      "Epoch 177/300\n",
      "88/88 [==============================] - 0s 508us/step - loss: 211929.3906 - val_loss: 203586.6094\n",
      "Epoch 178/300\n",
      "88/88 [==============================] - 0s 506us/step - loss: 211227.2344 - val_loss: 202515.4062\n",
      "Epoch 179/300\n",
      "88/88 [==============================] - 0s 510us/step - loss: 210790.1250 - val_loss: 201359.5469\n",
      "Epoch 180/300\n",
      "88/88 [==============================] - 0s 511us/step - loss: 209923.4219 - val_loss: 201184.5312\n",
      "Epoch 181/300\n",
      "88/88 [==============================] - 0s 505us/step - loss: 208930.5469 - val_loss: 200523.1875\n",
      "Epoch 182/300\n",
      "88/88 [==============================] - 0s 509us/step - loss: 208635.7500 - val_loss: 200335.4688\n",
      "Epoch 183/300\n",
      "88/88 [==============================] - 0s 514us/step - loss: 208236.2031 - val_loss: 199263.6562\n",
      "Epoch 184/300\n",
      "88/88 [==============================] - 0s 490us/step - loss: 207540.1250 - val_loss: 198526.6250\n",
      "Epoch 185/300\n",
      "88/88 [==============================] - 0s 505us/step - loss: 206931.0625 - val_loss: 198200.9062\n",
      "Epoch 186/300\n",
      "88/88 [==============================] - 0s 490us/step - loss: 205816.2656 - val_loss: 198427.0469\n",
      "Epoch 187/300\n",
      "88/88 [==============================] - 0s 488us/step - loss: 205846.4688 - val_loss: 197079.5312\n",
      "Epoch 188/300\n",
      "88/88 [==============================] - 0s 512us/step - loss: 204723.8750 - val_loss: 196074.1875\n",
      "Epoch 189/300\n",
      "88/88 [==============================] - 0s 508us/step - loss: 204122.0469 - val_loss: 195400.1250\n",
      "Epoch 190/300\n",
      "88/88 [==============================] - 0s 513us/step - loss: 204108.0938 - val_loss: 194746.8594\n",
      "Epoch 191/300\n",
      "88/88 [==============================] - 0s 507us/step - loss: 203222.9062 - val_loss: 195053.9062\n",
      "Epoch 192/300\n",
      "88/88 [==============================] - 0s 500us/step - loss: 202323.0156 - val_loss: 193637.1562\n",
      "Epoch 193/300\n",
      "88/88 [==============================] - 0s 514us/step - loss: 201446.7500 - val_loss: 193357.1875\n",
      "Epoch 194/300\n",
      "88/88 [==============================] - 0s 516us/step - loss: 201384.4375 - val_loss: 192499.4531\n",
      "Epoch 195/300\n",
      "88/88 [==============================] - 0s 509us/step - loss: 200433.2500 - val_loss: 192084.6562\n",
      "Epoch 196/300\n",
      "88/88 [==============================] - 0s 498us/step - loss: 200310.6094 - val_loss: 192973.2656\n",
      "Epoch 197/300\n",
      "88/88 [==============================] - 0s 512us/step - loss: 199968.8281 - val_loss: 190683.2812\n",
      "Epoch 198/300\n",
      "88/88 [==============================] - 0s 515us/step - loss: 198695.6562 - val_loss: 190196.7188\n",
      "Epoch 199/300\n",
      "88/88 [==============================] - 0s 493us/step - loss: 197887.2188 - val_loss: 190428.4375\n",
      "Epoch 200/300\n",
      "88/88 [==============================] - 0s 498us/step - loss: 197894.8906 - val_loss: 189607.5312\n",
      "Epoch 201/300\n",
      "88/88 [==============================] - 0s 508us/step - loss: 196714.5625 - val_loss: 189184.6875\n",
      "Epoch 202/300\n",
      "88/88 [==============================] - 0s 527us/step - loss: 196275.2344 - val_loss: 188387.5000\n",
      "Epoch 203/300\n",
      "88/88 [==============================] - 0s 500us/step - loss: 196115.0625 - val_loss: 188876.3125\n",
      "Epoch 204/300\n",
      "88/88 [==============================] - 0s 497us/step - loss: 195278.7969 - val_loss: 186690.9844\n",
      "Epoch 205/300\n",
      "88/88 [==============================] - 0s 511us/step - loss: 194739.1250 - val_loss: 186619.6875\n",
      "Epoch 206/300\n",
      "88/88 [==============================] - 0s 515us/step - loss: 194068.8281 - val_loss: 185552.3125\n",
      "Epoch 207/300\n",
      "88/88 [==============================] - 0s 520us/step - loss: 193663.9531 - val_loss: 185528.5938\n",
      "Epoch 208/300\n",
      "88/88 [==============================] - 0s 500us/step - loss: 192372.7031 - val_loss: 184677.5781\n",
      "Epoch 209/300\n",
      "88/88 [==============================] - 0s 513us/step - loss: 192084.7500 - val_loss: 184241.0781\n",
      "Epoch 210/300\n",
      "88/88 [==============================] - 0s 513us/step - loss: 192079.6875 - val_loss: 183601.3125\n",
      "Epoch 211/300\n",
      "88/88 [==============================] - 0s 525us/step - loss: 190875.2344 - val_loss: 182778.0469\n",
      "Epoch 212/300\n",
      "88/88 [==============================] - 0s 498us/step - loss: 190861.2344 - val_loss: 182195.1562\n",
      "Epoch 213/300\n",
      "88/88 [==============================] - 0s 496us/step - loss: 189855.4219 - val_loss: 182292.3750\n",
      "Epoch 214/300\n",
      "88/88 [==============================] - 0s 534us/step - loss: 189681.4375 - val_loss: 181294.6094\n",
      "Epoch 215/300\n",
      "88/88 [==============================] - 0s 509us/step - loss: 188857.2344 - val_loss: 182819.5781\n",
      "Epoch 216/300\n",
      "88/88 [==============================] - 0s 513us/step - loss: 189084.4531 - val_loss: 180681.1875\n",
      "Epoch 217/300\n",
      "88/88 [==============================] - 0s 503us/step - loss: 188920.7812 - val_loss: 179637.3906\n",
      "Epoch 218/300\n",
      "88/88 [==============================] - 0s 514us/step - loss: 188122.3906 - val_loss: 179333.7500\n",
      "Epoch 219/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 511us/step - loss: 187331.0469 - val_loss: 178788.5469\n",
      "Epoch 220/300\n",
      "88/88 [==============================] - 0s 507us/step - loss: 186929.9062 - val_loss: 179706.1094\n",
      "Epoch 221/300\n",
      "88/88 [==============================] - 0s 522us/step - loss: 186641.4844 - val_loss: 178123.0312\n",
      "Epoch 222/300\n",
      "88/88 [==============================] - 0s 507us/step - loss: 186613.2969 - val_loss: 178403.6406\n",
      "Epoch 223/300\n",
      "88/88 [==============================] - 0s 503us/step - loss: 186258.0469 - val_loss: 178177.9844\n",
      "Epoch 224/300\n",
      "88/88 [==============================] - 0s 506us/step - loss: 186028.0000 - val_loss: 177948.2188\n",
      "Epoch 225/300\n",
      "88/88 [==============================] - 0s 508us/step - loss: 185337.6562 - val_loss: 176870.8594\n",
      "Epoch 226/300\n",
      "88/88 [==============================] - 0s 496us/step - loss: 185291.8438 - val_loss: 176506.4688\n",
      "Epoch 227/300\n",
      "88/88 [==============================] - 0s 514us/step - loss: 184259.6094 - val_loss: 176404.7969\n",
      "Epoch 228/300\n",
      "88/88 [==============================] - 0s 505us/step - loss: 183995.1250 - val_loss: 176801.2500\n",
      "Epoch 229/300\n",
      "88/88 [==============================] - 0s 509us/step - loss: 183786.4062 - val_loss: 176147.3594\n",
      "Epoch 230/300\n",
      "88/88 [==============================] - 0s 514us/step - loss: 183716.9844 - val_loss: 178665.1406\n",
      "Epoch 231/300\n",
      "88/88 [==============================] - 0s 488us/step - loss: 184382.0312 - val_loss: 176077.4688\n",
      "Epoch 232/300\n",
      "88/88 [==============================] - 0s 513us/step - loss: 183523.8438 - val_loss: 175248.5781\n",
      "Epoch 233/300\n",
      "88/88 [==============================] - 0s 524us/step - loss: 183871.9844 - val_loss: 174968.2969\n",
      "Epoch 234/300\n",
      "88/88 [==============================] - 0s 504us/step - loss: 183949.5000 - val_loss: 174837.7188\n",
      "Epoch 235/300\n",
      "88/88 [==============================] - 0s 512us/step - loss: 182271.3906 - val_loss: 174666.4062\n",
      "Epoch 236/300\n",
      "88/88 [==============================] - 0s 510us/step - loss: 182542.6406 - val_loss: 174877.6094\n",
      "Epoch 237/300\n",
      "88/88 [==============================] - 0s 510us/step - loss: 182472.2656 - val_loss: 174204.0781\n",
      "Epoch 238/300\n",
      "88/88 [==============================] - 0s 509us/step - loss: 182139.4375 - val_loss: 174225.2812\n",
      "Epoch 239/300\n",
      "88/88 [==============================] - 0s 490us/step - loss: 182737.2812 - val_loss: 173971.3125\n",
      "Epoch 240/300\n",
      "88/88 [==============================] - 0s 507us/step - loss: 181795.2500 - val_loss: 174535.9688\n",
      "Epoch 241/300\n",
      "88/88 [==============================] - 0s 509us/step - loss: 182098.2344 - val_loss: 173942.6250\n",
      "Epoch 242/300\n",
      "88/88 [==============================] - 0s 505us/step - loss: 182402.0938 - val_loss: 173705.0000\n",
      "Epoch 243/300\n",
      "88/88 [==============================] - 0s 498us/step - loss: 181195.9375 - val_loss: 174063.0469\n",
      "Epoch 244/300\n",
      "88/88 [==============================] - 0s 504us/step - loss: 181863.5156 - val_loss: 173336.7031\n",
      "Epoch 245/300\n",
      "88/88 [==============================] - 0s 521us/step - loss: 181134.4375 - val_loss: 175290.8906\n",
      "Epoch 246/300\n",
      "88/88 [==============================] - 0s 503us/step - loss: 181425.0000 - val_loss: 174267.1875\n",
      "Epoch 247/300\n",
      "88/88 [==============================] - 0s 505us/step - loss: 181271.2812 - val_loss: 173845.9531\n",
      "Epoch 248/300\n",
      "88/88 [==============================] - 0s 502us/step - loss: 181676.8125 - val_loss: 173505.4375\n",
      "Epoch 249/300\n",
      "88/88 [==============================] - 0s 517us/step - loss: 180906.1875 - val_loss: 173608.5000\n",
      "Epoch 250/300\n",
      "88/88 [==============================] - 0s 505us/step - loss: 180052.5000 - val_loss: 173742.0312\n",
      "Epoch 251/300\n",
      "88/88 [==============================] - 0s 514us/step - loss: 180499.7344 - val_loss: 172939.0156\n",
      "Epoch 252/300\n",
      "88/88 [==============================] - 0s 505us/step - loss: 180284.0469 - val_loss: 172972.1719\n",
      "Epoch 253/300\n",
      "88/88 [==============================] - 0s 511us/step - loss: 180333.7188 - val_loss: 172839.5000\n",
      "Epoch 254/300\n",
      "88/88 [==============================] - 0s 513us/step - loss: 179977.8125 - val_loss: 172509.8750\n",
      "Epoch 255/300\n",
      "88/88 [==============================] - 0s 515us/step - loss: 180412.1562 - val_loss: 172480.6719\n",
      "Epoch 256/300\n",
      "88/88 [==============================] - 0s 513us/step - loss: 179748.0312 - val_loss: 172439.6719\n",
      "Epoch 257/300\n",
      "88/88 [==============================] - 0s 507us/step - loss: 179898.2031 - val_loss: 172957.5781\n",
      "Epoch 258/300\n",
      "88/88 [==============================] - 0s 504us/step - loss: 179698.7969 - val_loss: 172351.9219\n",
      "Epoch 259/300\n",
      "88/88 [==============================] - 0s 497us/step - loss: 180074.9375 - val_loss: 171907.8438\n",
      "Epoch 260/300\n",
      "88/88 [==============================] - 0s 519us/step - loss: 180082.1875 - val_loss: 171707.2812\n",
      "Epoch 261/300\n",
      "88/88 [==============================] - 0s 504us/step - loss: 179196.9688 - val_loss: 171948.2969\n",
      "Epoch 262/300\n",
      "88/88 [==============================] - 0s 491us/step - loss: 179510.3438 - val_loss: 174776.5781\n",
      "Epoch 263/300\n",
      "88/88 [==============================] - 0s 506us/step - loss: 180570.5938 - val_loss: 171344.6562\n",
      "Epoch 264/300\n",
      "88/88 [==============================] - 0s 507us/step - loss: 179471.8594 - val_loss: 172829.9062\n",
      "Epoch 265/300\n",
      "88/88 [==============================] - 0s 518us/step - loss: 179419.1875 - val_loss: 171709.2500\n",
      "Epoch 266/300\n",
      "88/88 [==============================] - 0s 509us/step - loss: 179458.5938 - val_loss: 171163.0938\n",
      "Epoch 267/300\n",
      "88/88 [==============================] - 0s 505us/step - loss: 179189.3750 - val_loss: 171037.1094\n",
      "Epoch 268/300\n",
      "88/88 [==============================] - 0s 517us/step - loss: 179554.9688 - val_loss: 171760.4375\n",
      "Epoch 269/300\n",
      "88/88 [==============================] - 0s 509us/step - loss: 179957.4688 - val_loss: 170535.0312\n",
      "Epoch 270/300\n",
      "88/88 [==============================] - 0s 509us/step - loss: 178806.0781 - val_loss: 171199.3594\n",
      "Epoch 271/300\n",
      "88/88 [==============================] - 0s 491us/step - loss: 178957.4688 - val_loss: 171341.7812\n",
      "Epoch 272/300\n",
      "88/88 [==============================] - 0s 515us/step - loss: 178704.6875 - val_loss: 170624.9062\n",
      "Epoch 273/300\n",
      "88/88 [==============================] - 0s 518us/step - loss: 178824.1719 - val_loss: 170450.9688\n",
      "Epoch 274/300\n",
      "88/88 [==============================] - 0s 495us/step - loss: 178212.1562 - val_loss: 171293.0625\n",
      "Epoch 275/300\n",
      "88/88 [==============================] - 0s 503us/step - loss: 178873.1094 - val_loss: 171191.2969\n",
      "Epoch 276/300\n",
      "88/88 [==============================] - 0s 512us/step - loss: 178655.7656 - val_loss: 170273.9688\n",
      "Epoch 277/300\n",
      "88/88 [==============================] - 0s 506us/step - loss: 178640.7188 - val_loss: 172284.5469\n",
      "Epoch 278/300\n",
      "88/88 [==============================] - 0s 501us/step - loss: 178659.9219 - val_loss: 172256.0625\n",
      "Epoch 279/300\n",
      "88/88 [==============================] - 0s 498us/step - loss: 178413.5312 - val_loss: 170347.3906\n",
      "Epoch 280/300\n",
      "88/88 [==============================] - 0s 522us/step - loss: 178131.6875 - val_loss: 170250.3281\n",
      "Epoch 281/300\n",
      "88/88 [==============================] - 0s 512us/step - loss: 177773.2031 - val_loss: 170370.7188\n",
      "Epoch 282/300\n",
      "88/88 [==============================] - 0s 518us/step - loss: 179235.5000 - val_loss: 169900.2656\n",
      "Epoch 283/300\n",
      "88/88 [==============================] - 0s 503us/step - loss: 177758.0156 - val_loss: 170292.6406\n",
      "Epoch 284/300\n",
      "88/88 [==============================] - 0s 516us/step - loss: 177762.6562 - val_loss: 169811.0781\n",
      "Epoch 285/300\n",
      "88/88 [==============================] - 0s 486us/step - loss: 178741.4844 - val_loss: 170021.3906\n",
      "Epoch 286/300\n",
      "88/88 [==============================] - 0s 489us/step - loss: 177562.6875 - val_loss: 171419.2500\n",
      "Epoch 287/300\n",
      "88/88 [==============================] - 0s 487us/step - loss: 177872.8438 - val_loss: 170061.9844\n",
      "Epoch 288/300\n",
      "88/88 [==============================] - 0s 507us/step - loss: 177661.7344 - val_loss: 169618.7188\n",
      "Epoch 289/300\n",
      "88/88 [==============================] - 0s 500us/step - loss: 177250.2188 - val_loss: 169558.2031\n",
      "Epoch 290/300\n",
      "88/88 [==============================] - 0s 497us/step - loss: 177961.0000 - val_loss: 169632.1406\n",
      "Epoch 291/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 486us/step - loss: 177284.8594 - val_loss: 169095.5938\n",
      "Epoch 292/300\n",
      "88/88 [==============================] - 0s 503us/step - loss: 176370.2812 - val_loss: 175068.3281\n",
      "Epoch 293/300\n",
      "88/88 [==============================] - 0s 507us/step - loss: 178370.7188 - val_loss: 169078.2812\n",
      "Epoch 294/300\n",
      "88/88 [==============================] - 0s 498us/step - loss: 177162.0469 - val_loss: 169881.4844\n",
      "Epoch 295/300\n",
      "88/88 [==============================] - 0s 501us/step - loss: 177268.9062 - val_loss: 170756.9688\n",
      "Epoch 296/300\n",
      "88/88 [==============================] - 0s 509us/step - loss: 176891.1094 - val_loss: 170104.6094\n",
      "Epoch 297/300\n",
      "88/88 [==============================] - 0s 498us/step - loss: 176934.8594 - val_loss: 168797.0469\n",
      "Epoch 298/300\n",
      "88/88 [==============================] - 0s 499us/step - loss: 177154.3750 - val_loss: 169672.0938\n",
      "Epoch 299/300\n",
      "88/88 [==============================] - 0s 500us/step - loss: 177298.4062 - val_loss: 168452.9531\n",
      "Epoch 300/300\n",
      "88/88 [==============================] - 0s 496us/step - loss: 176353.2500 - val_loss: 170047.8438\n",
      "55/55 [==============================] - 0s 257us/step\n",
      "Mean Squared Error: 182160.89778748312\n",
      "Root Mean Squared Error: 426.80311361034273\n",
      "R-squared: 0.5492668841230668\n",
      "Adjusted R-squared: 0.5487514660374442\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "#from keras.layers import Dropout\n",
    "#model.add(Dropout(0.5)) \n",
    "\n",
    "#from keras.regularizers import l1, l2\n",
    "#model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1], kernel_regularizer=l2(0.01)))\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 10, restore_best_weights=True)\n",
    "model.fit(X_train_scaled, y_train, epochs = 300, batch_size = 64, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse_r = mean_squared_error(y_test, y_pred, squared = False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "n = len(y_test)\n",
    "k = X_train_scaled.shape[1]  \n",
    "adj_r2 = 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {mse_r}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Adjusted R-squared: {adj_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "82226ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 182160.89778748312\n",
      "Root Mean Squared Error: 426.80311361034273\n",
      "R-squared: 0.5492668841230668\n",
      "Adjusted R-squared: 0.5487514660374442\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {mse_r}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Adjusted R-squared: {adj_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "077803f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 247us/step\n",
      "55/55 [==============================] - 0s 234us/step\n",
      "Training MSE: 175837.1534937032\n",
      "Validation MSE: 182160.89778748312\n",
      "Huber Loss: [[ 84.10565186 266.10565186 147.10565186 ... 398.89434814  74.10565186\n",
      "  108.10565186]\n",
      " [115.5806427   65.4193573   52.5806427  ... 599.5806427  125.5806427\n",
      "   91.5806427 ]\n",
      " [ 97.43060303  83.56939697  34.43060303 ... 581.43060303 107.43060303\n",
      "   73.43060303]\n",
      " ...\n",
      " [653.83374023 835.83374023 716.83374023 ... 169.83374023 643.83374023\n",
      "  677.83374023]\n",
      " [171.47569275   9.52430725 108.47569275 ... 655.47569275 181.47569275\n",
      "  147.47569275]\n",
      " [232.24658203 414.24658203 295.24658203 ... 250.75341797 222.24658203\n",
      "  256.24658203]]\n",
      "Mean Huber Loss: 627.0388039451589\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.predict(X_train_scaled)\n",
    "test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "train_mse = mean_squared_error(y_train, train_pred)\n",
    "test_mse = mean_squared_error(y_test, test_pred)\n",
    "\n",
    "print(f'Training MSE: {train_mse}')\n",
    "print(f'Validation MSE: {test_mse}')\n",
    "\n",
    "import tensorflow as tf\n",
    "def huber_loss(y_test, y_pred, delta = 1.0):\n",
    "    error = y_test - y_pred\n",
    "    condition = tf.abs(error) < delta\n",
    "    squared_loss = 0.5 * tf.square(error)\n",
    "    linear_loss = delta * (tf.abs(error) - 0.5 * delta)\n",
    "    return tf.where(condition, squared_loss, linear_loss)\n",
    "\n",
    "loss = huber_loss(y_test, y_pred, delta = 1.0)\n",
    "print(\"Huber Loss:\", loss.numpy())\n",
    "\n",
    "mean_huber_loss = np.mean(loss)\n",
    "print(f\"Mean Huber Loss: {mean_huber_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a055dc2d",
   "metadata": {},
   "source": [
    "## 30% Training MSE: 190473.52005780334\n",
    "Validation MSE: 200931.60889353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c3b99ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 919380.3125 - val_loss: 918245.1250\n",
      "Epoch 2/300\n",
      "77/77 [==============================] - 0s 612us/step - loss: 917919.0000 - val_loss: 911409.9375\n",
      "Epoch 3/300\n",
      "77/77 [==============================] - 0s 610us/step - loss: 847333.5625 - val_loss: 686914.8750\n",
      "Epoch 4/300\n",
      "77/77 [==============================] - 0s 639us/step - loss: 438707.3750 - val_loss: 321354.1250\n",
      "Epoch 5/300\n",
      "77/77 [==============================] - 0s 593us/step - loss: 322707.1875 - val_loss: 315309.5625\n",
      "Epoch 6/300\n",
      "77/77 [==============================] - 0s 611us/step - loss: 316903.1250 - val_loss: 309393.0312\n",
      "Epoch 7/300\n",
      "77/77 [==============================] - 0s 609us/step - loss: 311280.2500 - val_loss: 303289.5625\n",
      "Epoch 8/300\n",
      "77/77 [==============================] - 0s 584us/step - loss: 305306.5312 - val_loss: 297312.5938\n",
      "Epoch 9/300\n",
      "77/77 [==============================] - 0s 592us/step - loss: 299310.8125 - val_loss: 290851.5625\n",
      "Epoch 10/300\n",
      "77/77 [==============================] - 0s 598us/step - loss: 293246.0938 - val_loss: 284634.1875\n",
      "Epoch 11/300\n",
      "77/77 [==============================] - 0s 627us/step - loss: 287318.4688 - val_loss: 278032.6875\n",
      "Epoch 12/300\n",
      "77/77 [==============================] - 0s 597us/step - loss: 281251.5625 - val_loss: 271599.2500\n",
      "Epoch 13/300\n",
      "77/77 [==============================] - 0s 599us/step - loss: 275734.6562 - val_loss: 265130.9688\n",
      "Epoch 14/300\n",
      "77/77 [==============================] - 0s 577us/step - loss: 269161.0625 - val_loss: 259496.1406\n",
      "Epoch 15/300\n",
      "77/77 [==============================] - 0s 592us/step - loss: 264413.3438 - val_loss: 253926.0312\n",
      "Epoch 16/300\n",
      "77/77 [==============================] - 0s 597us/step - loss: 260644.7188 - val_loss: 249310.5469\n",
      "Epoch 17/300\n",
      "77/77 [==============================] - 0s 631us/step - loss: 256147.9688 - val_loss: 244934.4219\n",
      "Epoch 18/300\n",
      "77/77 [==============================] - 0s 602us/step - loss: 252500.6875 - val_loss: 242079.6875\n",
      "Epoch 19/300\n",
      "77/77 [==============================] - 0s 602us/step - loss: 250320.7656 - val_loss: 238882.3594\n",
      "Epoch 20/300\n",
      "77/77 [==============================] - 0s 578us/step - loss: 247991.8750 - val_loss: 237071.9062\n",
      "Epoch 21/300\n",
      "77/77 [==============================] - 0s 591us/step - loss: 246712.3125 - val_loss: 234674.7812\n",
      "Epoch 22/300\n",
      "77/77 [==============================] - 0s 602us/step - loss: 245073.4688 - val_loss: 233069.9219\n",
      "Epoch 23/300\n",
      "77/77 [==============================] - 0s 597us/step - loss: 243734.2812 - val_loss: 231637.6562\n",
      "Epoch 24/300\n",
      "77/77 [==============================] - 0s 597us/step - loss: 242850.1406 - val_loss: 231658.7031\n",
      "Epoch 25/300\n",
      "77/77 [==============================] - 0s 594us/step - loss: 242163.1562 - val_loss: 229364.9375\n",
      "Epoch 26/300\n",
      "77/77 [==============================] - 0s 593us/step - loss: 241411.2656 - val_loss: 229330.7500\n",
      "Epoch 27/300\n",
      "77/77 [==============================] - 0s 606us/step - loss: 240807.6094 - val_loss: 227759.2031\n",
      "Epoch 28/300\n",
      "77/77 [==============================] - 0s 577us/step - loss: 240203.8125 - val_loss: 227947.3750\n",
      "Epoch 29/300\n",
      "77/77 [==============================] - 0s 625us/step - loss: 240267.6406 - val_loss: 227101.1406\n",
      "Epoch 30/300\n",
      "77/77 [==============================] - 0s 625us/step - loss: 239491.5000 - val_loss: 226133.8906\n",
      "Epoch 31/300\n",
      "77/77 [==============================] - 0s 604us/step - loss: 239269.7812 - val_loss: 226875.0469\n",
      "Epoch 32/300\n",
      "77/77 [==============================] - 0s 585us/step - loss: 239658.5938 - val_loss: 225556.9375\n",
      "Epoch 33/300\n",
      "77/77 [==============================] - 0s 605us/step - loss: 239007.3906 - val_loss: 225384.4062\n",
      "Epoch 34/300\n",
      "77/77 [==============================] - 0s 627us/step - loss: 239101.2031 - val_loss: 225138.4688\n",
      "Epoch 35/300\n",
      "77/77 [==============================] - 0s 625us/step - loss: 238612.0625 - val_loss: 224741.3125\n",
      "Epoch 36/300\n",
      "77/77 [==============================] - 0s 629us/step - loss: 238576.3906 - val_loss: 226317.3906\n",
      "Epoch 37/300\n",
      "77/77 [==============================] - 0s 563us/step - loss: 238677.8281 - val_loss: 224436.2969\n",
      "Epoch 38/300\n",
      "77/77 [==============================] - 0s 515us/step - loss: 238422.1875 - val_loss: 225030.3281\n",
      "Epoch 39/300\n",
      "77/77 [==============================] - 0s 518us/step - loss: 238528.6719 - val_loss: 224307.0625\n",
      "Epoch 40/300\n",
      "77/77 [==============================] - 0s 598us/step - loss: 238157.8750 - val_loss: 223973.8438\n",
      "Epoch 41/300\n",
      "77/77 [==============================] - 0s 646us/step - loss: 237722.2500 - val_loss: 224742.6094\n",
      "Epoch 42/300\n",
      "77/77 [==============================] - 0s 587us/step - loss: 238275.0625 - val_loss: 223875.4219\n",
      "Epoch 43/300\n",
      "77/77 [==============================] - 0s 617us/step - loss: 238375.0625 - val_loss: 224311.6875\n",
      "Epoch 44/300\n",
      "77/77 [==============================] - 0s 578us/step - loss: 237857.2656 - val_loss: 224188.9219\n",
      "Epoch 45/300\n",
      "77/77 [==============================] - 0s 612us/step - loss: 237547.2344 - val_loss: 223445.5000\n",
      "Epoch 46/300\n",
      "77/77 [==============================] - 0s 612us/step - loss: 237604.6406 - val_loss: 223729.8594\n",
      "Epoch 47/300\n",
      "77/77 [==============================] - 0s 618us/step - loss: 237827.3125 - val_loss: 223253.6875\n",
      "Epoch 48/300\n",
      "77/77 [==============================] - 0s 594us/step - loss: 237344.5625 - val_loss: 223367.6562\n",
      "Epoch 49/300\n",
      "77/77 [==============================] - 0s 608us/step - loss: 237593.8281 - val_loss: 223364.8281\n",
      "Epoch 50/300\n",
      "77/77 [==============================] - 0s 565us/step - loss: 237490.9844 - val_loss: 223709.4062\n",
      "Epoch 51/300\n",
      "77/77 [==============================] - 0s 619us/step - loss: 237552.1406 - val_loss: 223002.6250\n",
      "Epoch 52/300\n",
      "77/77 [==============================] - 0s 613us/step - loss: 237799.8281 - val_loss: 223056.1719\n",
      "Epoch 53/300\n",
      "77/77 [==============================] - 0s 601us/step - loss: 237281.9062 - val_loss: 223012.6875\n",
      "Epoch 54/300\n",
      "77/77 [==============================] - 0s 586us/step - loss: 237109.8281 - val_loss: 222735.4219\n",
      "Epoch 55/300\n",
      "77/77 [==============================] - 0s 567us/step - loss: 237163.3906 - val_loss: 222628.7969\n",
      "Epoch 56/300\n",
      "77/77 [==============================] - 0s 556us/step - loss: 237170.1719 - val_loss: 222686.8438\n",
      "Epoch 57/300\n",
      "77/77 [==============================] - 0s 572us/step - loss: 237038.3594 - val_loss: 222434.4688\n",
      "Epoch 58/300\n",
      "77/77 [==============================] - 0s 574us/step - loss: 236990.8438 - val_loss: 223151.6406\n",
      "Epoch 59/300\n",
      "77/77 [==============================] - 0s 581us/step - loss: 236946.0312 - val_loss: 222340.4219\n",
      "Epoch 60/300\n",
      "77/77 [==============================] - 0s 639us/step - loss: 236715.5469 - val_loss: 222767.3594\n",
      "Epoch 61/300\n",
      "77/77 [==============================] - 0s 646us/step - loss: 236862.0000 - val_loss: 222248.7500\n",
      "Epoch 62/300\n",
      "77/77 [==============================] - 0s 602us/step - loss: 236910.0000 - val_loss: 223066.2969\n",
      "Epoch 63/300\n",
      "77/77 [==============================] - 0s 617us/step - loss: 237110.3594 - val_loss: 222024.2500\n",
      "Epoch 64/300\n",
      "77/77 [==============================] - 0s 608us/step - loss: 237210.1250 - val_loss: 222284.0781\n",
      "Epoch 65/300\n",
      "77/77 [==============================] - 0s 582us/step - loss: 236573.7500 - val_loss: 222655.9531\n",
      "Epoch 66/300\n",
      "77/77 [==============================] - 0s 768us/step - loss: 236638.5000 - val_loss: 223063.6562\n",
      "Epoch 67/300\n",
      "77/77 [==============================] - 0s 641us/step - loss: 236777.2188 - val_loss: 222985.8438\n",
      "Epoch 68/300\n",
      "77/77 [==============================] - 0s 661us/step - loss: 236651.0156 - val_loss: 222065.2500\n",
      "Epoch 69/300\n",
      "77/77 [==============================] - 0s 633us/step - loss: 236433.5938 - val_loss: 221512.8125\n",
      "Epoch 70/300\n",
      "77/77 [==============================] - 0s 597us/step - loss: 236763.0938 - val_loss: 221806.8438\n",
      "Epoch 71/300\n",
      "77/77 [==============================] - 0s 542us/step - loss: 236241.2812 - val_loss: 222315.8750\n",
      "Epoch 72/300\n",
      "77/77 [==============================] - 0s 552us/step - loss: 236138.7812 - val_loss: 221312.8906\n",
      "Epoch 73/300\n",
      "77/77 [==============================] - 0s 589us/step - loss: 236120.4375 - val_loss: 221433.5938\n",
      "Epoch 74/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 553us/step - loss: 235910.3906 - val_loss: 221140.8594\n",
      "Epoch 75/300\n",
      "77/77 [==============================] - 0s 557us/step - loss: 236159.9531 - val_loss: 221437.1250\n",
      "Epoch 76/300\n",
      "77/77 [==============================] - 0s 563us/step - loss: 235997.1406 - val_loss: 221276.9219\n",
      "Epoch 77/300\n",
      "77/77 [==============================] - 0s 571us/step - loss: 235944.8438 - val_loss: 223626.0938\n",
      "Epoch 78/300\n",
      "77/77 [==============================] - 0s 559us/step - loss: 236000.8125 - val_loss: 221809.3906\n",
      "Epoch 79/300\n",
      "77/77 [==============================] - 0s 565us/step - loss: 235978.1875 - val_loss: 221223.4688\n",
      "Epoch 80/300\n",
      "77/77 [==============================] - 0s 571us/step - loss: 235703.7344 - val_loss: 220530.2500\n",
      "Epoch 81/300\n",
      "77/77 [==============================] - 0s 558us/step - loss: 235540.9219 - val_loss: 220557.6875\n",
      "Epoch 82/300\n",
      "77/77 [==============================] - 0s 563us/step - loss: 235482.7031 - val_loss: 220269.1406\n",
      "Epoch 83/300\n",
      "77/77 [==============================] - 0s 566us/step - loss: 235956.7969 - val_loss: 220135.3906\n",
      "Epoch 84/300\n",
      "77/77 [==============================] - 0s 568us/step - loss: 235660.1562 - val_loss: 220309.5000\n",
      "Epoch 85/300\n",
      "77/77 [==============================] - 0s 553us/step - loss: 234864.0781 - val_loss: 220144.1719\n",
      "Epoch 86/300\n",
      "77/77 [==============================] - 0s 557us/step - loss: 235229.8438 - val_loss: 221074.3750\n",
      "Epoch 87/300\n",
      "77/77 [==============================] - 0s 562us/step - loss: 235011.3594 - val_loss: 220410.0312\n",
      "Epoch 88/300\n",
      "77/77 [==============================] - 0s 564us/step - loss: 235057.0156 - val_loss: 219533.1719\n",
      "Epoch 89/300\n",
      "77/77 [==============================] - 0s 582us/step - loss: 234752.9062 - val_loss: 219340.5156\n",
      "Epoch 90/300\n",
      "77/77 [==============================] - 0s 558us/step - loss: 234884.3281 - val_loss: 219199.3438\n",
      "Epoch 91/300\n",
      "77/77 [==============================] - 0s 564us/step - loss: 234405.5312 - val_loss: 219704.7656\n",
      "Epoch 92/300\n",
      "77/77 [==============================] - 0s 568us/step - loss: 234506.9062 - val_loss: 219222.0312\n",
      "Epoch 93/300\n",
      "77/77 [==============================] - 0s 581us/step - loss: 234510.8750 - val_loss: 218768.8438\n",
      "Epoch 94/300\n",
      "77/77 [==============================] - 0s 557us/step - loss: 233938.6406 - val_loss: 219536.3125\n",
      "Epoch 95/300\n",
      "77/77 [==============================] - 0s 551us/step - loss: 233947.4375 - val_loss: 219756.1719\n",
      "Epoch 96/300\n",
      "77/77 [==============================] - 0s 581us/step - loss: 234119.9062 - val_loss: 218645.5625\n",
      "Epoch 97/300\n",
      "77/77 [==============================] - 0s 567us/step - loss: 233684.1562 - val_loss: 218462.1875\n",
      "Epoch 98/300\n",
      "77/77 [==============================] - 0s 558us/step - loss: 233808.9531 - val_loss: 218195.5625\n",
      "Epoch 99/300\n",
      "77/77 [==============================] - 0s 572us/step - loss: 233314.8750 - val_loss: 218444.3750\n",
      "Epoch 100/300\n",
      "77/77 [==============================] - 0s 572us/step - loss: 233340.9531 - val_loss: 217715.9688\n",
      "Epoch 101/300\n",
      "77/77 [==============================] - 0s 562us/step - loss: 233218.1719 - val_loss: 217249.4688\n",
      "Epoch 102/300\n",
      "77/77 [==============================] - 0s 579us/step - loss: 232949.5625 - val_loss: 217134.7344\n",
      "Epoch 103/300\n",
      "77/77 [==============================] - 0s 561us/step - loss: 232784.1875 - val_loss: 217497.5156\n",
      "Epoch 104/300\n",
      "77/77 [==============================] - 0s 556us/step - loss: 232547.5781 - val_loss: 216538.2031\n",
      "Epoch 105/300\n",
      "77/77 [==============================] - 0s 574us/step - loss: 232769.0000 - val_loss: 216658.3125\n",
      "Epoch 106/300\n",
      "77/77 [==============================] - 0s 567us/step - loss: 232154.0000 - val_loss: 216186.9688\n",
      "Epoch 107/300\n",
      "77/77 [==============================] - 0s 568us/step - loss: 231984.2812 - val_loss: 216131.9219\n",
      "Epoch 108/300\n",
      "77/77 [==============================] - 0s 568us/step - loss: 231619.3750 - val_loss: 215982.2969\n",
      "Epoch 109/300\n",
      "77/77 [==============================] - 0s 583us/step - loss: 231679.2656 - val_loss: 215613.8594\n",
      "Epoch 110/300\n",
      "77/77 [==============================] - 0s 582us/step - loss: 231288.9844 - val_loss: 215059.8594\n",
      "Epoch 111/300\n",
      "77/77 [==============================] - 0s 561us/step - loss: 231063.7656 - val_loss: 214590.8594\n",
      "Epoch 112/300\n",
      "77/77 [==============================] - 0s 581us/step - loss: 230689.6875 - val_loss: 214376.2969\n",
      "Epoch 113/300\n",
      "77/77 [==============================] - 0s 567us/step - loss: 230324.8125 - val_loss: 213977.3750\n",
      "Epoch 114/300\n",
      "77/77 [==============================] - 0s 552us/step - loss: 229977.2969 - val_loss: 214188.0781\n",
      "Epoch 115/300\n",
      "77/77 [==============================] - 0s 577us/step - loss: 229571.9531 - val_loss: 213646.2500\n",
      "Epoch 116/300\n",
      "77/77 [==============================] - 0s 568us/step - loss: 229712.0156 - val_loss: 212924.8906\n",
      "Epoch 117/300\n",
      "77/77 [==============================] - 0s 554us/step - loss: 229099.3906 - val_loss: 213085.0312\n",
      "Epoch 118/300\n",
      "77/77 [==============================] - 0s 575us/step - loss: 229007.3438 - val_loss: 212209.7812\n",
      "Epoch 119/300\n",
      "77/77 [==============================] - 0s 546us/step - loss: 228412.8750 - val_loss: 213227.3906\n",
      "Epoch 120/300\n",
      "77/77 [==============================] - 0s 562us/step - loss: 228302.7500 - val_loss: 211435.6250\n",
      "Epoch 121/300\n",
      "77/77 [==============================] - 0s 562us/step - loss: 227693.3906 - val_loss: 211716.1406\n",
      "Epoch 122/300\n",
      "77/77 [==============================] - 0s 587us/step - loss: 227438.7969 - val_loss: 211408.8438\n",
      "Epoch 123/300\n",
      "77/77 [==============================] - 0s 559us/step - loss: 227134.3438 - val_loss: 210684.6875\n",
      "Epoch 124/300\n",
      "77/77 [==============================] - 0s 574us/step - loss: 226917.7969 - val_loss: 211947.2188\n",
      "Epoch 125/300\n",
      "77/77 [==============================] - 0s 556us/step - loss: 226664.8750 - val_loss: 210064.7500\n",
      "Epoch 126/300\n",
      "77/77 [==============================] - 0s 567us/step - loss: 226395.0938 - val_loss: 209174.3906\n",
      "Epoch 127/300\n",
      "77/77 [==============================] - 0s 563us/step - loss: 225964.5781 - val_loss: 208980.4688\n",
      "Epoch 128/300\n",
      "77/77 [==============================] - 0s 579us/step - loss: 225403.3281 - val_loss: 208631.7656\n",
      "Epoch 129/300\n",
      "77/77 [==============================] - 0s 572us/step - loss: 225286.3125 - val_loss: 208191.9062\n",
      "Epoch 130/300\n",
      "77/77 [==============================] - 0s 559us/step - loss: 224754.0938 - val_loss: 207813.0625\n",
      "Epoch 131/300\n",
      "77/77 [==============================] - 0s 576us/step - loss: 224609.0781 - val_loss: 207562.4219\n",
      "Epoch 132/300\n",
      "77/77 [==============================] - 0s 550us/step - loss: 224577.2344 - val_loss: 207004.0938\n",
      "Epoch 133/300\n",
      "77/77 [==============================] - 0s 546us/step - loss: 223777.9531 - val_loss: 207111.2812\n",
      "Epoch 134/300\n",
      "77/77 [==============================] - 0s 570us/step - loss: 223764.0469 - val_loss: 206189.8281\n",
      "Epoch 135/300\n",
      "77/77 [==============================] - 0s 556us/step - loss: 222860.5781 - val_loss: 206285.8281\n",
      "Epoch 136/300\n",
      "77/77 [==============================] - 0s 568us/step - loss: 222990.2031 - val_loss: 205481.0156\n",
      "Epoch 137/300\n",
      "77/77 [==============================] - 0s 581us/step - loss: 222418.9062 - val_loss: 205395.5625\n",
      "Epoch 138/300\n",
      "77/77 [==============================] - 0s 570us/step - loss: 222736.0781 - val_loss: 204743.1562\n",
      "Epoch 139/300\n",
      "77/77 [==============================] - 0s 563us/step - loss: 221829.4062 - val_loss: 204621.6719\n",
      "Epoch 140/300\n",
      "77/77 [==============================] - 0s 564us/step - loss: 221850.3281 - val_loss: 204077.8281\n",
      "Epoch 141/300\n",
      "77/77 [==============================] - 0s 568us/step - loss: 221729.1406 - val_loss: 203932.9062\n",
      "Epoch 142/300\n",
      "77/77 [==============================] - 0s 562us/step - loss: 221209.8125 - val_loss: 203262.5312\n",
      "Epoch 143/300\n",
      "77/77 [==============================] - 0s 580us/step - loss: 220732.7031 - val_loss: 202764.7969\n",
      "Epoch 144/300\n",
      "77/77 [==============================] - 0s 572us/step - loss: 219906.2656 - val_loss: 202066.0781\n",
      "Epoch 145/300\n",
      "77/77 [==============================] - 0s 559us/step - loss: 219355.2344 - val_loss: 201207.5625\n",
      "Epoch 146/300\n",
      "77/77 [==============================] - 0s 545us/step - loss: 218961.3125 - val_loss: 202213.3438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/300\n",
      "77/77 [==============================] - 0s 556us/step - loss: 217899.3906 - val_loss: 199991.5156\n",
      "Epoch 148/300\n",
      "77/77 [==============================] - 0s 568us/step - loss: 217393.0781 - val_loss: 199684.1406\n",
      "Epoch 149/300\n",
      "77/77 [==============================] - 0s 554us/step - loss: 217121.4844 - val_loss: 201003.7188\n",
      "Epoch 150/300\n",
      "77/77 [==============================] - 0s 550us/step - loss: 217530.6562 - val_loss: 198532.9688\n",
      "Epoch 151/300\n",
      "77/77 [==============================] - 0s 567us/step - loss: 216061.9688 - val_loss: 197825.0625\n",
      "Epoch 152/300\n",
      "77/77 [==============================] - 0s 558us/step - loss: 215541.7031 - val_loss: 197673.4531\n",
      "Epoch 153/300\n",
      "77/77 [==============================] - 0s 552us/step - loss: 214863.4219 - val_loss: 197287.5312\n",
      "Epoch 154/300\n",
      "77/77 [==============================] - 0s 566us/step - loss: 214260.9219 - val_loss: 196594.3594\n",
      "Epoch 155/300\n",
      "77/77 [==============================] - 0s 573us/step - loss: 214183.6094 - val_loss: 195973.2969\n",
      "Epoch 156/300\n",
      "77/77 [==============================] - 0s 562us/step - loss: 213346.0469 - val_loss: 196401.2969\n",
      "Epoch 157/300\n",
      "77/77 [==============================] - 0s 563us/step - loss: 212987.7969 - val_loss: 194583.0312\n",
      "Epoch 158/300\n",
      "77/77 [==============================] - 0s 558us/step - loss: 212206.3906 - val_loss: 195540.9688\n",
      "Epoch 159/300\n",
      "77/77 [==============================] - 0s 558us/step - loss: 212324.1250 - val_loss: 194108.5625\n",
      "Epoch 160/300\n",
      "77/77 [==============================] - 0s 577us/step - loss: 211490.0312 - val_loss: 193583.8438\n",
      "Epoch 161/300\n",
      "77/77 [==============================] - 0s 557us/step - loss: 210998.4062 - val_loss: 193107.8750\n",
      "Epoch 162/300\n",
      "77/77 [==============================] - 0s 558us/step - loss: 209746.6875 - val_loss: 195117.5781\n",
      "Epoch 163/300\n",
      "77/77 [==============================] - 0s 564us/step - loss: 210063.4531 - val_loss: 191249.2188\n",
      "Epoch 164/300\n",
      "77/77 [==============================] - 0s 563us/step - loss: 208988.3594 - val_loss: 190358.8906\n",
      "Epoch 165/300\n",
      "77/77 [==============================] - 0s 561us/step - loss: 208510.2500 - val_loss: 192408.7344\n",
      "Epoch 166/300\n",
      "77/77 [==============================] - 0s 571us/step - loss: 207590.5469 - val_loss: 189532.3750\n",
      "Epoch 167/300\n",
      "77/77 [==============================] - 0s 571us/step - loss: 206780.8594 - val_loss: 188589.9219\n",
      "Epoch 168/300\n",
      "77/77 [==============================] - 0s 554us/step - loss: 206186.4062 - val_loss: 189076.6406\n",
      "Epoch 169/300\n",
      "77/77 [==============================] - 0s 585us/step - loss: 205466.9375 - val_loss: 187268.5625\n",
      "Epoch 170/300\n",
      "77/77 [==============================] - 0s 559us/step - loss: 204859.8438 - val_loss: 189832.5000\n",
      "Epoch 171/300\n",
      "77/77 [==============================] - 0s 555us/step - loss: 204110.9375 - val_loss: 186216.5938\n",
      "Epoch 172/300\n",
      "77/77 [==============================] - 0s 575us/step - loss: 202881.6406 - val_loss: 186499.0156\n",
      "Epoch 173/300\n",
      "77/77 [==============================] - 0s 576us/step - loss: 202819.6719 - val_loss: 185528.9062\n",
      "Epoch 174/300\n",
      "77/77 [==============================] - 0s 555us/step - loss: 201913.5625 - val_loss: 185315.0938\n",
      "Epoch 175/300\n",
      "77/77 [==============================] - 0s 571us/step - loss: 201365.5469 - val_loss: 182902.1406\n",
      "Epoch 176/300\n",
      "77/77 [==============================] - 0s 572us/step - loss: 200072.1406 - val_loss: 182283.4844\n",
      "Epoch 177/300\n",
      "77/77 [==============================] - 0s 561us/step - loss: 199912.5000 - val_loss: 182007.2188\n",
      "Epoch 178/300\n",
      "77/77 [==============================] - 0s 570us/step - loss: 199319.0469 - val_loss: 181237.9062\n",
      "Epoch 179/300\n",
      "77/77 [==============================] - 0s 561us/step - loss: 199451.7344 - val_loss: 181092.6719\n",
      "Epoch 180/300\n",
      "77/77 [==============================] - 0s 561us/step - loss: 198253.2344 - val_loss: 181475.8281\n",
      "Epoch 181/300\n",
      "77/77 [==============================] - 0s 564us/step - loss: 197367.3906 - val_loss: 179466.5312\n",
      "Epoch 182/300\n",
      "77/77 [==============================] - 0s 564us/step - loss: 196721.0781 - val_loss: 178819.2031\n",
      "Epoch 183/300\n",
      "77/77 [==============================] - 0s 564us/step - loss: 196703.8438 - val_loss: 178365.4844\n",
      "Epoch 184/300\n",
      "77/77 [==============================] - 0s 573us/step - loss: 195746.8750 - val_loss: 178185.6562\n",
      "Epoch 185/300\n",
      "77/77 [==============================] - 0s 586us/step - loss: 195161.6875 - val_loss: 177357.4688\n",
      "Epoch 186/300\n",
      "77/77 [==============================] - 0s 549us/step - loss: 194921.9688 - val_loss: 177156.8438\n",
      "Epoch 187/300\n",
      "77/77 [==============================] - 0s 575us/step - loss: 194396.0781 - val_loss: 176803.2188\n",
      "Epoch 188/300\n",
      "77/77 [==============================] - 0s 574us/step - loss: 194309.3750 - val_loss: 176271.0000\n",
      "Epoch 189/300\n",
      "77/77 [==============================] - 0s 562us/step - loss: 193399.4219 - val_loss: 175397.3438\n",
      "Epoch 190/300\n",
      "77/77 [==============================] - 0s 567us/step - loss: 193021.6562 - val_loss: 174796.5156\n",
      "Epoch 191/300\n",
      "77/77 [==============================] - 0s 566us/step - loss: 192353.1562 - val_loss: 174740.2969\n",
      "Epoch 192/300\n",
      "77/77 [==============================] - 0s 559us/step - loss: 192000.1719 - val_loss: 175186.6719\n",
      "Epoch 193/300\n",
      "77/77 [==============================] - 0s 554us/step - loss: 191812.2656 - val_loss: 175239.1875\n",
      "Epoch 194/300\n",
      "77/77 [==============================] - 0s 575us/step - loss: 192197.6094 - val_loss: 173517.0781\n",
      "Epoch 195/300\n",
      "77/77 [==============================] - 0s 569us/step - loss: 191477.9688 - val_loss: 173239.3594\n",
      "Epoch 196/300\n",
      "77/77 [==============================] - 0s 557us/step - loss: 190541.7344 - val_loss: 173574.4219\n",
      "Epoch 197/300\n",
      "77/77 [==============================] - 0s 575us/step - loss: 190975.5625 - val_loss: 172799.1094\n",
      "Epoch 198/300\n",
      "77/77 [==============================] - 0s 561us/step - loss: 189889.4688 - val_loss: 172426.3906\n",
      "Epoch 199/300\n",
      "77/77 [==============================] - 0s 553us/step - loss: 190573.8906 - val_loss: 174074.9844\n",
      "Epoch 200/300\n",
      "77/77 [==============================] - 0s 582us/step - loss: 189844.9375 - val_loss: 171850.8906\n",
      "Epoch 201/300\n",
      "77/77 [==============================] - 0s 576us/step - loss: 189010.3281 - val_loss: 171560.7812\n",
      "Epoch 202/300\n",
      "77/77 [==============================] - 0s 554us/step - loss: 188478.6406 - val_loss: 171661.4688\n",
      "Epoch 203/300\n",
      "77/77 [==============================] - 0s 580us/step - loss: 189207.7656 - val_loss: 170989.6406\n",
      "Epoch 204/300\n",
      "77/77 [==============================] - 0s 584us/step - loss: 188536.8594 - val_loss: 170687.9844\n",
      "Epoch 205/300\n",
      "77/77 [==============================] - 0s 557us/step - loss: 188169.0469 - val_loss: 171267.1562\n",
      "Epoch 206/300\n",
      "77/77 [==============================] - 0s 558us/step - loss: 188100.4688 - val_loss: 170501.7500\n",
      "Epoch 207/300\n",
      "77/77 [==============================] - 0s 586us/step - loss: 187595.4219 - val_loss: 171511.7969\n",
      "Epoch 208/300\n",
      "77/77 [==============================] - 0s 553us/step - loss: 187269.5625 - val_loss: 169741.4219\n",
      "Epoch 209/300\n",
      "77/77 [==============================] - 0s 565us/step - loss: 187266.5938 - val_loss: 169589.6250\n",
      "Epoch 210/300\n",
      "77/77 [==============================] - 0s 560us/step - loss: 186897.2500 - val_loss: 169436.9531\n",
      "Epoch 211/300\n",
      "77/77 [==============================] - 0s 560us/step - loss: 187281.1719 - val_loss: 169156.0781\n",
      "Epoch 212/300\n",
      "77/77 [==============================] - 0s 539us/step - loss: 187395.5938 - val_loss: 170276.8594\n",
      "Epoch 213/300\n",
      "77/77 [==============================] - 0s 546us/step - loss: 186603.8438 - val_loss: 170586.6406\n",
      "Epoch 214/300\n",
      "77/77 [==============================] - 0s 547us/step - loss: 186473.0156 - val_loss: 168746.0938\n",
      "Epoch 215/300\n",
      "77/77 [==============================] - 0s 552us/step - loss: 186008.2500 - val_loss: 168379.0625\n",
      "Epoch 216/300\n",
      "77/77 [==============================] - 0s 560us/step - loss: 186117.5781 - val_loss: 168214.5156\n",
      "Epoch 217/300\n",
      "77/77 [==============================] - 0s 537us/step - loss: 185767.0781 - val_loss: 168006.1875\n",
      "Epoch 218/300\n",
      "77/77 [==============================] - 0s 590us/step - loss: 185220.8594 - val_loss: 168031.4531\n",
      "Epoch 219/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 537us/step - loss: 185600.4062 - val_loss: 168128.7188\n",
      "Epoch 220/300\n",
      "77/77 [==============================] - 0s 547us/step - loss: 185064.6875 - val_loss: 168428.3750\n",
      "Epoch 221/300\n",
      "77/77 [==============================] - 0s 569us/step - loss: 185758.8281 - val_loss: 167194.3750\n",
      "Epoch 222/300\n",
      "77/77 [==============================] - 0s 567us/step - loss: 185116.3594 - val_loss: 166972.7188\n",
      "Epoch 223/300\n",
      "77/77 [==============================] - 0s 558us/step - loss: 185012.3125 - val_loss: 167428.7500\n",
      "Epoch 224/300\n",
      "77/77 [==============================] - 0s 559us/step - loss: 184553.0156 - val_loss: 166910.3438\n",
      "Epoch 225/300\n",
      "77/77 [==============================] - 0s 566us/step - loss: 184566.3906 - val_loss: 167524.0625\n",
      "Epoch 226/300\n",
      "77/77 [==============================] - 0s 555us/step - loss: 184202.1719 - val_loss: 167823.1406\n",
      "Epoch 227/300\n",
      "77/77 [==============================] - 0s 569us/step - loss: 184961.5938 - val_loss: 166473.0781\n",
      "Epoch 228/300\n",
      "77/77 [==============================] - 0s 557us/step - loss: 185018.5938 - val_loss: 168521.2031\n",
      "Epoch 229/300\n",
      "77/77 [==============================] - 0s 570us/step - loss: 184284.4375 - val_loss: 166058.0625\n",
      "Epoch 230/300\n",
      "77/77 [==============================] - 0s 566us/step - loss: 184055.0156 - val_loss: 165987.7812\n",
      "Epoch 231/300\n",
      "77/77 [==============================] - 0s 561us/step - loss: 184164.4375 - val_loss: 167486.3750\n",
      "Epoch 232/300\n",
      "77/77 [==============================] - 0s 553us/step - loss: 184755.6719 - val_loss: 167364.3594\n",
      "Epoch 233/300\n",
      "77/77 [==============================] - 0s 552us/step - loss: 183700.8438 - val_loss: 166940.1562\n",
      "Epoch 234/300\n",
      "77/77 [==============================] - 0s 560us/step - loss: 183682.4062 - val_loss: 165466.4688\n",
      "Epoch 235/300\n",
      "77/77 [==============================] - 0s 564us/step - loss: 183863.7031 - val_loss: 166043.9062\n",
      "Epoch 236/300\n",
      "77/77 [==============================] - 0s 567us/step - loss: 183722.9219 - val_loss: 165777.2812\n",
      "Epoch 237/300\n",
      "77/77 [==============================] - 0s 565us/step - loss: 183378.1875 - val_loss: 166735.2031\n",
      "Epoch 238/300\n",
      "77/77 [==============================] - 0s 566us/step - loss: 183228.5469 - val_loss: 165447.2812\n",
      "Epoch 239/300\n",
      "77/77 [==============================] - 0s 568us/step - loss: 184011.9844 - val_loss: 165444.8594\n",
      "Epoch 240/300\n",
      "77/77 [==============================] - 0s 573us/step - loss: 183049.2344 - val_loss: 165168.8750\n",
      "Epoch 241/300\n",
      "77/77 [==============================] - 0s 565us/step - loss: 183493.1250 - val_loss: 165229.9219\n",
      "Epoch 242/300\n",
      "77/77 [==============================] - 0s 556us/step - loss: 183030.7812 - val_loss: 165887.2812\n",
      "Epoch 243/300\n",
      "77/77 [==============================] - 0s 581us/step - loss: 183691.0625 - val_loss: 165684.3438\n",
      "Epoch 244/300\n",
      "77/77 [==============================] - 0s 566us/step - loss: 182418.5781 - val_loss: 166882.9688\n",
      "Epoch 245/300\n",
      "77/77 [==============================] - 0s 552us/step - loss: 182951.8906 - val_loss: 165096.2031\n",
      "Epoch 246/300\n",
      "77/77 [==============================] - 0s 574us/step - loss: 183536.1719 - val_loss: 164636.2344\n",
      "Epoch 247/300\n",
      "77/77 [==============================] - 0s 567us/step - loss: 182324.1562 - val_loss: 164869.8906\n",
      "Epoch 248/300\n",
      "77/77 [==============================] - 0s 556us/step - loss: 183236.2031 - val_loss: 165096.1094\n",
      "Epoch 249/300\n",
      "77/77 [==============================] - 0s 569us/step - loss: 182192.2188 - val_loss: 165440.8594\n",
      "Epoch 250/300\n",
      "77/77 [==============================] - 0s 564us/step - loss: 183123.3438 - val_loss: 165651.1406\n",
      "Epoch 251/300\n",
      "77/77 [==============================] - 0s 560us/step - loss: 182981.6406 - val_loss: 164171.2812\n",
      "Epoch 252/300\n",
      "77/77 [==============================] - 0s 572us/step - loss: 182923.7812 - val_loss: 164059.5000\n",
      "Epoch 253/300\n",
      "77/77 [==============================] - 0s 565us/step - loss: 182021.2656 - val_loss: 163887.6875\n",
      "Epoch 254/300\n",
      "77/77 [==============================] - 0s 559us/step - loss: 182657.2188 - val_loss: 164504.2969\n",
      "Epoch 255/300\n",
      "77/77 [==============================] - 0s 570us/step - loss: 182560.2656 - val_loss: 165060.6875\n",
      "Epoch 256/300\n",
      "77/77 [==============================] - 0s 564us/step - loss: 182354.9531 - val_loss: 164253.8906\n",
      "Epoch 257/300\n",
      "77/77 [==============================] - 0s 556us/step - loss: 181977.2344 - val_loss: 165476.4531\n",
      "Epoch 258/300\n",
      "77/77 [==============================] - 0s 571us/step - loss: 182583.5938 - val_loss: 164835.1250\n",
      "Epoch 259/300\n",
      "77/77 [==============================] - 0s 561us/step - loss: 181483.8281 - val_loss: 163892.8125\n",
      "Epoch 260/300\n",
      "77/77 [==============================] - 0s 565us/step - loss: 181558.5156 - val_loss: 164887.7344\n",
      "Epoch 261/300\n",
      "77/77 [==============================] - 0s 574us/step - loss: 181974.4844 - val_loss: 164998.6094\n",
      "Epoch 262/300\n",
      "77/77 [==============================] - 0s 565us/step - loss: 181476.9062 - val_loss: 163596.5156\n",
      "Epoch 263/300\n",
      "77/77 [==============================] - 0s 556us/step - loss: 181930.8438 - val_loss: 164185.8906\n",
      "Epoch 264/300\n",
      "77/77 [==============================] - 0s 573us/step - loss: 181526.3594 - val_loss: 163684.6406\n",
      "Epoch 265/300\n",
      "77/77 [==============================] - 0s 551us/step - loss: 181359.8594 - val_loss: 163488.4375\n",
      "Epoch 266/300\n",
      "77/77 [==============================] - 0s 560us/step - loss: 180985.6250 - val_loss: 163656.6562\n",
      "Epoch 267/300\n",
      "77/77 [==============================] - 0s 571us/step - loss: 181125.0469 - val_loss: 167002.5312\n",
      "Epoch 268/300\n",
      "77/77 [==============================] - 0s 579us/step - loss: 181583.7031 - val_loss: 163301.7812\n",
      "Epoch 269/300\n",
      "77/77 [==============================] - 0s 559us/step - loss: 181138.9844 - val_loss: 163145.0469\n",
      "Epoch 270/300\n",
      "77/77 [==============================] - 0s 565us/step - loss: 182203.4531 - val_loss: 164021.3438\n",
      "Epoch 271/300\n",
      "77/77 [==============================] - 0s 545us/step - loss: 180639.5156 - val_loss: 165287.6250\n",
      "Epoch 272/300\n",
      "77/77 [==============================] - 0s 548us/step - loss: 180782.3438 - val_loss: 164231.2500\n",
      "Epoch 273/300\n",
      "77/77 [==============================] - 0s 574us/step - loss: 181133.5625 - val_loss: 163809.5938\n",
      "Epoch 274/300\n",
      "77/77 [==============================] - 0s 572us/step - loss: 181527.0625 - val_loss: 162747.4062\n",
      "Epoch 275/300\n",
      "77/77 [==============================] - 0s 553us/step - loss: 180884.9062 - val_loss: 165775.4219\n",
      "Epoch 276/300\n",
      "77/77 [==============================] - 0s 564us/step - loss: 181426.9219 - val_loss: 163906.2812\n",
      "Epoch 277/300\n",
      "77/77 [==============================] - 0s 549us/step - loss: 181295.5000 - val_loss: 167143.7812\n",
      "Epoch 278/300\n",
      "77/77 [==============================] - 0s 545us/step - loss: 181011.3594 - val_loss: 165354.1406\n",
      "Epoch 279/300\n",
      "77/77 [==============================] - 0s 567us/step - loss: 180852.7031 - val_loss: 163216.3906\n",
      "Epoch 280/300\n",
      "77/77 [==============================] - 0s 575us/step - loss: 180596.8125 - val_loss: 162659.6250\n",
      "Epoch 281/300\n",
      "77/77 [==============================] - 0s 555us/step - loss: 180414.9844 - val_loss: 162783.5625\n",
      "Epoch 282/300\n",
      "77/77 [==============================] - 0s 581us/step - loss: 180709.2031 - val_loss: 162925.4219\n",
      "Epoch 283/300\n",
      "77/77 [==============================] - 0s 543us/step - loss: 181360.5312 - val_loss: 162965.1406\n",
      "Epoch 284/300\n",
      "77/77 [==============================] - 0s 543us/step - loss: 180907.1875 - val_loss: 163638.0312\n",
      "Epoch 285/300\n",
      "77/77 [==============================] - 0s 553us/step - loss: 180635.4062 - val_loss: 165494.0781\n",
      "Epoch 286/300\n",
      "77/77 [==============================] - 0s 543us/step - loss: 181749.9375 - val_loss: 163763.8594\n",
      "Epoch 287/300\n",
      "77/77 [==============================] - 0s 568us/step - loss: 180119.0781 - val_loss: 163942.3750\n",
      "Epoch 288/300\n",
      "77/77 [==============================] - 0s 579us/step - loss: 180945.3906 - val_loss: 162436.2031\n",
      "Epoch 289/300\n",
      "77/77 [==============================] - 0s 570us/step - loss: 180424.7500 - val_loss: 163701.6719\n",
      "Epoch 290/300\n",
      "77/77 [==============================] - 0s 555us/step - loss: 180984.8438 - val_loss: 163087.5000\n",
      "Epoch 291/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 554us/step - loss: 180298.5469 - val_loss: 162437.3750\n",
      "Epoch 292/300\n",
      "77/77 [==============================] - 0s 556us/step - loss: 180300.7344 - val_loss: 162357.6250\n",
      "Epoch 293/300\n",
      "77/77 [==============================] - 0s 555us/step - loss: 179470.9219 - val_loss: 162535.8281\n",
      "Epoch 294/300\n",
      "77/77 [==============================] - 0s 565us/step - loss: 179418.4688 - val_loss: 163126.6719\n",
      "Epoch 295/300\n",
      "77/77 [==============================] - 0s 568us/step - loss: 180049.2812 - val_loss: 162586.7969\n",
      "Epoch 296/300\n",
      "77/77 [==============================] - 0s 559us/step - loss: 180410.2344 - val_loss: 161979.6719\n",
      "Epoch 297/300\n",
      "77/77 [==============================] - 0s 568us/step - loss: 179504.7344 - val_loss: 161869.6406\n",
      "Epoch 298/300\n",
      "77/77 [==============================] - 0s 544us/step - loss: 179465.7031 - val_loss: 162539.1094\n",
      "Epoch 299/300\n",
      "77/77 [==============================] - 0s 558us/step - loss: 181011.5781 - val_loss: 162461.2969\n",
      "Epoch 300/300\n",
      "77/77 [==============================] - 0s 552us/step - loss: 179904.1719 - val_loss: 162571.5156\n",
      "Mean Squared Error: 182160.89778748312\n",
      "Root Mean Squared Error: 426.80311361034273\n",
      "R-squared: 0.5492668841230668\n",
      "Adjusted R-squared: 0.5487514660374442\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "#from keras.layers import Dropout\n",
    "#model.add(Dropout(0.5)) \n",
    "\n",
    "#from keras.regularizers import l1, l2\n",
    "#model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1], kernel_regularizer=l2(0.01)))\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 10, restore_best_weights=True)\n",
    "model.fit(X_train_scaled, y_train, epochs = 300, batch_size = 64, validation_split=0.3, callbacks=[early_stopping])\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse_r = mean_squared_error(y_test, y_pred, squared = False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "n = len(y_test)\n",
    "k = X_train_scaled.shape[1]  \n",
    "adj_r2 = 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {mse_r}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Adjusted R-squared: {adj_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f4ed3263",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 182160.89778748312\n",
      "Root Mean Squared Error: 426.80311361034273\n",
      "R-squared: 0.5492668841230668\n",
      "Adjusted R-squared: 0.5487514660374442\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {mse_r}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Adjusted R-squared: {adj_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "53397bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 267us/step\n",
      "55/55 [==============================] - 0s 261us/step\n",
      "Training MSE: 174220.74619443633\n",
      "Validation MSE: 179539.4143288872\n",
      "Huber Loss: [[ 84.10565186 266.10565186 147.10565186 ... 398.89434814  74.10565186\n",
      "  108.10565186]\n",
      " [115.5806427   65.4193573   52.5806427  ... 599.5806427  125.5806427\n",
      "   91.5806427 ]\n",
      " [ 97.43060303  83.56939697  34.43060303 ... 581.43060303 107.43060303\n",
      "   73.43060303]\n",
      " ...\n",
      " [653.83374023 835.83374023 716.83374023 ... 169.83374023 643.83374023\n",
      "  677.83374023]\n",
      " [171.47569275   9.52430725 108.47569275 ... 655.47569275 181.47569275\n",
      "  147.47569275]\n",
      " [232.24658203 414.24658203 295.24658203 ... 250.75341797 222.24658203\n",
      "  256.24658203]]\n",
      "Mean Huber Loss: 627.0388039451589\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.predict(X_train_scaled)\n",
    "test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "train_mse = mean_squared_error(y_train, train_pred)\n",
    "test_mse = mean_squared_error(y_test, test_pred)\n",
    "\n",
    "print(f'Training MSE: {train_mse}')\n",
    "print(f'Validation MSE: {test_mse}')\n",
    "\n",
    "import tensorflow as tf\n",
    "def huber_loss(y_test, y_pred, delta = 1.0):\n",
    "    error = y_test - y_pred\n",
    "    condition = tf.abs(error) < delta\n",
    "    squared_loss = 0.5 * tf.square(error)\n",
    "    linear_loss = delta * (tf.abs(error) - 0.5 * delta)\n",
    "    return tf.where(condition, squared_loss, linear_loss)\n",
    "\n",
    "loss = huber_loss(y_test, y_pred, delta = 1.0)\n",
    "print(\"Huber Loss:\", loss.numpy())\n",
    "\n",
    "mean_huber_loss = np.mean(loss)\n",
    "print(f\"Mean Huber Loss: {mean_huber_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f796ea26",
   "metadata": {},
   "source": [
    "## No overfitting \n",
    "\n",
    "\n",
    "## 30% Training MSE: 167561.7460854632\n",
    "Validation MSE: 182676.4375581989"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d8b450",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "577688c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ff30a011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 260812.0098650761\n",
      "Root Mean Squared Error: 510.6975718221853\n",
      "R-squared: 0.35465508079698926\n",
      "Adjusted R-squared: 0.3539171220557623\n"
     ]
    }
   ],
   "source": [
    "regressor = svm.SVR(kernel = 'linear', C = 5.0, epsilon = 2.5)\n",
    "\n",
    "regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "yp_svm = regressor.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, yp_svm)\n",
    "mse_r = mean_squared_error(y_test, yp_svm, squared = False)\n",
    "r2 = r2_score(y_test, yp_svm)\n",
    "\n",
    "n = len(y_test)\n",
    "k = X_train_scaled.shape[1]  \n",
    "adj_r2 = 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {mse_r}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Adjusted R-squared: {adj_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8e88b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22382072257431407"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_svm = cross_val_score(svm.SVR(kernel = 'linear', C = 5.0, epsilon = 2.5), \n",
    "                            X_test_scaled, y_test, cv = 10, scoring = 'r2').mean()\n",
    "score_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ea0dc11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278.0</td>\n",
       "      <td>715.132368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.0</td>\n",
       "      <td>83.647308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215.0</td>\n",
       "      <td>545.293195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1290.0</td>\n",
       "      <td>799.546194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165.0</td>\n",
       "      <td>614.944886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual   Predicted\n",
       "0   278.0  715.132368\n",
       "1    96.0   83.647308\n",
       "2   215.0  545.293195\n",
       "3  1290.0  799.546194\n",
       "4   165.0  614.944886"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_svm = pd.DataFrame({'Actual': y_test, 'Predicted': yp_svm})\n",
    "pred_svm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee445f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "753e0e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 226015.57144926663\n",
      "Root Mean Squared Error: 475.4109500729518\n",
      "R-squared: 0.44075427825963653\n",
      "Adjusted R-squared: 0.44011477486142003\n"
     ]
    }
   ],
   "source": [
    "regressor = svm.SVR(kernel = 'poly', C = 50.0, epsilon = 3.5, degree = 2)\n",
    "\n",
    "regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "yp_svm_p2 = regressor.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, yp_svm_p2)\n",
    "mse_r = mean_squared_error(y_test, yp_svm_p2, squared = False)\n",
    "r2 = r2_score(y_test, yp_svm_p2)\n",
    "\n",
    "n = len(y_test)\n",
    "k = X_train_scaled.shape[1]  \n",
    "adj_r2 = 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {mse_r}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Adjusted R-squared: {adj_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7db15db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43712128689851515"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_svr = cross_val_score(svm.SVR(kernel = 'poly', C = 50.0, epsilon = 3.5, degree = 2), \n",
    "                            X_test_scaled, y_test, cv = 10, scoring = 'r2').mean()\n",
    "score_svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2b7f64bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 230861.0609871089\n",
      "Validation MSE: 226015.57144926663\n",
      "Mean Huber Loss: 332.35711018672214\n"
     ]
    }
   ],
   "source": [
    "train_pred = regressor.predict(X_train_scaled)\n",
    "test_pred = regressor.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "train_mse = mean_squared_error(y_train, train_pred)\n",
    "test_mse = mean_squared_error(y_test, test_pred)\n",
    "\n",
    "print(f'Training MSE: {train_mse}')\n",
    "print(f'Validation MSE: {test_mse}')\n",
    "\n",
    "import tensorflow as tf\n",
    "def huber_loss(y_test, yp_svm_p2, delta = 1.0):\n",
    "    error = y_test - yp_svm_p2\n",
    "    condition = tf.abs(error) < delta\n",
    "    squared_loss = 0.5 * tf.square(error)\n",
    "    linear_loss = delta * (tf.abs(error) - 0.5 * delta)\n",
    "    return tf.where(condition, squared_loss, linear_loss)\n",
    "\n",
    "loss = huber_loss(y_test, yp_svm_p2, delta = 1.0)\n",
    "#print(\"Huber Loss:\", loss.numpy())\n",
    "\n",
    "mean_huber_loss = np.mean(loss)\n",
    "print(f\"Mean Huber Loss: {mean_huber_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567dad86",
   "metadata": {},
   "source": [
    "## No overfitting \n",
    "\n",
    "## 30% Training MSE: 228137.12938671483\n",
    "Validation MSE: 234311.1493008199"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a207f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cebdc20b",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "051ace45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e7466068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 7, 9]}  # Adjust the range based on your data\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "#knn_regressor = KNeighborsRegressor(n_neighbors=best_k)\n",
    "#knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b1c23bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 171021.93224674446\n",
      "Root Mean Squared Error: 413.5479805859829\n",
      "R-squared: 0.5768287852050449\n",
      "Adjusted R-squared: 0.5763448844448449\n"
     ]
    }
   ],
   "source": [
    "knn_regressor = KNeighborsRegressor(n_neighbors = 9, metric='manhattan') \n",
    "\n",
    "knn_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "yp_knn = knn_regressor.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, yp_knn)\n",
    "mse_r = mean_squared_error(y_test, yp_knn, squared = False)\n",
    "r2 = r2_score(y_test, yp_knn)\n",
    "\n",
    "n = len(y_test)\n",
    "k = X_train_scaled.shape[1]  \n",
    "adj_r2 = 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {mse_r}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Adjusted R-squared: {adj_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "85167242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.566962709582967"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_knn = cross_val_score(KNeighborsRegressor(n_neighbors = 9), \n",
    "                            X_test_scaled, y_test, cv = 5, scoring = 'r2').mean()\n",
    "score_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7af89a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278.0</td>\n",
       "      <td>328.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.0</td>\n",
       "      <td>139.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215.0</td>\n",
       "      <td>172.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1290.0</td>\n",
       "      <td>997.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165.0</td>\n",
       "      <td>421.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual   Predicted\n",
       "0   278.0  328.333333\n",
       "1    96.0  139.777778\n",
       "2   215.0  172.888889\n",
       "3  1290.0  997.000000\n",
       "4   165.0  421.666667"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_knn = pd.DataFrame({'Actual': y_test, 'Predicted': yp_knn})\n",
    "pred_knn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a0860514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 137710.31506144654\n",
      "Validation MSE: 171021.93224674446\n",
      "Mean Huber Loss: 262.4580549918259\n"
     ]
    }
   ],
   "source": [
    "train_pred = knn_regressor.predict(X_train_scaled)\n",
    "test_pred = knn_regressor.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "train_mse = mean_squared_error(y_train, train_pred)\n",
    "test_mse = mean_squared_error(y_test, test_pred)\n",
    "\n",
    "print(f'Training MSE: {train_mse}')\n",
    "print(f'Validation MSE: {test_mse}')\n",
    "\n",
    "import tensorflow as tf\n",
    "def huber_loss(y_test, yp_knn, delta = 1.0):\n",
    "    error = y_test - yp_knn\n",
    "    condition = tf.abs(error) < delta\n",
    "    squared_loss = 0.5 * tf.square(error)\n",
    "    linear_loss = delta * (tf.abs(error) - 0.5 * delta)\n",
    "    return tf.where(condition, squared_loss, linear_loss)\n",
    "\n",
    "loss = huber_loss(y_test, yp_knn, delta = 1.0)\n",
    "#print(\"Huber Loss:\", loss.numpy())\n",
    "\n",
    "mean_huber_loss = np.mean(loss)\n",
    "print(f\"Mean Huber Loss: {mean_huber_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da91fbf7",
   "metadata": {},
   "source": [
    "## Overfitting here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a34e3255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 193217.9620947489\n",
      "Root Mean Squared Error: 439.5656516320957\n",
      "R-squared: 0.5219076368411402\n",
      "Adjusted R-squared: 0.5213609331668589\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "bagging_regressor = BaggingRegressor(KNeighborsRegressor(n_neighbors = 4), n_estimators = 10, random_state=12)\n",
    "bagging_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "yp_knn_bgg = bagging_regressor.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, yp_knn_bgg)\n",
    "mse_r = mean_squared_error(y_test, yp_knn_bgg, squared = False)\n",
    "r2 = r2_score(y_test, yp_knn_bgg)\n",
    "\n",
    "n = len(y_test)\n",
    "k = X_train_scaled.shape[1]  \n",
    "adj_r2 = 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {mse_r}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Adjusted R-squared: {adj_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a1dfb6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5459766094983227"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_knn_bgg = cross_val_score(BaggingRegressor(KNeighborsRegressor(n_neighbors = 4), n_estimators = 10, random_state=12), \n",
    "                            X_test_scaled, y_test, cv = 5, scoring = 'r2').mean()\n",
    "score_knn_bgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9b79040b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 112665.32327491797\n",
      "Validation MSE: 193217.9620947489\n",
      "Mean Huber Loss: 274.4220692422945\n"
     ]
    }
   ],
   "source": [
    "train_pred = bagging_regressor.predict(X_train_scaled)\n",
    "test_pred = bagging_regressor.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "train_mse = mean_squared_error(y_train, train_pred)\n",
    "test_mse = mean_squared_error(y_test, test_pred)\n",
    "\n",
    "print(f'Training MSE: {train_mse}')\n",
    "print(f'Validation MSE: {test_mse}')\n",
    "\n",
    "import tensorflow as tf\n",
    "def huber_loss(y_test, yp_knn_bgg, delta = 1.0):\n",
    "    error = y_test - yp_knn_bgg\n",
    "    condition = tf.abs(error) < delta\n",
    "    squared_loss = 0.5 * tf.square(error)\n",
    "    linear_loss = delta * (tf.abs(error) - 0.5 * delta)\n",
    "    return tf.where(condition, squared_loss, linear_loss)\n",
    "\n",
    "loss = huber_loss(y_test, yp_knn_bgg, delta = 1.0)\n",
    "#print(\"Huber Loss:\", loss.numpy())\n",
    "\n",
    "mean_huber_loss = np.mean(loss)\n",
    "print(f\"Mean Huber Loss: {mean_huber_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1633e6",
   "metadata": {},
   "source": [
    "## Overfitting here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e461dc",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3ae0b356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3f884de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeRegressor(), param_grid, cv = 5, scoring = 'neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ee9064cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 181200.42440230845\n",
      "Root Mean Squared Error: 425.67643157956076\n",
      "R-squared: 0.5516434488352242\n",
      "Adjusted R-squared: 0.551130748376488\n"
     ]
    }
   ],
   "source": [
    "tree_regressor = DecisionTreeRegressor(\n",
    "    max_depth = 10,\n",
    "    min_samples_split = 10,\n",
    "    min_samples_leaf = 4,\n",
    "    random_state = 12\n",
    ")\n",
    "\n",
    "tree_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "yp_dt = tree_regressor.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, yp_dt)\n",
    "mse_r = mean_squared_error(y_test, yp_dt, squared = False)\n",
    "r2 = r2_score(y_test, yp_dt)\n",
    "\n",
    "n = len(y_test)\n",
    "k = X_train_scaled.shape[1]  \n",
    "adj_r2 = 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {mse_r}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Adjusted R-squared: {adj_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "503c2f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4731598280110855"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dt = cross_val_score(DecisionTreeRegressor(max_depth = 10, min_samples_split = 10, \n",
    "                                                 min_samples_leaf = 4, random_state = 12), \n",
    "X_test_scaled, y_test, cv = 5, scoring = 'r2').mean()\n",
    "\n",
    "score_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eeb2b251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278.0</td>\n",
       "      <td>334.317647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.0</td>\n",
       "      <td>168.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215.0</td>\n",
       "      <td>109.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1290.0</td>\n",
       "      <td>1306.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165.0</td>\n",
       "      <td>574.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual    Predicted\n",
       "0   278.0   334.317647\n",
       "1    96.0   168.857143\n",
       "2   215.0   109.500000\n",
       "3  1290.0  1306.000000\n",
       "4   165.0   574.833333"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dt = pd.DataFrame({'Actual': y_test, 'Predicted': yp_dt})\n",
    "pred_dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e05c04f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 126603.5474418591\n",
      "Validation MSE: 181200.42440230845\n",
      "Mean Huber Loss: 267.1467770341865\n"
     ]
    }
   ],
   "source": [
    "train_pred = tree_regressor.predict(X_train_scaled)\n",
    "test_pred = tree_regressor.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "train_mse = mean_squared_error(y_train, train_pred)\n",
    "test_mse = mean_squared_error(y_test, test_pred)\n",
    "\n",
    "print(f'Training MSE: {train_mse}')\n",
    "print(f'Validation MSE: {test_mse}')\n",
    "\n",
    "import tensorflow as tf\n",
    "def huber_loss(y_test, yp_dt, delta = 1.0):\n",
    "    error = y_test - yp_dt\n",
    "    condition = tf.abs(error) < delta\n",
    "    squared_loss = 0.5 * tf.square(error)\n",
    "    linear_loss = delta * (tf.abs(error) - 0.5 * delta)\n",
    "    return tf.where(condition, squared_loss, linear_loss)\n",
    "\n",
    "loss = huber_loss(y_test, yp_dt, delta = 1.0)\n",
    "#print(\"Huber Loss:\", loss.numpy())\n",
    "\n",
    "mean_huber_loss = np.mean(loss)\n",
    "print(f\"Mean Huber Loss: {mean_huber_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4612edf",
   "metadata": {},
   "source": [
    "## Overfitting here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d71547",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "112bc5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 LN: 0.3991796133882427\n",
      "R2 LNP2: 0.4533307963682661\n",
      "R2 RP2: 0.4470638127692883\n",
      "R2 RF: 0.5867153839754451\n",
      "R2 SVM: 0.35465508079698926\n",
      "R2 SVR: 0.44075427825963653\n",
      "R2 KNN: 0.5768287852050449\n",
      "R2 KNN BGG: 0.5219076368411402\n",
      "R2 DT: 0.5516434488352242\n"
     ]
    }
   ],
   "source": [
    "print(\"R2 LN:\", r2_score(y_test, yp_lr))\n",
    "\n",
    "print(\"R2 LNP2:\", r2_score(y_test, yp_p2))\n",
    "\n",
    "print(\"R2 RP2:\", r2_score(y_test, yp_rp2))\n",
    "\n",
    "print(\"R2 RF:\", r2_score(y_test, y_pred_best))\n",
    "\n",
    "print(\"R2 SVM:\", r2_score(y_test, yp_svm))\n",
    "\n",
    "print(\"R2 SVR:\", r2_score(y_test, yp_svm_p2))\n",
    "\n",
    "print(\"R2 KNN:\", r2_score(y_test, yp_knn))\n",
    "\n",
    "print(\"R2 KNN BGG:\", r2_score(y_test, yp_knn_bgg))\n",
    "\n",
    "print(\"R2 DT:\", r2_score(y_test, yp_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543c1b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb95e9a4",
   "metadata": {},
   "source": [
    "## 10 %\n",
    "\n",
    "R2 LN: 0.38074734896171947\n",
    "R2 LNP2: 0.437375128022336\n",
    "R2 RP2: 0.43158689283648877\n",
    "R2 RF: 0.5731908439376762\n",
    "R2 SVM: 0.35080947923018724\n",
    "R2 SVR: 0.4270188162339221\n",
    "R2 KNN: 0.5503845902353699\n",
    "R2 KNN BGG: 0.5354262824282361\n",
    "R2 DT: 0.5445850330737287"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1de3be",
   "metadata": {},
   "source": [
    "## 20 %\n",
    "\n",
    "R2 LN: 0.3991796133882427\n",
    "R2 LNP2: 0.4533307963682661\n",
    "R2 RP2: 0.4470638127692883\n",
    "R2 RF: 0.5867153839754451\n",
    "R2 SVM: 0.35465508079698926\n",
    "R2 SVR: 0.44075427825963653\n",
    "R2 KNN: 0.5768287852050449\n",
    "R2 KNN BGG: 0.5219076368411402\n",
    "R2 DT: 0.5516434488352242"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc382ad9",
   "metadata": {},
   "source": [
    "## 30%\n",
    "\n",
    "R2 LN: 0.39912159290211624\n",
    "R2 LNP2: 0.4580627201369608\n",
    "R2 RP2: 0.44855675534225115\n",
    "R2 RF: 0.5818660606458415\n",
    "R2 SVM: 0.34350975005476103\n",
    "R2 SVR: 0.44365713118615513\n",
    "R2 KNN: 0.5712481683582395\n",
    "R2 KNN BGG: 0.5414348406777505\n",
    "R2 DT: 0.5362274954131457"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389a803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc80d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d5da8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "93c77371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation LN: 0.39460955763442185\n",
      "Cross Validation LNP2: 0.39460955763442185\n",
      "Cross Validation RP2: 0.38995153345812467\n",
      "Cross Validation RF: 0.5410243375530565\n",
      "Cross Validation SVM: 0.22382072257431407\n",
      "Cross Validation SVR: 0.43712128689851515\n",
      "Cross Validation KNN: 0.566962709582967\n",
      "Cross Validation KNN BGG: 0.5459766094983227\n",
      "Cross Validation DT: 0.4731598280110855\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross Validation LN:\", score_l) #yp_lr\n",
    "\n",
    "print(\"Cross Validation LNP2:\", score_lp2) #yp_p2\n",
    "\n",
    "print(\"Cross Validation RP2:\", score_rp2) #yp_rp2\n",
    "\n",
    "print(\"Cross Validation RF:\", score_rf) #y_pred_best\n",
    "\n",
    "#ANN y_pred\n",
    "\n",
    "print(\"Cross Validation SVM:\", score_svm) #yp_svm\n",
    "\n",
    "print(\"Cross Validation SVR:\", score_svr) #yp_svm_p2\n",
    "\n",
    "print(\"Cross Validation KNN:\", score_knn) #yp_knn\n",
    "\n",
    "print(\"Cross Validation KNN BGG:\", score_knn_bgg)  #yp_knn_bgg\n",
    "\n",
    "print(\"Cross Validation DT:\", score_dt) #yp_dt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87752301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ee44a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a751ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8fbacf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc0b4be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221651a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
